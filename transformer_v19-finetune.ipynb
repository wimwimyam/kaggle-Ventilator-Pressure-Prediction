{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:17:22.047222Z",
     "iopub.status.busy": "2021-10-13T04:17:22.046447Z",
     "iopub.status.idle": "2021-10-13T04:17:23.269684Z",
     "shell.execute_reply": "2021-10-13T04:17:23.269210Z",
     "shell.execute_reply.started": "2021-10-12T05:39:55.354395Z"
    },
    "executionInfo": {
     "elapsed": 2646,
     "status": "ok",
     "timestamp": 1633176713080,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "vsRfljafuYSE",
    "papermill": {
     "duration": 1.246673,
     "end_time": "2021-10-13T04:17:23.269823",
     "exception": false,
     "start_time": "2021-10-13T04:17:22.023150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "import torch_optimizer as optim\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:17:23.310367Z",
     "iopub.status.busy": "2021-10-13T04:17:23.309536Z",
     "iopub.status.idle": "2021-10-13T04:17:23.311571Z",
     "shell.execute_reply": "2021-10-13T04:17:23.312113Z",
     "shell.execute_reply.started": "2021-10-12T05:39:56.704014Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1633176713080,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "cagWoXxKwV31",
    "papermill": {
     "duration": 0.023844,
     "end_time": "2021-10-13T04:17:23.312240",
     "exception": false,
     "start_time": "2021-10-13T04:17:23.288396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:17:23.350976Z",
     "iopub.status.busy": "2021-10-13T04:17:23.350429Z",
     "iopub.status.idle": "2021-10-13T04:17:23.352666Z",
     "shell.execute_reply": "2021-10-13T04:17:23.353093Z",
     "shell.execute_reply.started": "2021-10-12T05:39:56.712676Z"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1633176713313,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "9VBtJTT0uo22",
    "papermill": {
     "duration": 0.023661,
     "end_time": "2021-10-13T04:17:23.353210",
     "exception": false,
     "start_time": "2021-10-13T04:17:23.329549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'transformer_v19'\n",
    "base_dir = \"./\"\n",
    "if not os.path.exists(f'models/{MODEL_NAME}'):\n",
    "    os.makedirs(f'models/{MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:17:23.392557Z",
     "iopub.status.busy": "2021-10-13T04:17:23.392066Z",
     "iopub.status.idle": "2021-10-13T04:17:35.818002Z",
     "shell.execute_reply": "2021-10-13T04:17:35.818695Z",
     "shell.execute_reply.started": "2021-10-12T05:39:56.724572Z"
    },
    "executionInfo": {
     "elapsed": 9971,
     "status": "ok",
     "timestamp": 1633176723595,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "kLXYOgoeuvy6",
    "papermill": {
     "duration": 12.448382,
     "end_time": "2021-10-13T04:17:35.818990",
     "exception": false,
     "start_time": "2021-10-13T04:17:23.370608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(base_dir + 'train.csv')\n",
    "test_df = pd.read_csv(base_dir + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:17:35.874558Z",
     "iopub.status.busy": "2021-10-13T04:17:35.873440Z",
     "iopub.status.idle": "2021-10-13T04:17:36.550713Z",
     "shell.execute_reply": "2021-10-13T04:17:36.550223Z",
     "shell.execute_reply.started": "2021-10-12T05:40:08.547318Z"
    },
    "papermill": {
     "duration": 0.705919,
     "end_time": "2021-10-13T04:17:36.550858",
     "exception": false,
     "start_time": "2021-10-13T04:17:35.844939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_df['pressure'] = le.fit_transform(train_df['pressure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:17:42.924598Z",
     "iopub.status.busy": "2021-10-13T04:17:42.924002Z",
     "iopub.status.idle": "2021-10-13T04:18:03.293805Z",
     "shell.execute_reply": "2021-10-13T04:18:03.294610Z",
     "shell.execute_reply.started": "2021-10-12T05:40:09.33342Z"
    },
    "executionInfo": {
     "elapsed": 15912,
     "status": "ok",
     "timestamp": 1633176739504,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "OhZfYGCOu7jn",
    "papermill": {
     "duration": 26.726301,
     "end_time": "2021-10-13T04:18:03.294787",
     "exception": false,
     "start_time": "2021-10-13T04:17:36.568486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['RC'] = (train_df['R'].astype(str) + '_' + train_df['C'].astype(str))\n",
    "train_df['RC'] = train_df['RC'].map({'20_50':0, '20_20':1, '50_20':2, '50_50':3, '5_50':4, '5_20':5, '50_10':6, '20_10':7, '5_10':8})\n",
    "test_df['RC'] = (test_df['R'].astype(str) + '_' + test_df['C'].astype(str))\n",
    "test_df['RC'] = test_df['RC'].map({'20_50':0, '20_20':1, '50_20':2, '50_50':3, '5_50':4, '5_20':5, '50_10':6, '20_10':7, '5_10':8})\n",
    "# train_df['u_in_cat'] = train_df['u_in'].round().astype(int)\n",
    "# test_df['u_in_cat'] = test_df['u_in'].round().astype(int)\n",
    "train_df['u_in_0'] = (train_df['u_in'].round() == 0).astype(int)\n",
    "test_df['u_in_0'] = (test_df['u_in'].round() == 0).astype(int)\n",
    "train_df['u_in_5'] = (train_df['u_in'].round() == 5).astype(int)\n",
    "test_df['u_in_5'] = (test_df['u_in'].round() == 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:18:03.374649Z",
     "iopub.status.busy": "2021-10-13T04:18:03.373814Z",
     "iopub.status.idle": "2021-10-13T04:18:03.377606Z",
     "shell.execute_reply": "2021-10-13T04:18:03.377190Z",
     "shell.execute_reply.started": "2021-10-12T05:40:37.325349Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1633176739505,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "e-n7EBcytRFf",
    "papermill": {
     "duration": 0.022961,
     "end_time": "2021-10-13T04:18:03.377711",
     "exception": false,
     "start_time": "2021-10-13T04:18:03.354750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# features = train_df.columns.drop(['id','breath_id','pressure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:18:03.419638Z",
     "iopub.status.busy": "2021-10-13T04:18:03.418779Z",
     "iopub.status.idle": "2021-10-13T04:18:09.870641Z",
     "shell.execute_reply": "2021-10-13T04:18:09.870135Z",
     "shell.execute_reply.started": "2021-10-12T05:40:37.338221Z"
    },
    "executionInfo": {
     "elapsed": 3412,
     "status": "ok",
     "timestamp": 1633176742913,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "SW8IEFydtP3S",
    "papermill": {
     "duration": 6.473443,
     "end_time": "2021-10-13T04:18:09.870773",
     "exception": false,
     "start_time": "2021-10-13T04:18:03.397330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "RS = StandardScaler()\n",
    "all_df = pd.concat([train_df,test_df])\n",
    "train_df['u_in'] = np.log1p(train_df['u_in'] - all_df['u_in'].min())\n",
    "test_df['u_in'] = np.log1p(test_df['u_in'] - all_df['u_in'].min())\n",
    "all_df['u_in'] = np.log1p(all_df['u_in'] - all_df['u_in'].min())\n",
    "\n",
    "RS.fit(all_df[['u_in','time_step']])\n",
    "train_df[['u_in','time_step']] = RS.transform(train_df[['u_in','time_step']])\n",
    "test_df[['u_in','time_step']] = RS.transform(test_df[['u_in','time_step']])\n",
    "\n",
    "# from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "# RS = StandardScaler()\n",
    "# all_df = pd.concat([train_df,test_df])\n",
    "# RS.fit(all_df[['u_in','time_step']])\n",
    "# train_df[['u_in','time_step']] = RS.transform(train_df[['u_in','time_step']])\n",
    "# test_df[['u_in','time_step']] = RS.transform(test_df[['u_in','time_step']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:18:09.991081Z",
     "iopub.status.busy": "2021-10-13T04:18:09.989870Z",
     "iopub.status.idle": "2021-10-13T04:18:10.177419Z",
     "shell.execute_reply": "2021-10-13T04:18:10.176927Z",
     "shell.execute_reply.started": "2021-10-12T05:40:43.444726Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1633176742914,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "ahQ_qNl6wYf7",
    "papermill": {
     "duration": 0.288427,
     "end_time": "2021-10-13T04:18:10.177548",
     "exception": false,
     "start_time": "2021-10-13T04:18:09.889121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_tr = train_df[['RC','u_in','u_out','u_in_0','u_in_5','time_step']].values.reshape(-1,80,6)\n",
    "X_test = test_df[['RC','u_in','u_out','u_in_0','u_in_5','time_step']].values.reshape(-1,80,6)\n",
    "# X_tr = train_df[features].values.reshape(-1,80,18)\n",
    "# X_test = test_df[features].values.reshape(-1,80,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:18:10.215778Z",
     "iopub.status.busy": "2021-10-13T04:18:10.215249Z",
     "iopub.status.idle": "2021-10-13T04:18:10.218888Z",
     "shell.execute_reply": "2021-10-13T04:18:10.218459Z",
     "shell.execute_reply.started": "2021-10-12T05:40:43.782967Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1633176743344,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "am4C6rtTwxcU",
    "papermill": {
     "duration": 0.024291,
     "end_time": "2021-10-13T04:18:10.219004",
     "exception": false,
     "start_time": "2021-10-13T04:18:10.194713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_tr = train_df['pressure'].values.reshape(-1,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo_label = np.load(\"subs/sub_logits_transformer_v11.npy\")\n",
    "# from scipy.special import softmax\n",
    "# pseudo_label = softmax(pseudo_label,axis=2)\n",
    "# mask = test_df['u_out'].values.reshape(-1,80) == 0\n",
    "# tmp1 = pseudo_label.max(2)\n",
    "# res = []\n",
    "# for i in tqdm(range(len(tmp1))):\n",
    "#     res.append(tmp1[i][mask[i]].mean())\n",
    "# res = np.array(res)\n",
    "# mask = res > 0.6\n",
    "# np.mean(mask)\n",
    "# pseudo_label = pseudo_label.argmax(-1)\n",
    "# X_tr = np.concatenate([X_tr,X_test[mask]],axis=0)\n",
    "# y_tr = np.concatenate([y_tr,pseudo_label[mask]],axis=0)\n",
    "# import gc\n",
    "# del pseudo_label, mask, res, tmp1; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_pressures = train_df[\"pressure\"].unique()\n",
    "# sorted_pressures = np.sort(unique_pressures)\n",
    "# total_pressures_len = len(sorted_pressures)\n",
    "# def find_nearest(prediction):\n",
    "#     insert_idx = np.searchsorted(sorted_pressures, prediction)\n",
    "#     if insert_idx == total_pressures_len:\n",
    "#         # If the predicted value is bigger than the highest pressure in the train dataset,\n",
    "#         # return the max value.\n",
    "#         return sorted_pressures[-1]\n",
    "#     elif insert_idx == 0:\n",
    "#         # Same control but for the lower bound.\n",
    "#         return sorted_pressures[0]\n",
    "#     lower_val = sorted_pressures[insert_idx - 1]\n",
    "#     upper_val = sorted_pressures[insert_idx]\n",
    "#     return lower_val if abs(lower_val - prediction) < abs(upper_val - prediction) else upper_val\n",
    "# pseudo_label = pd.read_csv(\"pressure_submission.csv\")['pressure'].values\n",
    "# for i in range(len(pseudo_label)):\n",
    "#     pseudo_label[i] = find_nearest(pseudo_label[i])\n",
    "# pseudo_label = le.transform(pseudo_label).reshape(-1,80)\n",
    "# X_tr = np.concatenate([X_tr,X_test],axis=0)\n",
    "# y_tr = np.concatenate([y_tr,pseudo_label],axis=0)\n",
    "# import gc\n",
    "# del pseudo_label; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:18:10.259036Z",
     "iopub.status.busy": "2021-10-13T04:18:10.258276Z",
     "iopub.status.idle": "2021-10-13T04:18:10.261260Z",
     "shell.execute_reply": "2021-10-13T04:18:10.261648Z",
     "shell.execute_reply.started": "2021-10-12T05:40:43.799012Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1633176743345,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "mBJplxgVzR3Z",
    "outputId": "f65abfaa-6083-4682-9027-09b75a68e97d",
    "papermill": {
     "duration": 0.025961,
     "end_time": "2021-10-13T04:18:10.261757",
     "exception": false,
     "start_time": "2021-10-13T04:18:10.235796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75450, 80, 6), (50300, 80, 6), (75450, 80))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape,X_test.shape,y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:18:10.299977Z",
     "iopub.status.busy": "2021-10-13T04:18:10.299375Z",
     "iopub.status.idle": "2021-10-13T04:18:10.302105Z",
     "shell.execute_reply": "2021-10-13T04:18:10.301680Z",
     "shell.execute_reply.started": "2021-10-12T05:40:43.819363Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1633176743345,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "n0ncwyMZwYUs",
    "papermill": {
     "duration": 0.023285,
     "end_time": "2021-10-13T04:18:10.302209",
     "exception": false,
     "start_time": "2021-10-13T04:18:10.278924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    X_tr = X_tr[:1000]\n",
    "    y_tr = y_tr[:1000]\n",
    "    X_test = X_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:18:10.352282Z",
     "iopub.status.busy": "2021-10-13T04:18:10.351510Z",
     "iopub.status.idle": "2021-10-13T04:18:10.353809Z",
     "shell.execute_reply": "2021-10-13T04:18:10.353418Z",
     "shell.execute_reply.started": "2021-10-12T05:49:50.818657Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1633176743345,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "KPHlkF2WcG-S",
    "papermill": {
     "duration": 0.034617,
     "end_time": "2021-10-13T04:18:10.353908",
     "exception": false,
     "start_time": "2021-10-13T04:18:10.319291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, train_dataloader, epoch, device = torch.device('cpu')):\n",
    "    model.eval()\n",
    "    MA_loss = 0\n",
    "    count = 0\n",
    "    for X,y in train_dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        y = F.one_hot(y,950).float()\n",
    "        y[:,:,:-1] += 0.1 * y[:,:,1:]\n",
    "        y[:,:,1:] += 0.1 * y[:,:,:-1]\n",
    "        y[y==1] = 0.8\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        mask1 = X[:,:,2] == 0\n",
    "        mask2 = X[:,:,2] == 1\n",
    "        pred = model(X)\n",
    "\n",
    "        pred = torch.sigmoid(pred[mask1].reshape(-1,950))\n",
    "        y = y[mask1].reshape(-1,950)\n",
    "\n",
    "        loss = -torch.sum(y * torch.log(1e-8 + pred) + (1-y) * torch.log(1 - pred + 1e-8),dim=-1).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        MA_loss += loss.item() * len(y)\n",
    "        count += len(y)\n",
    "    MA_loss /= count\n",
    "    return MA_loss\n",
    "\n",
    "def evaluation(model, val_dataloader, device = torch.device('cpu')):\n",
    "    model.eval()\n",
    "    criterion = nn.L1Loss()\n",
    "    MA_loss = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for X,y in val_dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            mask = X[:,:,2] == 0\n",
    "            pred = model(X)\n",
    "            pred = torch.argmax(pred,dim=-1)\n",
    "            pred = pred[mask].reshape(-1).cpu().numpy()\n",
    "            pred = torch.Tensor(le.inverse_transform(pred)).to(device)\n",
    "            y = y[mask].reshape(-1).cpu().long().numpy()\n",
    "            y = torch.Tensor(le.inverse_transform(y)).to(device)\n",
    "            loss = criterion(pred, y)\n",
    "            # loss = criterion(pred.reshape(-1), y.reshape(-1))\n",
    "            MA_loss += loss.item() * len(y)\n",
    "            count += len(y)\n",
    "        MA_loss /= count\n",
    "    return MA_loss\n",
    "\n",
    "def inference(model, test_dataloader, device = torch.device('cpu'), istest = False):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    with torch.no_grad():\n",
    "        if istest:\n",
    "            for X in test_dataloader:\n",
    "                X = X[0]\n",
    "                X = X.to(device)\n",
    "                pred = model(X).cpu()\n",
    "                pred = torch.argmax(pred,dim=-1)\n",
    "                prediction.append(pred)\n",
    "        else:\n",
    "            for X, y in test_dataloader:\n",
    "                X = X.to(device)\n",
    "                pred = model(X).cpu()\n",
    "                pred = torch.argmax(pred,dim=-1)\n",
    "                prediction.append(pred)\n",
    "    prediction = torch.cat(prediction,dim=0).numpy()\n",
    "    prediction = le.inverse_transform(prediction.reshape(-1)).reshape(-1,80)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:18:10.396705Z",
     "iopub.status.busy": "2021-10-13T04:18:10.395885Z",
     "iopub.status.idle": "2021-10-13T04:18:10.408552Z",
     "shell.execute_reply": "2021-10-13T04:18:10.408977Z",
     "shell.execute_reply.started": "2021-10-12T05:49:51.173858Z"
    },
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1633176743750,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "Up4IIaxk6onI",
    "papermill": {
     "duration": 0.037697,
     "end_time": "2021-10-13T04:18:10.409090",
     "exception": false,
     "start_time": "2021-10-13T04:18:10.371393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# helper functions\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d\n",
    "\n",
    "def calc_same_padding(kernel_size):\n",
    "    pad = kernel_size // 2\n",
    "    return (pad, pad - (kernel_size + 1) % 2)\n",
    "\n",
    "# helper classes\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * x.sigmoid()\n",
    "\n",
    "class GLU(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, gate = x.chunk(2, dim=self.dim)\n",
    "        return out * gate.sigmoid()\n",
    "\n",
    "class DepthWiseConv1d(nn.Module):\n",
    "    def __init__(self, chan_in, chan_out, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.padding = padding\n",
    "        self.conv = nn.Conv1d(chan_in, chan_out, kernel_size, groups = chan_in)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, self.padding)\n",
    "        return self.conv(x)\n",
    "\n",
    "# attention, feedforward, and conv module\n",
    "\n",
    "class Scale(nn.Module):\n",
    "    def __init__(self, scale, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) * self.scale\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x, **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        mult = 4,\n",
    "        dropout = 0.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, dim * mult),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim * mult, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class ConformerConvModule(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        causal = False,\n",
    "        expansion_factor = 2,\n",
    "        kernel_size = 31,\n",
    "        dropout = 0.):\n",
    "        super().__init__()\n",
    "\n",
    "        inner_dim = dim * expansion_factor\n",
    "        padding = calc_same_padding(kernel_size) if not causal else (kernel_size - 1, 0)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            Rearrange('b n c -> b c n'),\n",
    "            nn.Conv1d(dim, inner_dim * 2, 1),\n",
    "            GLU(dim=1),\n",
    "            DepthWiseConv1d(inner_dim, inner_dim, kernel_size = kernel_size, padding = padding),\n",
    "            nn.BatchNorm1d(inner_dim) if not causal else nn.Identity(),\n",
    "            Swish(),\n",
    "            nn.Conv1d(inner_dim, dim, 1),\n",
    "            Rearrange('b c n -> b n c'),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:18:10.446377Z",
     "iopub.status.busy": "2021-10-13T04:18:10.445524Z",
     "iopub.status.idle": "2021-10-13T04:18:10.465735Z",
     "shell.execute_reply": "2021-10-13T04:18:10.466163Z",
     "shell.execute_reply.started": "2021-10-12T05:49:51.626554Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1633176743750,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "oDGYzzf44rRS",
    "papermill": {
     "duration": 0.04015,
     "end_time": "2021-10-13T04:18:10.466275",
     "exception": false,
     "start_time": "2021-10-13T04:18:10.426125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        heads = 8,\n",
    "        dim_head = 64,\n",
    "        dropout = 0.,\n",
    "        max_pos_emb = 512,\n",
    "        causal = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        self.heads= heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.to_q = nn.Linear(dim, inner_dim, bias = False)\n",
    "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias = False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim)\n",
    "\n",
    "        self.max_pos_emb = max_pos_emb\n",
    "        # self.rel_pos_emb1 = nn.Linear(1, heads, bias=False)\n",
    "        # self.rel_pos_emb2 = nn.Linear(1, heads, bias=False)\n",
    "        self.rel_pos_emb = nn.Sequential(nn.Linear(1, dim_head),nn.GELU(),nn.Linear(dim_head, dim_head))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.causal = causal\n",
    "\n",
    "    def forward(self, x, position, context = None, mask = None, context_mask = None):\n",
    "        n, device, h, max_pos_emb, has_context = x.shape[-2], x.device, self.heads, self.max_pos_emb, exists(context)\n",
    "        context = default(context, x)\n",
    "\n",
    "        q, k, v = (self.to_q(x), *self.to_kv(context).chunk(2, dim = -1))\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
    "\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "\n",
    "        # shaw's relative positional embedding\n",
    "        dist = rearrange(position, 'b i -> b i () ()') - rearrange(position, 'b j -> b () j ()')\n",
    "        # rel_pos_emb = self.rel_pos_emb1(F.relu(dist)) + self.rel_pos_emb2(F.relu(-dist))   #(bijh)\n",
    "        # pos_attn = rel_pos_emb.permute(0,3,1,2)\n",
    "        rel_pos_emb = self.rel_pos_emb(dist)\n",
    "        pos_attn = einsum('b h n d, b n r d -> b h n r', q, rel_pos_emb) * self.scale\n",
    "        dots = dots + pos_attn\n",
    "\n",
    "        if exists(mask) or exists(context_mask):\n",
    "            mask = default(mask, lambda: torch.ones(*x.shape[:2], device = device))\n",
    "            context_mask = default(context_mask, mask) if not has_context else default(context_mask, lambda: torch.ones(*context.shape[:2], device = device))\n",
    "            mask_value = -torch.finfo(dots.dtype).max\n",
    "            mask = rearrange(mask, 'b i -> b () i ()') * rearrange(context_mask, 'b j -> b () () j')\n",
    "            dots.masked_fill_(~mask, mask_value)\n",
    "\n",
    "        if self.causal:\n",
    "            mask = torch.tril(torch.ones(dots.shape[-2:],device=dots.device)).T\n",
    "            mask = rearrange(mask, 'n r -> () () n r')\n",
    "            dots = dots - mask * 999\n",
    "\n",
    "        attn = dots.softmax(dim = -1)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out = self.to_out(out)\n",
    "        return self.dropout(out)\n",
    "\n",
    "\n",
    "class CustomConformerBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        dim_head = 64,\n",
    "        heads = 8,\n",
    "        ff_mult = 4,\n",
    "        conv_expansion_factor = 2,\n",
    "        conv_kernel_size = 31,\n",
    "        attn_dropout = 0.,\n",
    "        ff_dropout = 0.,\n",
    "        conv_dropout = 0.,\n",
    "        causal = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ff1 = FeedForward(dim = dim, mult = ff_mult, dropout = ff_dropout)\n",
    "        self.attn = CustomAttention(dim = dim, dim_head = dim_head, heads = heads, dropout = attn_dropout, causal = causal)\n",
    "        self.conv = ConformerConvModule(dim = dim, causal = causal, expansion_factor = conv_expansion_factor, kernel_size = conv_kernel_size, dropout = conv_dropout)\n",
    "        self.ff2 = FeedForward(dim = dim, mult = ff_mult, dropout = ff_dropout)\n",
    "\n",
    "        self.attn = PreNorm(dim, self.attn)\n",
    "        self.ff1 = Scale(0.5, PreNorm(dim, self.ff1))\n",
    "        self.ff2 = Scale(0.5, PreNorm(dim, self.ff2))\n",
    "\n",
    "    def forward(self, x, pos, mask = None):\n",
    "        x = self.ff1(x) + x\n",
    "        x = self.attn(x, position = pos, mask = mask) + x\n",
    "        x = self.conv(x) + x\n",
    "        x = self.ff2(x) + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:18:10.514157Z",
     "iopub.status.busy": "2021-10-13T04:18:10.513366Z",
     "iopub.status.idle": "2021-10-13T04:18:10.515694Z",
     "shell.execute_reply": "2021-10-13T04:18:10.515287Z",
     "shell.execute_reply.started": "2021-10-12T05:49:51.952469Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1633176743750,
     "user": {
      "displayName": "Pak Wing YAM",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01265674556408476665"
     },
     "user_tz": -480
    },
    "id": "yoWvAtiNcHBm",
    "papermill": {
     "duration": 0.032424,
     "end_time": "2021-10-13T04:18:10.515800",
     "exception": false,
     "start_time": "2021-10-13T04:18:10.483376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len = 5000):\n",
    "        super().__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self):\n",
    "        return self.pe\n",
    "\n",
    "class BrainModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        DIM = 256\n",
    "        n_layers = 4\n",
    "        self.input_layer = nn.Sequential(nn.Linear(5,DIM),nn.Mish(),nn.Linear(DIM,DIM),nn.Mish())\n",
    "        self.emb_RC = nn.Embedding(9,DIM)\n",
    "        self.emb_u_in = nn.Embedding(101,DIM)\n",
    "        self.scale_layer = nn.Linear(2*DIM,DIM)\n",
    "        self.encoder = nn.ModuleList()\n",
    "        for i in range(n_layers):\n",
    "            self.encoder.append(CustomConformerBlock(dim = DIM,\n",
    "                          dim_head = DIM//8,\n",
    "                          heads = 8,\n",
    "                          ff_mult = 4,\n",
    "                          conv_expansion_factor = 2,\n",
    "                          conv_kernel_size = 5,\n",
    "                          attn_dropout = 0.1,\n",
    "                          ff_dropout = 0.2,\n",
    "                          conv_dropout = 0.05,\n",
    "                          causal = False))\n",
    "        self.fc = nn.Sequential(nn.Linear(DIM,DIM),nn.Mish(),nn.Linear(DIM,950))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #(B,L,C)\n",
    "        pos = X[:,:,-1]\n",
    "        X_dense = self.input_layer(X[:,:,1:])\n",
    "        X = torch.cat([X_dense, self.emb_RC(X[:,:,0].long())],dim=-1)\n",
    "        X = self.scale_layer(X)\n",
    "        for layer in self.encoder:\n",
    "            X = layer(X,pos)\n",
    "        y = self.fc(X)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-13T04:18:10.562898Z",
     "iopub.status.busy": "2021-10-13T04:18:10.557434Z",
     "iopub.status.idle": "2021-10-13T13:02:23.401088Z",
     "shell.execute_reply": "2021-10-13T13:02:23.399054Z"
    },
    "id": "zHGGP6fbfKSv",
    "outputId": "1271a4dd-a37e-4b4d-b314-832921640556",
    "papermill": {
     "duration": 31452.86825,
     "end_time": "2021-10-13T13:02:23.401227",
     "exception": false,
     "start_time": "2021-10-13T04:18:10.532977",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "RC 0\n",
      "initial loss: 0.12861722443215698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8cf527a9c7941d89dee185044b16843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yampa\\.conda\\envs\\pytorch15\\lib\\site-packages\\pytorch_ranger\\ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1025.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.6059817874583393\n",
      "val_loss: 0.1278085380728838\n",
      "best loss: 0.1278085380728838\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.5845617990994043\n",
      "val_loss: 0.12747869371303228\n",
      "best loss: 0.12747869371303228\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.5676203790743144\n",
      "val_loss: 0.12765808772065432\n",
      "best loss: 0.12747869371303228\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.555985259394525\n",
      "val_loss: 0.12728918631803265\n",
      "best loss: 0.12728918631803265\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.545664573881004\n",
      "val_loss: 0.12702733848459516\n",
      "best loss: 0.12702733848459516\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.5369464755436213\n",
      "val_loss: 0.12711703404722877\n",
      "best loss: 0.12702733848459516\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.5278598163107153\n",
      "val_loss: 0.1268522940540507\n",
      "best loss: 0.1268522940540507\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.5210798758976622\n",
      "val_loss: 0.1269361959936364\n",
      "best loss: 0.1268522940540507\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.5134232482321512\n",
      "val_loss: 0.12664542046599953\n",
      "best loss: 0.12664542046599953\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.5068755873552737\n",
      "val_loss: 0.1267249856761443\n",
      "best loss: 0.12664542046599953\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.500006025630289\n",
      "val_loss: 0.1267191960313593\n",
      "best loss: 0.12664542046599953\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.4940280219292945\n",
      "val_loss: 0.12700997643140238\n",
      "best loss: 0.12664542046599953\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.487856861800214\n",
      "val_loss: 0.12706495508433852\n",
      "best loss: 0.12664542046599953\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.4813583217117845\n",
      "val_loss: 0.12703167913097227\n",
      "best loss: 0.12664542046599953\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.4760325199391455\n",
      "val_loss: 0.1266946051092229\n",
      "best loss: 0.12664542046599953\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.47093096300665\n",
      "val_loss: 0.1269824938484181\n",
      "best loss: 0.12664542046599953\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.4640266573085663\n",
      "val_loss: 0.1266135913535679\n",
      "best loss: 0.1266135913535679\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.459709054255179\n",
      "val_loss: 0.12700274514710672\n",
      "best loss: 0.1266135913535679\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.4561443395864906\n",
      "val_loss: 0.12660780677099523\n",
      "best loss: 0.12660780677099523\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.4486735987254002\n",
      "val_loss: 0.1268117876648437\n",
      "best loss: 0.12660780677099523\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.4461878617039234\n",
      "val_loss: 0.12672498350916542\n",
      "best loss: 0.12660780677099523\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.436880644493998\n",
      "val_loss: 0.1265050943161109\n",
      "best loss: 0.1265050943161109\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.433389326842203\n",
      "val_loss: 0.12681322871009865\n",
      "best loss: 0.1265050943161109\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.4270711414769677\n",
      "val_loss: 0.12647905208263016\n",
      "best loss: 0.12647905208263016\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.4229869647090534\n",
      "val_loss: 0.1264486761480209\n",
      "best loss: 0.1264486761480209\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.4192586393645192\n",
      "val_loss: 0.12641106132981816\n",
      "best loss: 0.12641106132981816\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.4137401978904043\n",
      "val_loss: 0.12688990615732051\n",
      "best loss: 0.12641106132981816\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.4083986914707376\n",
      "val_loss: 0.12655428256626403\n",
      "best loss: 0.12641106132981816\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.40365161032201\n",
      "val_loss: 0.12711703797397725\n",
      "best loss: 0.12641106132981816\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.398261804181106\n",
      "val_loss: 0.12676983518656737\n",
      "best loss: 0.12641106132981816\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.392455366117172\n",
      "val_loss: 0.12672353835226194\n",
      "best loss: 0.12641106132981816\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.3897066133329985\n",
      "val_loss: 0.12651232838739837\n",
      "best loss: 0.12641106132981816\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.3834530177270974\n",
      "val_loss: 0.12613041019647472\n",
      "best loss: 0.12613041019647472\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.3797751195295933\n",
      "val_loss: 0.12685663209159007\n",
      "best loss: 0.12613041019647472\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.37398696548057\n",
      "val_loss: 0.12619840631567947\n",
      "best loss: 0.12613041019647472\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.3702857553482035\n",
      "val_loss: 0.12648627921602826\n",
      "best loss: 0.12613041019647472\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.3653679905977145\n",
      "val_loss: 0.12603781981558818\n",
      "best loss: 0.12603781981558818\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.3606293793071584\n",
      "val_loss: 0.12661215304961634\n",
      "best loss: 0.12603781981558818\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.357929403738545\n",
      "val_loss: 0.12673366324422153\n",
      "best loss: 0.12603781981558818\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.353873810918088\n",
      "val_loss: 0.12627941847745358\n",
      "best loss: 0.12603781981558818\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.3485729295986184\n",
      "val_loss: 0.12616801880412273\n",
      "best loss: 0.12603781981558818\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.3427701873084574\n",
      "val_loss: 0.12644144046782752\n",
      "best loss: 0.12603781981558818\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.3395269642276966\n",
      "val_loss: 0.12640237838553592\n",
      "best loss: 0.12603781981558818\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.3340424223772995\n",
      "val_loss: 0.12614776500943747\n",
      "best loss: 0.12603781981558818\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 2.3317053510563746\n",
      "val_loss: 0.1264052764350926\n",
      "best loss: 0.12603781981558818\n",
      "*********************************\n",
      "epoch 45\n",
      "Train_loss: 2.327286161503765\n",
      "val_loss: 0.12603203590883572\n",
      "best loss: 0.12603203590883572\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 2.3224301851487548\n",
      "val_loss: 0.1264790526066668\n",
      "best loss: 0.12603203590883572\n",
      "*********************************\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 47\n",
      "Train_loss: 2.3240049970380188\n",
      "val_loss: 0.12677707053099713\n",
      "best loss: 0.12603203590883572\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 2.3062874181274826\n",
      "val_loss: 0.12619406264252314\n",
      "best loss: 0.12603203590883572\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 2.3030197902904934\n",
      "val_loss: 0.1262201037583248\n",
      "best loss: 0.12603203590883572\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 2.3023841471714066\n",
      "val_loss: 0.12614342333859785\n",
      "best loss: 0.12603203590883572\n",
      "*********************************\n",
      "epoch 51\n",
      "Train_loss: 2.302193652129665\n",
      "val_loss: 0.12594234787558753\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 52\n",
      "Train_loss: 2.3001566038247736\n",
      "val_loss: 0.12602914287948258\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 53\n",
      "Train_loss: 2.300972710425304\n",
      "val_loss: 0.12610725748200693\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 54\n",
      "Train_loss: 2.300538480731029\n",
      "val_loss: 0.12609568833955248\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 55\n",
      "Train_loss: 2.2997522895777456\n",
      "val_loss: 0.12603782434517813\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 56\n",
      "Train_loss: 2.2988483829250526\n",
      "val_loss: 0.12609424391826274\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 57\n",
      "Train_loss: 2.29834542503364\n",
      "val_loss: 0.12614053491212004\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 58\n",
      "Train_loss: 2.297986989690109\n",
      "val_loss: 0.12601178689793957\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 59\n",
      "Train_loss: 2.2974032784409406\n",
      "val_loss: 0.1259857430408345\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 60\n",
      "Train_loss: 2.297150701675394\n",
      "val_loss: 0.12598574338610383\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61\n",
      "Train_loss: 2.2967173423649303\n",
      "val_loss: 0.12597995655008162\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 62\n",
      "Train_loss: 2.296484461973666\n",
      "val_loss: 0.1261506569618938\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 63\n",
      "Train_loss: 2.2941959196284474\n",
      "val_loss: 0.12601033367504208\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 64\n",
      "Train_loss: 2.295100433387619\n",
      "val_loss: 0.12600019960646197\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 65\n",
      "Train_loss: 2.2945679431410366\n",
      "val_loss: 0.12598862790453777\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 66\n",
      "Train_loss: 2.2947584086309325\n",
      "val_loss: 0.12594812590632234\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 67\n",
      "Train_loss: 2.2942288762448073\n",
      "val_loss: 0.12600454349456838\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 68\n",
      "Train_loss: 2.2939160431478163\n",
      "val_loss: 0.12597995421506758\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 69\n",
      "Train_loss: 2.2946790849719876\n",
      "val_loss: 0.1259944218179676\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 70\n",
      "Train_loss: 2.293840537769033\n",
      "val_loss: 0.1259770608775478\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 71\n",
      "Train_loss: 2.2948496421368265\n",
      "val_loss: 0.12597561723112088\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "epoch 72\n",
      "Train_loss: 2.2938003866872023\n",
      "val_loss: 0.125985737077733\n",
      "best loss: 0.12594234787558753\n",
      "*********************************\n",
      "RC 1\n",
      "initial loss: 0.13152096335648503\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e2264f1b4541d28875f334385b96f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.4911415090743927\n",
      "val_loss: 0.1310442881977918\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.4714728379431348\n",
      "val_loss: 0.13118804751405777\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.45775638227505\n",
      "val_loss: 0.13135261165388804\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.4472285906441047\n",
      "val_loss: 0.13130343492078056\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.4382077170560503\n",
      "val_loss: 0.1311993933831222\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.424423956232599\n",
      "val_loss: 0.1311369759575361\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.421740737257437\n",
      "val_loss: 0.13129396920009662\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.412827035915916\n",
      "val_loss: 0.13129965454277434\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.4038149692432937\n",
      "val_loss: 0.13125425128517101\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.398431095395189\n",
      "val_loss: 0.13130910342738336\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.392133593352107\n",
      "val_loss: 0.13134693269891143\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 11\n",
      "Train_loss: 2.3856320277122647\n",
      "val_loss: 0.13146042247567297\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.378579102623048\n",
      "val_loss: 0.13139800647340716\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.374520065352425\n",
      "val_loss: 0.1314509735325274\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.377957471972197\n",
      "val_loss: 0.1314112487223166\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.3770731969441212\n",
      "val_loss: 0.13149258507287254\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.375382169752804\n",
      "val_loss: 0.1315398749619801\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.3741681400790537\n",
      "val_loss: 0.13156635940607364\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.3712843650054385\n",
      "val_loss: 0.13146989646043522\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.3750462702955297\n",
      "val_loss: 0.13152095650209522\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.37169148146637\n",
      "val_loss: 0.13153231049090125\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.371755261800231\n",
      "val_loss: 0.13154554029878845\n",
      "best loss: 0.1310442881977918\n",
      "*********************************\n",
      "RC 2\n",
      "initial loss: 0.2065492881443781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4978b5471ba461999103ff59bce098b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.9029980957904082\n",
      "val_loss: 0.20543665021320207\n",
      "best loss: 0.20543665021320207\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.877357284011952\n",
      "val_loss: 0.20340919506740832\n",
      "best loss: 0.20340919506740832\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.8602327314346874\n",
      "val_loss: 0.20208088640660782\n",
      "best loss: 0.20208088640660782\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.8479147113873537\n",
      "val_loss: 0.20324984790641565\n",
      "best loss: 0.20208088640660782\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.8367257724708237\n",
      "val_loss: 0.20211796967859333\n",
      "best loss: 0.20208088640660782\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.8253941848390416\n",
      "val_loss: 0.2016825371850231\n",
      "best loss: 0.2016825371850231\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.8144508378494937\n",
      "val_loss: 0.2024064404382609\n",
      "best loss: 0.2016825371850231\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.8064072916028855\n",
      "val_loss: 0.20169489779198435\n",
      "best loss: 0.2016825371850231\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.800650081928838\n",
      "val_loss: 0.2016179770813551\n",
      "best loss: 0.2016179770813551\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.791859955361473\n",
      "val_loss: 0.20160287320846781\n",
      "best loss: 0.20160287320846781\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.784880403763191\n",
      "val_loss: 0.20153556435473405\n",
      "best loss: 0.20153556435473405\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.779635653722829\n",
      "val_loss: 0.20205891189420536\n",
      "best loss: 0.20153556435473405\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.770819441490502\n",
      "val_loss: 0.20170863585436702\n",
      "best loss: 0.20153556435473405\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.7658270071604227\n",
      "val_loss: 0.20117154607389903\n",
      "best loss: 0.20117154607389903\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.7576736043026586\n",
      "val_loss: 0.20183227398564174\n",
      "best loss: 0.20117154607389903\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.751252934028411\n",
      "val_loss: 0.2017072643361179\n",
      "best loss: 0.20117154607389903\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.746625245957293\n",
      "val_loss: 0.20173885446593556\n",
      "best loss: 0.20117154607389903\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.7403410795354084\n",
      "val_loss: 0.2022113879847778\n",
      "best loss: 0.20117154607389903\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.73481036446286\n",
      "val_loss: 0.2015850022569118\n",
      "best loss: 0.20117154607389903\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.728980836329133\n",
      "val_loss: 0.2025602902027721\n",
      "best loss: 0.20117154607389903\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.722176091825462\n",
      "val_loss: 0.2015767735096103\n",
      "best loss: 0.20117154607389903\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.7164118100237977\n",
      "val_loss: 0.2013707397341868\n",
      "best loss: 0.20117154607389903\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.7135671744802567\n",
      "val_loss: 0.2021028690060492\n",
      "best loss: 0.20117154607389903\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.7067037869509574\n",
      "val_loss: 0.20110012004970806\n",
      "best loss: 0.20110012004970806\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.702685373712473\n",
      "val_loss: 0.20206990117391324\n",
      "best loss: 0.20110012004970806\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.69608585287182\n",
      "val_loss: 0.2024545212318861\n",
      "best loss: 0.20110012004970806\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.6896969157203143\n",
      "val_loss: 0.20173336510874415\n",
      "best loss: 0.20110012004970806\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.6866713563457782\n",
      "val_loss: 0.20098885812764988\n",
      "best loss: 0.20098885812764988\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.681915892596157\n",
      "val_loss: 0.2008501212733851\n",
      "best loss: 0.2008501212733851\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.677052311090272\n",
      "val_loss: 0.20203006519102967\n",
      "best loss: 0.2008501212733851\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.672804157965485\n",
      "val_loss: 0.20117842320959844\n",
      "best loss: 0.2008501212733851\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.6661775015918625\n",
      "val_loss: 0.20034051129900882\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.659874693348445\n",
      "val_loss: 0.2004421550007526\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.6565151304694514\n",
      "val_loss: 0.2020012032873885\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.6504641607641855\n",
      "val_loss: 0.20128144471381687\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.6446192736601937\n",
      "val_loss: 0.2011578226040564\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.641108434018021\n",
      "val_loss: 0.2016015015458073\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.6401620478885195\n",
      "val_loss: 0.2015286924714174\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.6311362672827245\n",
      "val_loss: 0.2011166084926079\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.6268410168538665\n",
      "val_loss: 0.20142704504059833\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.6209232411197614\n",
      "val_loss: 0.20098061799746839\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.6160029423667317\n",
      "val_loss: 0.2013377554938867\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 42\n",
      "Train_loss: 2.614142604782415\n",
      "val_loss: 0.2008858397189599\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.599717219392852\n",
      "val_loss: 0.20094214624588078\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 2.600841114820765\n",
      "val_loss: 0.20101358839523611\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 45\n",
      "Train_loss: 2.5992956231718503\n",
      "val_loss: 0.2009737532531996\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 2.598164867471329\n",
      "val_loss: 0.2012017611136144\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 2.5976235211289724\n",
      "val_loss: 0.20108364526882633\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 2.597244287716765\n",
      "val_loss: 0.20115231683404244\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 2.595056173788482\n",
      "val_loss: 0.20107540145615388\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 2.5967455740980396\n",
      "val_loss: 0.20119352594000514\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 51\n",
      "Train_loss: 2.5945406394210977\n",
      "val_loss: 0.20105754319067437\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "epoch 52\n",
      "Train_loss: 2.596175693385763\n",
      "val_loss: 0.20094490411948673\n",
      "best loss: 0.20034051129900882\n",
      "*********************************\n",
      "RC 3\n",
      "initial loss: 0.22275845456220644\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8509ff7931c942bd940e5a6b22771800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.863224666276131\n",
      "val_loss: 0.22198739229538525\n",
      "best loss: 0.22198739229538525\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.8362160600912567\n",
      "val_loss: 0.22162201392945782\n",
      "best loss: 0.22162201392945782\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.8160805672152542\n",
      "val_loss: 0.22146641554784025\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.8006010041305682\n",
      "val_loss: 0.2216234009762921\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.7868233877810513\n",
      "val_loss: 0.22155670317766415\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.7749603087367136\n",
      "val_loss: 0.22162478488788415\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.7649095971502424\n",
      "val_loss: 0.22177343683892004\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.755281739284025\n",
      "val_loss: 0.2215261514499282\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.7465253005949517\n",
      "val_loss: 0.2221110430026086\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.7391753876229523\n",
      "val_loss: 0.22203741187710369\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.7315405071832006\n",
      "val_loss: 0.22225691924273627\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.72383238586626\n",
      "val_loss: 0.22171788273601054\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.717603069339625\n",
      "val_loss: 0.22225692256320134\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 13\n",
      "Train_loss: 2.709749754588197\n",
      "val_loss: 0.22234304935995106\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.70010211340578\n",
      "val_loss: 0.22213465984482786\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.699362147148656\n",
      "val_loss: 0.22196100056854592\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.6979436550023648\n",
      "val_loss: 0.22211520440342458\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.697179346169944\n",
      "val_loss: 0.22212354522173042\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.696255684868909\n",
      "val_loss: 0.22193044048782026\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.695196034255564\n",
      "val_loss: 0.22192349095085456\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.6950571287703715\n",
      "val_loss: 0.22185541245891788\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.693280680011244\n",
      "val_loss: 0.22187070234332884\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.692821338019874\n",
      "val_loss: 0.22186514551147482\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.6923066871461425\n",
      "val_loss: 0.221660921447923\n",
      "best loss: 0.22146641554784025\n",
      "*********************************\n",
      "RC 4\n",
      "initial loss: 0.08434597010901985\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ac0295059d4f03883bcae70481700f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.298091469369275\n",
      "val_loss: 0.08360019045787359\n",
      "best loss: 0.08360019045787359\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.2849968170441692\n",
      "val_loss: 0.08351859645505949\n",
      "best loss: 0.08351859645505949\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.272494333672835\n",
      "val_loss: 0.08334110151334113\n",
      "best loss: 0.08334110151334113\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.2632980288396283\n",
      "val_loss: 0.08330960764322289\n",
      "best loss: 0.08330960764322289\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.254164466574615\n",
      "val_loss: 0.08320081887953958\n",
      "best loss: 0.08320081887953958\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.24912774700457\n",
      "val_loss: 0.08303906636518275\n",
      "best loss: 0.08303906636518275\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.2427601226687153\n",
      "val_loss: 0.08297035714550616\n",
      "best loss: 0.08297035714550616\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.235931052882792\n",
      "val_loss: 0.08305910572318911\n",
      "best loss: 0.08297035714550616\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.2288045618174936\n",
      "val_loss: 0.08307771920955162\n",
      "best loss: 0.08297035714550616\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.2231162182452824\n",
      "val_loss: 0.0830605386060822\n",
      "best loss: 0.08297035714550616\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.2188213607835685\n",
      "val_loss: 0.08315501000744395\n",
      "best loss: 0.08297035714550616\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.2125826110357965\n",
      "val_loss: 0.0832566444160758\n",
      "best loss: 0.08297035714550616\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.208579794224071\n",
      "val_loss: 0.08312781371877564\n",
      "best loss: 0.08297035714550616\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.2016849446800983\n",
      "val_loss: 0.0830075751254397\n",
      "best loss: 0.08297035714550616\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.195969068319691\n",
      "val_loss: 0.08294459273970596\n",
      "best loss: 0.08294459273970596\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.189547586322036\n",
      "val_loss: 0.08290451139240781\n",
      "best loss: 0.08290451139240781\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.186258128634937\n",
      "val_loss: 0.08319796017415435\n",
      "best loss: 0.08290451139240781\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.1831847542133507\n",
      "val_loss: 0.08312924711351405\n",
      "best loss: 0.08290451139240781\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.1777113019322574\n",
      "val_loss: 0.0830218915318818\n",
      "best loss: 0.08290451139240781\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.173497438873347\n",
      "val_loss: 0.0829173940058916\n",
      "best loss: 0.08290451139240781\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.170476215190574\n",
      "val_loss: 0.08293027988310986\n",
      "best loss: 0.08290451139240781\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.1622311616768375\n",
      "val_loss: 0.08297751478780603\n",
      "best loss: 0.08290451139240781\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.158597951173818\n",
      "val_loss: 0.08278570258813765\n",
      "best loss: 0.08278570258813765\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.1539178380038035\n",
      "val_loss: 0.08278141042536075\n",
      "best loss: 0.08278141042536075\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.149590850930581\n",
      "val_loss: 0.0830476527208237\n",
      "best loss: 0.08278141042536075\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.144404808488455\n",
      "val_loss: 0.08279000053625331\n",
      "best loss: 0.08278141042536075\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.138776961126602\n",
      "val_loss: 0.0827155651460303\n",
      "best loss: 0.0827155651460303\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.138416100293974\n",
      "val_loss: 0.08294029891077698\n",
      "best loss: 0.0827155651460303\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.1301664107409617\n",
      "val_loss: 0.08295890576241666\n",
      "best loss: 0.0827155651460303\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.126931674581073\n",
      "val_loss: 0.08270840513398069\n",
      "best loss: 0.08270840513398069\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.124946009324967\n",
      "val_loss: 0.08284582258847915\n",
      "best loss: 0.08270840513398069\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.124332888076522\n",
      "val_loss: 0.08313354080333155\n",
      "best loss: 0.08270840513398069\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.11295789768496\n",
      "val_loss: 0.0832409015375501\n",
      "best loss: 0.08270840513398069\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.1112066094949142\n",
      "val_loss: 0.08282148842078507\n",
      "best loss: 0.08270840513398069\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.102300060441884\n",
      "val_loss: 0.08296463214989809\n",
      "best loss: 0.08270840513398069\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.100564823573191\n",
      "val_loss: 0.08291166983858093\n",
      "best loss: 0.08270840513398069\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.097960148562921\n",
      "val_loss: 0.08304765648487407\n",
      "best loss: 0.08270840513398069\n",
      "*********************************\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 37\n",
      "Train_loss: 2.092703039389148\n",
      "val_loss: 0.08341410650146726\n",
      "best loss: 0.08270840513398069\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.0792057951872045\n",
      "val_loss: 0.08277138722965864\n",
      "best loss: 0.08270840513398069\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.0760863946654506\n",
      "val_loss: 0.08281289836920833\n",
      "best loss: 0.08270840513398069\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.07746577043623\n",
      "val_loss: 0.08278856678440646\n",
      "best loss: 0.08270840513398069\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.0759509753969954\n",
      "val_loss: 0.08270267946905978\n",
      "best loss: 0.08270267946905978\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.075566128788404\n",
      "val_loss: 0.08268693784799873\n",
      "best loss: 0.08268693784799873\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.0748948095164876\n",
      "val_loss: 0.08269695568070275\n",
      "best loss: 0.08268693784799873\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 2.0739325620929163\n",
      "val_loss: 0.0827084125049173\n",
      "best loss: 0.08268693784799873\n",
      "*********************************\n",
      "epoch 45\n",
      "Train_loss: 2.074030181997486\n",
      "val_loss: 0.08267119109604491\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 2.0723147929906007\n",
      "val_loss: 0.08272558251679923\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 2.074377016922818\n",
      "val_loss: 0.0827542111543667\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 2.0727127129718035\n",
      "val_loss: 0.08269265699728352\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 2.0728489797260994\n",
      "val_loss: 0.08271270048888833\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 2.0713441709167753\n",
      "val_loss: 0.08274705542701152\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 51\n",
      "Train_loss: 2.0706685234949305\n",
      "val_loss: 0.08272701395957745\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 52\n",
      "Train_loss: 2.069759145828023\n",
      "val_loss: 0.08274848864987064\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 53\n",
      "Train_loss: 2.0712819969745544\n",
      "val_loss: 0.0827212884915668\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 54\n",
      "Train_loss: 2.0682618221522047\n",
      "val_loss: 0.08268836736657839\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 55\n",
      "Train_loss: 2.0689196792751923\n",
      "val_loss: 0.08270554074247034\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 56\n",
      "Train_loss: 2.070394785816985\n",
      "val_loss: 0.08267834554272488\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 57\n",
      "Train_loss: 2.0660695354462573\n",
      "val_loss: 0.08267691518189117\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 58\n",
      "Train_loss: 2.0648112706017328\n",
      "val_loss: 0.08271413021408723\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 59\n",
      "Train_loss: 2.0651467927169835\n",
      "val_loss: 0.08269695561091946\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 60\n",
      "Train_loss: 2.0666009064743385\n",
      "val_loss: 0.08268979752215819\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61\n",
      "Train_loss: 2.066555097100021\n",
      "val_loss: 0.08267548408287155\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 62\n",
      "Train_loss: 2.0665150755207846\n",
      "val_loss: 0.08268407217353765\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 63\n",
      "Train_loss: 2.0660372259979045\n",
      "val_loss: 0.08270411134328082\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 64\n",
      "Train_loss: 2.0664727537494922\n",
      "val_loss: 0.08270411380359714\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 65\n",
      "Train_loss: 2.064199784463484\n",
      "val_loss: 0.08268979809680846\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "epoch 66\n",
      "Train_loss: 2.0663071142743137\n",
      "val_loss: 0.0827084091528918\n",
      "best loss: 0.08267119109604491\n",
      "*********************************\n",
      "RC 5\n",
      "initial loss: 0.08777280055309668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c037d174a61946e3ad2acb0b7b62a5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.2465580045131133\n",
      "val_loss: 0.08721433140283676\n",
      "best loss: 0.08721433140283676\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.2283364840658058\n",
      "val_loss: 0.08715793508807067\n",
      "best loss: 0.08715793508807067\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.2137911945943523\n",
      "val_loss: 0.08673839501033763\n",
      "best loss: 0.08673839501033763\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.203138576871024\n",
      "val_loss: 0.08663936102041471\n",
      "best loss: 0.08663936102041471\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.1927159067509345\n",
      "val_loss: 0.08657333221984886\n",
      "best loss: 0.08657333221984886\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.185965205808691\n",
      "val_loss: 0.08661322441283635\n",
      "best loss: 0.08657333221984886\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.1775434337971404\n",
      "val_loss: 0.08665448948998987\n",
      "best loss: 0.08657333221984886\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.1696563106444104\n",
      "val_loss: 0.08657058030885868\n",
      "best loss: 0.08657058030885868\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.165697903001525\n",
      "val_loss: 0.08680304580802575\n",
      "best loss: 0.08657058030885868\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.1584634394723845\n",
      "val_loss: 0.08651005696750871\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.152681615675623\n",
      "val_loss: 0.08661047364241521\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.148038342816791\n",
      "val_loss: 0.08666824652545525\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.140201563012199\n",
      "val_loss: 0.086713632979265\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.1372099998506653\n",
      "val_loss: 0.0867301467834892\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.1310462692548606\n",
      "val_loss: 0.08665999132574156\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.1239633937091043\n",
      "val_loss: 0.08657471016077083\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.1200868671216453\n",
      "val_loss: 0.0869502274491147\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.114672343115182\n",
      "val_loss: 0.08681817539732366\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.1096460722247325\n",
      "val_loss: 0.08679754982002279\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.1049923474163483\n",
      "val_loss: 0.08681130119827163\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 20\n",
      "Train_loss: 2.1006864294947922\n",
      "val_loss: 0.08672739032669585\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.0898624256178517\n",
      "val_loss: 0.08652244465582577\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.0882606502492047\n",
      "val_loss: 0.08655270311690101\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.0869689732614067\n",
      "val_loss: 0.08659121624137177\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.085817085715872\n",
      "val_loss: 0.08655820350259645\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.086019877475642\n",
      "val_loss: 0.08653757268063149\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.0855823262480198\n",
      "val_loss: 0.08654169974365993\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.0851161980443313\n",
      "val_loss: 0.08653894684487633\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.0832045985695467\n",
      "val_loss: 0.0865609551390862\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.0819958594217907\n",
      "val_loss: 0.08653894745510408\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.0833181648014008\n",
      "val_loss: 0.0865637059170878\n",
      "best loss: 0.08651005696750871\n",
      "*********************************\n",
      "RC 6\n",
      "initial loss: 0.1344488024143382\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a232e2c8719e4d9f8cdab14e4b0b7420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.4425815350268474\n",
      "val_loss: 0.1337474747637227\n",
      "best loss: 0.1337474747637227\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.412661140705347\n",
      "val_loss: 0.13309071691615118\n",
      "best loss: 0.13309071691615118\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.3938118063912346\n",
      "val_loss: 0.13303858191359544\n",
      "best loss: 0.13303858191359544\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.3789017552932155\n",
      "val_loss: 0.13320340261940583\n",
      "best loss: 0.13303858191359544\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.366728631648255\n",
      "val_loss: 0.1329847626453665\n",
      "best loss: 0.1329847626453665\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.3565340044407956\n",
      "val_loss: 0.13296205952058798\n",
      "best loss: 0.13296205952058798\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.34670436435907\n",
      "val_loss: 0.13276949178836783\n",
      "best loss: 0.13276949178836783\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.339588289320473\n",
      "val_loss: 0.13261223478521567\n",
      "best loss: 0.13261223478521567\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.3304256599593085\n",
      "val_loss: 0.13293347054238822\n",
      "best loss: 0.13261223478521567\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.323186476026061\n",
      "val_loss: 0.1325163762193086\n",
      "best loss: 0.1325163762193086\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.3155048256425745\n",
      "val_loss: 0.132475170428532\n",
      "best loss: 0.132475170428532\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.3089132948595963\n",
      "val_loss: 0.13250460719621507\n",
      "best loss: 0.132475170428532\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.30252409570827\n",
      "val_loss: 0.13224896681403997\n",
      "best loss: 0.13224896681403997\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.294580898396501\n",
      "val_loss: 0.1322649400713786\n",
      "best loss: 0.13224896681403997\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.2886987305577478\n",
      "val_loss: 0.1325727169103638\n",
      "best loss: 0.13224896681403997\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.282181160499367\n",
      "val_loss: 0.13211021554901828\n",
      "best loss: 0.13211021554901828\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.276859152871944\n",
      "val_loss: 0.13216740102720503\n",
      "best loss: 0.13211021554901828\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.270135933788104\n",
      "val_loss: 0.13204966465047377\n",
      "best loss: 0.13204966465047377\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.2656619991575786\n",
      "val_loss: 0.13200510213768415\n",
      "best loss: 0.13200510213768415\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.2572504627532166\n",
      "val_loss: 0.13199416816156875\n",
      "best loss: 0.13199416816156875\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.2528405982412503\n",
      "val_loss: 0.13171665854312703\n",
      "best loss: 0.13171665854312703\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.247493287165233\n",
      "val_loss: 0.13221111907066377\n",
      "best loss: 0.13171665854312703\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.242384053980605\n",
      "val_loss: 0.13181421562538417\n",
      "best loss: 0.13171665854312703\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.2377715823355153\n",
      "val_loss: 0.13206059929659067\n",
      "best loss: 0.13171665854312703\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.2318321163073818\n",
      "val_loss: 0.13176375486138295\n",
      "best loss: 0.13171665854312703\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.226882086820306\n",
      "val_loss: 0.13162248297409676\n",
      "best loss: 0.13162248297409676\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.2197514871765494\n",
      "val_loss: 0.13170152861215986\n",
      "best loss: 0.13162248297409676\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.215083505396901\n",
      "val_loss: 0.13133320382573807\n",
      "best loss: 0.13133320382573807\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.209702711753315\n",
      "val_loss: 0.1315425938471971\n",
      "best loss: 0.13133320382573807\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.205023348871924\n",
      "val_loss: 0.1310834542990026\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.1994787867280072\n",
      "val_loss: 0.1315653028879159\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.1962058177262973\n",
      "val_loss: 0.13133572942533478\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.19007702007359\n",
      "val_loss: 0.13150306979056103\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.1853762909997334\n",
      "val_loss: 0.13133153069235629\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.1812562540841003\n",
      "val_loss: 0.13180243642545098\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.176390106968927\n",
      "val_loss: 0.13146438650817713\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.1725127882742634\n",
      "val_loss: 0.13146018939664145\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.1681948578648416\n",
      "val_loss: 0.13138534729965085\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.1631601955734814\n",
      "val_loss: 0.13164854734977044\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.160455682738094\n",
      "val_loss: 0.13208834652966886\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 40\n",
      "Train_loss: 2.153922345298685\n",
      "val_loss: 0.1317696434687795\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.140755692162251\n",
      "val_loss: 0.1315039138728453\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.138812179265008\n",
      "val_loss: 0.13141898325161427\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.138240447432178\n",
      "val_loss: 0.13141982606884517\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 2.136722970208038\n",
      "val_loss: 0.13137525256287994\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 45\n",
      "Train_loss: 2.137041420003072\n",
      "val_loss: 0.13138618632163251\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 2.136690980644166\n",
      "val_loss: 0.13142654761509465\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 2.135277209408061\n",
      "val_loss: 0.1313298451691158\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 2.1355081056537175\n",
      "val_loss: 0.13136684412513605\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 2.1352391404097064\n",
      "val_loss: 0.1313735752030881\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 2.134279074564303\n",
      "val_loss: 0.1313575911164649\n",
      "best loss: 0.1310834542990026\n",
      "*********************************\n",
      "RC 7\n",
      "initial loss: 0.1439910371780862\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab398f646364cc9b49319eecd91121f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.359633783689153\n",
      "val_loss: 0.14304549512545994\n",
      "best loss: 0.14304549512545994\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.3466238492789637\n",
      "val_loss: 0.14233491550728156\n",
      "best loss: 0.14233491550728156\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.334655339598733\n",
      "val_loss: 0.14215917687722618\n",
      "best loss: 0.14215917687722618\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.323437822568578\n",
      "val_loss: 0.14214771857215727\n",
      "best loss: 0.14214771857215727\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.316895154955645\n",
      "val_loss: 0.14169310331231239\n",
      "best loss: 0.14169310331231239\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.3133929640271687\n",
      "val_loss: 0.14162051340277823\n",
      "best loss: 0.14162051340277823\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.302938204261066\n",
      "val_loss: 0.1425622212620076\n",
      "best loss: 0.14162051340277823\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.30001761012467\n",
      "val_loss: 0.14171410290288117\n",
      "best loss: 0.14162051340277823\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.2900571573750867\n",
      "val_loss: 0.1419987298115811\n",
      "best loss: 0.14162051340277823\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.2860693983473572\n",
      "val_loss: 0.14150207498798215\n",
      "best loss: 0.14150207498798215\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.280856926271739\n",
      "val_loss: 0.14143140400823542\n",
      "best loss: 0.14143140400823542\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.2793721052250135\n",
      "val_loss: 0.1424246978250752\n",
      "best loss: 0.14143140400823542\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.273293394180403\n",
      "val_loss: 0.1413607231202935\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.2671239949803375\n",
      "val_loss: 0.14138747240593738\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.2623978996685103\n",
      "val_loss: 0.14143713471084857\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.259015306472473\n",
      "val_loss: 0.1428239181764896\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.2539087935297872\n",
      "val_loss: 0.14148297362250617\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.246833757090282\n",
      "val_loss: 0.14201209152986038\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.245824854696323\n",
      "val_loss: 0.14161859257046508\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.237454288321107\n",
      "val_loss: 0.1420426480719064\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.234992119074598\n",
      "val_loss: 0.14260806727564512\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.2309311445527436\n",
      "val_loss: 0.14225850543583196\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.227023404195504\n",
      "val_loss: 0.1419987187081835\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 23\n",
      "Train_loss: 2.2179527959149996\n",
      "val_loss: 0.142464803887452\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.2111489053009863\n",
      "val_loss: 0.14171028356327464\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.2106050695910375\n",
      "val_loss: 0.14198153230306274\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.2110307685956387\n",
      "val_loss: 0.1417083746416875\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.2097461563740315\n",
      "val_loss: 0.14178096018014957\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.2112609479680594\n",
      "val_loss: 0.14176185681011844\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.2058670345470053\n",
      "val_loss: 0.14176568464043932\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.211433866571273\n",
      "val_loss: 0.14177904975686678\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.2102554117351336\n",
      "val_loss: 0.1418096110902491\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.2081739080141265\n",
      "val_loss: 0.14180579039591795\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.207120133974141\n",
      "val_loss: 0.14181915727154404\n",
      "best loss: 0.1413607231202935\n",
      "*********************************\n",
      "RC 8\n",
      "initial loss: 0.1389115700529591\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5a59923fba457095b68a8cdedc29d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.3322182063363766\n",
      "val_loss: 0.13794329356829357\n",
      "best loss: 0.13794329356829357\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.308118819798442\n",
      "val_loss: 0.1374316714202153\n",
      "best loss: 0.1374316714202153\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.29718847995026\n",
      "val_loss: 0.13781785346334613\n",
      "best loss: 0.1374316714202153\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.2879589873378627\n",
      "val_loss: 0.13797147866299656\n",
      "best loss: 0.1374316714202153\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.27669860348091\n",
      "val_loss: 0.13763885912100793\n",
      "best loss: 0.1374316714202153\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.268691504675491\n",
      "val_loss: 0.13735556674474417\n",
      "best loss: 0.13735556674474417\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.261854059250981\n",
      "val_loss: 0.136867897009362\n",
      "best loss: 0.136867897009362\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.2537864133134473\n",
      "val_loss: 0.1369510536247143\n",
      "best loss: 0.136867897009362\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.2482193805384934\n",
      "val_loss: 0.1366635329334279\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.241633217118238\n",
      "val_loss: 0.13709622497738316\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.2359154464773043\n",
      "val_loss: 0.13717938235691288\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.2307413307349817\n",
      "val_loss: 0.13694259882236157\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.2266943804413764\n",
      "val_loss: 0.13681998005213025\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.218401052284816\n",
      "val_loss: 0.13729777554499692\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.2158025303628253\n",
      "val_loss: 0.13734851369534193\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.2102286404149023\n",
      "val_loss: 0.13771920039855487\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.204551932190079\n",
      "val_loss: 0.1372103881852667\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.1973752815333256\n",
      "val_loss: 0.13704830835533793\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.1935342647174747\n",
      "val_loss: 0.1369017286248559\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 19\n",
      "Train_loss: 2.1877896295256365\n",
      "val_loss: 0.1371229987755812\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.179509735212602\n",
      "val_loss: 0.13700320300763383\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.1771800028719905\n",
      "val_loss: 0.1371075026535615\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.17587346653981\n",
      "val_loss: 0.13687353435345143\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.1753244772892417\n",
      "val_loss: 0.13690454007784367\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.1761389354235057\n",
      "val_loss: 0.13699615460244674\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.1748915894384617\n",
      "val_loss: 0.13693414307957472\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.175450226469919\n",
      "val_loss: 0.1369031382233215\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.174762924604543\n",
      "val_loss: 0.1369651472074993\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.1730203929090677\n",
      "val_loss: 0.13709059399825244\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.173379909108916\n",
      "val_loss: 0.1370201151378889\n",
      "best loss: 0.1366635329334279\n",
      "*********************************\n",
      "fold 0, score: 0.13952731912267932\n",
      "fold: 1\n",
      "RC 0\n",
      "initial loss: 0.13219816358031364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135dc0151d93404397dc82a749d1a6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.5394796615387802\n",
      "val_loss: 0.1320091488111852\n",
      "best loss: 0.1320091488111852\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.522145614117154\n",
      "val_loss: 0.13179560508690644\n",
      "best loss: 0.13179560508690644\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.5070713287653494\n",
      "val_loss: 0.1316267898008527\n",
      "best loss: 0.1316267898008527\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.4946091725815376\n",
      "val_loss: 0.13108571161490856\n",
      "best loss: 0.13108571161490856\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.4846233453254527\n",
      "val_loss: 0.13151424196923017\n",
      "best loss: 0.13108571161490856\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.4765119073669415\n",
      "val_loss: 0.1313714016497737\n",
      "best loss: 0.13108571161490856\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.4666475146957696\n",
      "val_loss: 0.13144498387948456\n",
      "best loss: 0.13108571161490856\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.4600143899995586\n",
      "val_loss: 0.131084268964205\n",
      "best loss: 0.131084268964205\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.452969465212638\n",
      "val_loss: 0.13186341912158653\n",
      "best loss: 0.131084268964205\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.446738825811609\n",
      "val_loss: 0.13119970086719462\n",
      "best loss: 0.131084268964205\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.439886984898786\n",
      "val_loss: 0.13159360683516771\n",
      "best loss: 0.131084268964205\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.4339073307809214\n",
      "val_loss: 0.13156474999243642\n",
      "best loss: 0.131084268964205\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.4288532162706953\n",
      "val_loss: 0.13116074042368303\n",
      "best loss: 0.131084268964205\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.4225595800523214\n",
      "val_loss: 0.13111024152301878\n",
      "best loss: 0.131084268964205\n",
      "*********************************\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 14\n",
      "Train_loss: 2.417178467965254\n",
      "val_loss: 0.13173789534601277\n",
      "best loss: 0.131084268964205\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.4077619035072084\n",
      "val_loss: 0.13124587196040483\n",
      "best loss: 0.131084268964205\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.4068147921996754\n",
      "val_loss: 0.13115785806158836\n",
      "best loss: 0.131084268964205\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.405628701743673\n",
      "val_loss: 0.1311059098193166\n",
      "best loss: 0.131084268964205\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.405855254703193\n",
      "val_loss: 0.13106406889118816\n",
      "best loss: 0.13106406889118816\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.404114644649072\n",
      "val_loss: 0.13105685232096623\n",
      "best loss: 0.13105685232096623\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.4038638366977354\n",
      "val_loss: 0.13109870050241623\n",
      "best loss: 0.13105685232096623\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.4036365420789068\n",
      "val_loss: 0.13114199639204668\n",
      "best loss: 0.13105685232096623\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.403831271107782\n",
      "val_loss: 0.13111313167608055\n",
      "best loss: 0.13105685232096623\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.401699533693364\n",
      "val_loss: 0.13102944131597158\n",
      "best loss: 0.13102944131597158\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.401999300616678\n",
      "val_loss: 0.13108427214206328\n",
      "best loss: 0.13102944131597158\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.4014741781848508\n",
      "val_loss: 0.13102367253283367\n",
      "best loss: 0.13102367253283367\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.3992976799926153\n",
      "val_loss: 0.13108716046841468\n",
      "best loss: 0.13102367253283367\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.399889742295297\n",
      "val_loss: 0.1311174599275968\n",
      "best loss: 0.13102367253283367\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.3986157386638345\n",
      "val_loss: 0.1311087961005965\n",
      "best loss: 0.13102367253283367\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.3975634881821923\n",
      "val_loss: 0.13105974065863327\n",
      "best loss: 0.13102367253283367\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.397706868326473\n",
      "val_loss: 0.1310857169620045\n",
      "best loss: 0.13102367253283367\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.3970581639988318\n",
      "val_loss: 0.1311362148864659\n",
      "best loss: 0.13102367253283367\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.395885441347619\n",
      "val_loss: 0.130963072881094\n",
      "best loss: 0.130963072881094\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.3955055067473126\n",
      "val_loss: 0.13110446937302095\n",
      "best loss: 0.130963072881094\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.3946038416576774\n",
      "val_loss: 0.13109581347002291\n",
      "best loss: 0.130963072881094\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.3938701820128023\n",
      "val_loss: 0.1310453172817468\n",
      "best loss: 0.130963072881094\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.3938482781045862\n",
      "val_loss: 0.13097028549940712\n",
      "best loss: 0.130963072881094\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.3933350165129466\n",
      "val_loss: 0.130888040948287\n",
      "best loss: 0.130888040948287\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.391659433970938\n",
      "val_loss: 0.13112178514591138\n",
      "best loss: 0.130888040948287\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.3905591036774343\n",
      "val_loss: 0.13113765611384617\n",
      "best loss: 0.130888040948287\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.3898298305985075\n",
      "val_loss: 0.13100202672820246\n",
      "best loss: 0.130888040948287\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.3899999707652806\n",
      "val_loss: 0.1308274436431652\n",
      "best loss: 0.1308274436431652\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.389196494771277\n",
      "val_loss: 0.1311131296722958\n",
      "best loss: 0.1308274436431652\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.388221485853061\n",
      "val_loss: 0.13100635791444376\n",
      "best loss: 0.1308274436431652\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 2.3881420327751695\n",
      "val_loss: 0.1310323291689013\n",
      "best loss: 0.1308274436431652\n",
      "*********************************\n",
      "epoch 45\n",
      "Train_loss: 2.3863915885712816\n",
      "val_loss: 0.13099336643871412\n",
      "best loss: 0.1308274436431652\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 2.385985674463179\n",
      "val_loss: 0.13122278260012515\n",
      "best loss: 0.1308274436431652\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 2.3860981572797204\n",
      "val_loss: 0.13082311853280787\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 2.3840908457960315\n",
      "val_loss: 0.13113765731697336\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 2.3835474981038702\n",
      "val_loss: 0.13095873847601353\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 2.383537844965513\n",
      "val_loss: 0.131091485863192\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 51\n",
      "Train_loss: 2.3812660499681475\n",
      "val_loss: 0.13099625950386964\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 52\n",
      "Train_loss: 2.3811103316603894\n",
      "val_loss: 0.13108715472985896\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 53\n",
      "Train_loss: 2.3798508955114706\n",
      "val_loss: 0.13101357176983094\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 54\n",
      "Train_loss: 2.3795257807774277\n",
      "val_loss: 0.1309904831285528\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 55\n",
      "Train_loss: 2.379513134915548\n",
      "val_loss: 0.13100924010863887\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 56\n",
      "Train_loss: 2.3803010262323987\n",
      "val_loss: 0.13101212758815267\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 57\n",
      "Train_loss: 2.379444501222798\n",
      "val_loss: 0.13101501374067898\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 58\n",
      "Train_loss: 2.379494226206838\n",
      "val_loss: 0.13102222923775061\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 59\n",
      "Train_loss: 2.3795479677401827\n",
      "val_loss: 0.13100202590736024\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 60\n",
      "Train_loss: 2.380165498803101\n",
      "val_loss: 0.13101646072924622\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61\n",
      "Train_loss: 2.3790211854564443\n",
      "val_loss: 0.13102655113232703\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 62\n",
      "Train_loss: 2.379105977731397\n",
      "val_loss: 0.13102511805893166\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 63\n",
      "Train_loss: 2.3793664940774932\n",
      "val_loss: 0.1310078010694576\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 64\n",
      "Train_loss: 2.3791584645742354\n",
      "val_loss: 0.1310164582651904\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 65\n",
      "Train_loss: 2.3786689722223717\n",
      "val_loss: 0.13101789793988214\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 66\n",
      "Train_loss: 2.3783512097323976\n",
      "val_loss: 0.13104098631447833\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 67\n",
      "Train_loss: 2.3790035650074586\n",
      "val_loss: 0.13099336899512998\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "epoch 68\n",
      "Train_loss: 2.37838215847917\n",
      "val_loss: 0.13097028152486706\n",
      "best loss: 0.13082311853280787\n",
      "*********************************\n",
      "RC 1\n",
      "initial loss: 0.12361042935319574\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32c82a9f5134ee5a9af61908e5c43c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.420536829673506\n",
      "val_loss: 0.12285628137745225\n",
      "best loss: 0.12285628137745225\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.408471677985212\n",
      "val_loss: 0.12279012676191708\n",
      "best loss: 0.12279012676191708\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.3946849566676662\n",
      "val_loss: 0.12244235361266607\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.3820513452095398\n",
      "val_loss: 0.12285817348820048\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.3716686590829505\n",
      "val_loss: 0.12269751035425192\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.3604817362189947\n",
      "val_loss: 0.12292999980418108\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.355750789612596\n",
      "val_loss: 0.12290354435771428\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.3474701710417327\n",
      "val_loss: 0.12277123349691081\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.3382446920364712\n",
      "val_loss: 0.12258978156248461\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.3353287768666102\n",
      "val_loss: 0.12283171173473058\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.3276760837753647\n",
      "val_loss: 0.12286195966573729\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.3212312554493066\n",
      "val_loss: 0.12255575658693671\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.3125796500961817\n",
      "val_loss: 0.12245369583312214\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 13\n",
      "Train_loss: 2.307807639065583\n",
      "val_loss: 0.12300370976054423\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.300774654256467\n",
      "val_loss: 0.12280525409245077\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.2986882889281754\n",
      "val_loss: 0.12264270628531432\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.297514082191123\n",
      "val_loss: 0.12263892575375318\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.2979330039185966\n",
      "val_loss: 0.12262380253020307\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.294168850276226\n",
      "val_loss: 0.12260867544825575\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.295232976349532\n",
      "val_loss: 0.1225255159404525\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.2971097362967536\n",
      "val_loss: 0.12259923787984112\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.293754271109775\n",
      "val_loss: 0.1226067873603603\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.2955866706098744\n",
      "val_loss: 0.122625693650612\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.291161750819291\n",
      "val_loss: 0.12257466474148611\n",
      "best loss: 0.12244235361266607\n",
      "*********************************\n",
      "RC 2\n",
      "initial loss: 0.20237348128848565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e78df50e20746738e0451e232ec675c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.8265859252409764\n",
      "val_loss: 0.2015210063623036\n",
      "best loss: 0.2015210063623036\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.801085857793164\n",
      "val_loss: 0.20160062935266526\n",
      "best loss: 0.2015210063623036\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.787339268658367\n",
      "val_loss: 0.20099936725670206\n",
      "best loss: 0.20099936725670206\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.7716377188163803\n",
      "val_loss: 0.20085797394453028\n",
      "best loss: 0.20085797394453028\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.7609371533108624\n",
      "val_loss: 0.20050792552549243\n",
      "best loss: 0.20050792552549243\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.7477997810329655\n",
      "val_loss: 0.1998009737438806\n",
      "best loss: 0.1998009737438806\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.740829755374888\n",
      "val_loss: 0.20024573127939624\n",
      "best loss: 0.1998009737438806\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.7314914355692275\n",
      "val_loss: 0.19965544815229955\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.7274552143627493\n",
      "val_loss: 0.19985450196903504\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.7173266706742196\n",
      "val_loss: 0.20000962742094747\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.710818873577433\n",
      "val_loss: 0.19990941043574006\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.704090035251213\n",
      "val_loss: 0.20013590638694526\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.6961590345919833\n",
      "val_loss: 0.20044066333566843\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.692968855142366\n",
      "val_loss: 0.2007701226498087\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.6871716775162433\n",
      "val_loss: 0.20016060707960784\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.6793183054359346\n",
      "val_loss: 0.2005244013014939\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.6743474689579867\n",
      "val_loss: 0.20000139083050258\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.6673597913561746\n",
      "val_loss: 0.19995607913786928\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 18\n",
      "Train_loss: 2.6621713168727243\n",
      "val_loss: 0.20022239432216327\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.6542694813372356\n",
      "val_loss: 0.2003816370429211\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.6522627234202547\n",
      "val_loss: 0.200118064464001\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.6535168729176646\n",
      "val_loss: 0.20024848052254157\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.650435758561794\n",
      "val_loss: 0.2001427764260068\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.650405770213694\n",
      "val_loss: 0.20026494910153797\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.649177792469014\n",
      "val_loss: 0.2002182788407123\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.650438406893515\n",
      "val_loss: 0.20038162570665607\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.648956633253964\n",
      "val_loss: 0.20010708345052747\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.646775765057569\n",
      "val_loss: 0.20008924843246004\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.6488402382706897\n",
      "val_loss: 0.20010434338672786\n",
      "best loss: 0.19965544815229955\n",
      "*********************************\n",
      "RC 3\n",
      "initial loss: 0.21183119833222167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b256ddbf62004feda826f4644d0ee8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.794888310278494\n",
      "val_loss: 0.2104968049513618\n",
      "best loss: 0.2104968049513618\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.7681642836739577\n",
      "val_loss: 0.20927905187396317\n",
      "best loss: 0.20927905187396317\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.749134115754169\n",
      "val_loss: 0.20880139266522815\n",
      "best loss: 0.20880139266522815\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.7335681393212696\n",
      "val_loss: 0.20844175157229372\n",
      "best loss: 0.20844175157229372\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.7202498678516607\n",
      "val_loss: 0.20834039452958666\n",
      "best loss: 0.20834039452958666\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.7089557278813974\n",
      "val_loss: 0.20815294125341224\n",
      "best loss: 0.20815294125341224\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.6989904745651816\n",
      "val_loss: 0.20877500302043328\n",
      "best loss: 0.20815294125341224\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.6895535004211437\n",
      "val_loss: 0.2084972974795163\n",
      "best loss: 0.20815294125341224\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.681303416675944\n",
      "val_loss: 0.20843481220806773\n",
      "best loss: 0.20815294125341224\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.6739393594998044\n",
      "val_loss: 0.20861115958258353\n",
      "best loss: 0.20815294125341224\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.665797962805185\n",
      "val_loss: 0.2085278468613047\n",
      "best loss: 0.20815294125341224\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.6586720998362616\n",
      "val_loss: 0.2083973205141957\n",
      "best loss: 0.20815294125341224\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.652273213221502\n",
      "val_loss: 0.20849730701296315\n",
      "best loss: 0.20815294125341224\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.645192412394879\n",
      "val_loss: 0.20808906652299683\n",
      "best loss: 0.20808906652299683\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.6382838941077713\n",
      "val_loss: 0.2084584247170054\n",
      "best loss: 0.20808906652299683\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.6321855507847904\n",
      "val_loss: 0.20831956703737511\n",
      "best loss: 0.20808906652299683\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.626213646809718\n",
      "val_loss: 0.20827929933752062\n",
      "best loss: 0.20808906652299683\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.6198288739427107\n",
      "val_loss: 0.20813628016265984\n",
      "best loss: 0.20808906652299683\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.614085739694021\n",
      "val_loss: 0.20854311391413977\n",
      "best loss: 0.20808906652299683\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.608694070511895\n",
      "val_loss: 0.20819876820419986\n",
      "best loss: 0.20808906652299683\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.602732055821194\n",
      "val_loss: 0.20873891034899505\n",
      "best loss: 0.20808906652299683\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.596382617085491\n",
      "val_loss: 0.20828069036371408\n",
      "best loss: 0.20808906652299683\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.5913596550357707\n",
      "val_loss: 0.20841814924635577\n",
      "best loss: 0.20808906652299683\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.5866150161591577\n",
      "val_loss: 0.20847369461586512\n",
      "best loss: 0.20808906652299683\n",
      "*********************************\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 24\n",
      "Train_loss: 2.5804532011531776\n",
      "val_loss: 0.208132110819818\n",
      "best loss: 0.20808906652299683\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.570606893428922\n",
      "val_loss: 0.20798770376028056\n",
      "best loss: 0.20798770376028056\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.5688972293383228\n",
      "val_loss: 0.2080876834721474\n",
      "best loss: 0.20798770376028056\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.5668686402081824\n",
      "val_loss: 0.20805019112607365\n",
      "best loss: 0.20798770376028056\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.568091726109084\n",
      "val_loss: 0.20800436943675274\n",
      "best loss: 0.20798770376028056\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.566489297162318\n",
      "val_loss: 0.2079835460222735\n",
      "best loss: 0.2079835460222735\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.564579293668663\n",
      "val_loss: 0.20801686440593942\n",
      "best loss: 0.2079835460222735\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.5646295939254635\n",
      "val_loss: 0.2079182786316286\n",
      "best loss: 0.2079182786316286\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.5647620710338828\n",
      "val_loss: 0.20794188718203144\n",
      "best loss: 0.2079182786316286\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.564444784441532\n",
      "val_loss: 0.20795160265407284\n",
      "best loss: 0.2079182786316286\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.5629505103828945\n",
      "val_loss: 0.20795715365065148\n",
      "best loss: 0.2079182786316286\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.5635275887363442\n",
      "val_loss: 0.20802380708356208\n",
      "best loss: 0.2079182786316286\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.5624589359448287\n",
      "val_loss: 0.20794328037703105\n",
      "best loss: 0.2079182786316286\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.561923026721891\n",
      "val_loss: 0.20799186499327652\n",
      "best loss: 0.2079182786316286\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.561470358099825\n",
      "val_loss: 0.2078891244099801\n",
      "best loss: 0.2078891244099801\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.560882999310357\n",
      "val_loss: 0.20793077071976712\n",
      "best loss: 0.2078891244099801\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.559863964471206\n",
      "val_loss: 0.20795022181352796\n",
      "best loss: 0.2078891244099801\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.5588613451222875\n",
      "val_loss: 0.20795854850588122\n",
      "best loss: 0.2078891244099801\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.558731772572567\n",
      "val_loss: 0.20792661426821032\n",
      "best loss: 0.2078891244099801\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.558015859098391\n",
      "val_loss: 0.20795437443339965\n",
      "best loss: 0.2078891244099801\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 2.557873042765451\n",
      "val_loss: 0.20810711775405497\n",
      "best loss: 0.2078891244099801\n",
      "*********************************\n",
      "epoch 45\n",
      "Train_loss: 2.557788244190387\n",
      "val_loss: 0.2078335779220743\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 2.5569760481637838\n",
      "val_loss: 0.20792939001696162\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 2.556035610976145\n",
      "val_loss: 0.20810295174521182\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 2.5556293091256697\n",
      "val_loss: 0.20800019539958894\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 2.5550389659569714\n",
      "val_loss: 0.20812239983754974\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 2.553529743326545\n",
      "val_loss: 0.20801408574641422\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 51\n",
      "Train_loss: 2.5530840906934857\n",
      "val_loss: 0.2079668893174011\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 52\n",
      "Train_loss: 2.552520051839445\n",
      "val_loss: 0.20790439153462795\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 53\n",
      "Train_loss: 2.5513195359134015\n",
      "val_loss: 0.20800298683208462\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 54\n",
      "Train_loss: 2.5512692601269262\n",
      "val_loss: 0.2080668554169115\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 55\n",
      "Train_loss: 2.550985374353503\n",
      "val_loss: 0.20791828531934506\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 56\n",
      "Train_loss: 2.5496226729069384\n",
      "val_loss: 0.20788634535106962\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 57\n",
      "Train_loss: 2.548732012618418\n",
      "val_loss: 0.20784607851826672\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 58\n",
      "Train_loss: 2.548024951185126\n",
      "val_loss: 0.2078502408152109\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 59\n",
      "Train_loss: 2.5481808845093377\n",
      "val_loss: 0.2078891184654086\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 60\n",
      "Train_loss: 2.547748886697767\n",
      "val_loss: 0.20790161436639612\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61\n",
      "Train_loss: 2.5476695442106596\n",
      "val_loss: 0.20790161948364855\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 62\n",
      "Train_loss: 2.5484329709958504\n",
      "val_loss: 0.20790023143533282\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 63\n",
      "Train_loss: 2.5482580176495047\n",
      "val_loss: 0.20789467685664803\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 64\n",
      "Train_loss: 2.5482614165955857\n",
      "val_loss: 0.20794604745909273\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 65\n",
      "Train_loss: 2.5477290059056235\n",
      "val_loss: 0.20796132892482064\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "epoch 66\n",
      "Train_loss: 2.5478385181768908\n",
      "val_loss: 0.20790161577586996\n",
      "best loss: 0.2078335779220743\n",
      "*********************************\n",
      "RC 4\n",
      "initial loss: 0.08557974416772075\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6847b04cf084c32bb8a1809fbcf344c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.261501331608823\n",
      "val_loss: 0.08492390300275376\n",
      "best loss: 0.08492390300275376\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.2496910797163236\n",
      "val_loss: 0.08494538907251918\n",
      "best loss: 0.08492390300275376\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.2378362028690595\n",
      "val_loss: 0.08486805750755759\n",
      "best loss: 0.08486805750755759\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.2280516481737327\n",
      "val_loss: 0.08495541094036983\n",
      "best loss: 0.08486805750755759\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.2204414254363805\n",
      "val_loss: 0.08476352738710682\n",
      "best loss: 0.08476352738710682\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.213045303268084\n",
      "val_loss: 0.08484658023780882\n",
      "best loss: 0.08476352738710682\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.207316108550834\n",
      "val_loss: 0.08472486469328969\n",
      "best loss: 0.08472486469328969\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.2012551993868716\n",
      "val_loss: 0.08476495908017265\n",
      "best loss: 0.08472486469328969\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.195417267891015\n",
      "val_loss: 0.08471770388890774\n",
      "best loss: 0.08471770388890774\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.189663776842179\n",
      "val_loss: 0.0847735485143763\n",
      "best loss: 0.08471770388890774\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.1834863358324723\n",
      "val_loss: 0.08460457863192995\n",
      "best loss: 0.08460457863192995\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.1781796009848655\n",
      "val_loss: 0.08466901681821766\n",
      "best loss: 0.08460457863192995\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.1753901081739495\n",
      "val_loss: 0.08466901583892045\n",
      "best loss: 0.08460457863192995\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.1695270919588863\n",
      "val_loss: 0.08478643619512781\n",
      "best loss: 0.08460457863192995\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.1644973187950027\n",
      "val_loss: 0.08462892110784934\n",
      "best loss: 0.08460457863192995\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.161221063997979\n",
      "val_loss: 0.08445565578001242\n",
      "best loss: 0.08445565578001242\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.1550016256366216\n",
      "val_loss: 0.08465040312353979\n",
      "best loss: 0.08445565578001242\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.1503223511019676\n",
      "val_loss: 0.0846618564181202\n",
      "best loss: 0.08445565578001242\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.1466324931774214\n",
      "val_loss: 0.0846203298120249\n",
      "best loss: 0.08445565578001242\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.139818726218528\n",
      "val_loss: 0.08487951274373548\n",
      "best loss: 0.08445565578001242\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.135900855048412\n",
      "val_loss: 0.08487092060049192\n",
      "best loss: 0.08445565578001242\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.134957466413074\n",
      "val_loss: 0.08442271954143517\n",
      "best loss: 0.08442271954143517\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.1290714407267606\n",
      "val_loss: 0.0846461063106539\n",
      "best loss: 0.08442271954143517\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.1228181013022542\n",
      "val_loss: 0.08483941922157211\n",
      "best loss: 0.08442271954143517\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.120811858311244\n",
      "val_loss: 0.08456877683525428\n",
      "best loss: 0.08442271954143517\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.1151410001804543\n",
      "val_loss: 0.08462605580151815\n",
      "best loss: 0.08442271954143517\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.1128315154032418\n",
      "val_loss: 0.08474920733720565\n",
      "best loss: 0.08442271954143517\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.107592711517876\n",
      "val_loss: 0.08448143079960367\n",
      "best loss: 0.08442271954143517\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.105005970763328\n",
      "val_loss: 0.08462319453575544\n",
      "best loss: 0.08442271954143517\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.100406971192671\n",
      "val_loss: 0.08462605524092248\n",
      "best loss: 0.08442271954143517\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.094389933987658\n",
      "val_loss: 0.08448572820176757\n",
      "best loss: 0.08442271954143517\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.092217649707557\n",
      "val_loss: 0.08450434135436428\n",
      "best loss: 0.08442271954143517\n",
      "*********************************\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 32\n",
      "Train_loss: 2.0919053458677808\n",
      "val_loss: 0.08474777615844918\n",
      "best loss: 0.08442271954143517\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.0782469917127253\n",
      "val_loss: 0.08437546311151789\n",
      "best loss: 0.08437546311151789\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.07457021124517\n",
      "val_loss: 0.08435541588962168\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.0764631761656633\n",
      "val_loss: 0.08445851430122375\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.072880423883823\n",
      "val_loss: 0.0844284454083076\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.0731155367997975\n",
      "val_loss: 0.08440696707139349\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.0720374652884774\n",
      "val_loss: 0.08441985358542611\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.070928773063704\n",
      "val_loss: 0.08450147714767477\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.073161393452556\n",
      "val_loss: 0.08444705975038698\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.070828137578857\n",
      "val_loss: 0.08444563192245685\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.0712100816743293\n",
      "val_loss: 0.08440696915078763\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.0709272608077307\n",
      "val_loss: 0.08441126256170456\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 2.069256842337968\n",
      "val_loss: 0.08442987932463457\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 45\n",
      "Train_loss: 2.069509127615161\n",
      "val_loss: 0.08441126493869701\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 2.0683089546231774\n",
      "val_loss: 0.08436973699864501\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 2.067228990922667\n",
      "val_loss: 0.08436257862619208\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 2.069930467081729\n",
      "val_loss: 0.08436830726918165\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 2.0683234928016394\n",
      "val_loss: 0.08438691994616743\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 2.068834399990171\n",
      "val_loss: 0.08437117022310525\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 51\n",
      "Train_loss: 2.0676184759995473\n",
      "val_loss: 0.08437403291129983\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 52\n",
      "Train_loss: 2.0670421161235595\n",
      "val_loss: 0.0843940820875412\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 53\n",
      "Train_loss: 2.066438337610546\n",
      "val_loss: 0.08439121569856532\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 54\n",
      "Train_loss: 2.068810739097763\n",
      "val_loss: 0.08439121570205577\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "epoch 55\n",
      "Train_loss: 2.0691338555044902\n",
      "val_loss: 0.08438835540754706\n",
      "best loss: 0.08435541588962168\n",
      "*********************************\n",
      "RC 5\n",
      "initial loss: 0.08635530750046097\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5708116964458b83658b6b3657267b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.196835739481576\n",
      "val_loss: 0.08528472872137989\n",
      "best loss: 0.08528472872137989\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.1775297915509206\n",
      "val_loss: 0.08519265025827895\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.167676356922888\n",
      "val_loss: 0.08534107945401372\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.1562380207126193\n",
      "val_loss: 0.08564891925163719\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.1482131840898178\n",
      "val_loss: 0.08550873984063945\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.1398066202896495\n",
      "val_loss: 0.08555821306619718\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.1317645070890197\n",
      "val_loss: 0.08543315572876604\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.125578755972483\n",
      "val_loss: 0.08555271944136532\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.118600817038675\n",
      "val_loss: 0.08569839574770195\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.112020679969981\n",
      "val_loss: 0.0856200630711316\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.103775958943096\n",
      "val_loss: 0.08554722391977046\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.1008018231755234\n",
      "val_loss: 0.08571076461232055\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 12\n",
      "Train_loss: 2.0948031192918988\n",
      "val_loss: 0.08541803761869567\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.0848459130552213\n",
      "val_loss: 0.08539467593238985\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.086209977919617\n",
      "val_loss: 0.08544964512886394\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.0850378516099988\n",
      "val_loss: 0.08549087688307902\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.0824766635990613\n",
      "val_loss: 0.08543453123513327\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.0823747580438026\n",
      "val_loss: 0.08543727473495014\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.08205437582544\n",
      "val_loss: 0.08559807255076192\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.0823975866229767\n",
      "val_loss: 0.08547988316842904\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.081822748277574\n",
      "val_loss: 0.08535894037295082\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.0805083816626317\n",
      "val_loss: 0.08539880031878012\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.0790109973532807\n",
      "val_loss: 0.08537680968232966\n",
      "best loss: 0.08519265025827895\n",
      "*********************************\n",
      "RC 6\n",
      "initial loss: 0.1383374881687641\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2475d9a7c24149aeb7d9fd8641b375bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.3845708047184053\n",
      "val_loss: 0.1368383355689548\n",
      "best loss: 0.1368383355689548\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.356395253566268\n",
      "val_loss: 0.13623548175588415\n",
      "best loss: 0.13623548175588415\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.3370805267027013\n",
      "val_loss: 0.13592270043767946\n",
      "best loss: 0.13592270043767946\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.3226240306083095\n",
      "val_loss: 0.1355645138472142\n",
      "best loss: 0.1355645138472142\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.311177237448061\n",
      "val_loss: 0.13505919176138434\n",
      "best loss: 0.13505919176138434\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.2996738967365093\n",
      "val_loss: 0.1350415383016473\n",
      "best loss: 0.1350415383016473\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.2918597597632426\n",
      "val_loss: 0.13457909067404455\n",
      "best loss: 0.13457909067404455\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.2834914900774095\n",
      "val_loss: 0.1344100891460775\n",
      "best loss: 0.1344100891460775\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.275550556237046\n",
      "val_loss: 0.13443110994745583\n",
      "best loss: 0.1344100891460775\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.267786126593424\n",
      "val_loss: 0.1344958533112139\n",
      "best loss: 0.1344100891460775\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.2608962626246023\n",
      "val_loss: 0.13406452118729173\n",
      "best loss: 0.13406452118729173\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.2541366638665594\n",
      "val_loss: 0.13439411840130044\n",
      "best loss: 0.13406452118729173\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.2471815334075154\n",
      "val_loss: 0.13425622709959736\n",
      "best loss: 0.13406452118729173\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.241563351273102\n",
      "val_loss: 0.13498099342876257\n",
      "best loss: 0.13406452118729173\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.2345845823594903\n",
      "val_loss: 0.1339089718539915\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.2286930875851247\n",
      "val_loss: 0.1340552739463175\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.2231979561335438\n",
      "val_loss: 0.13479349777715\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.2175743085369417\n",
      "val_loss: 0.1342957387252222\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.2115573959601953\n",
      "val_loss: 0.134507621982801\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.205944429481319\n",
      "val_loss: 0.13419904952772072\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.201531837712991\n",
      "val_loss: 0.13447399464828205\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.195716060875519\n",
      "val_loss: 0.13497847851024566\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.190529928311809\n",
      "val_loss: 0.13437141825208315\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.1855689121855937\n",
      "val_loss: 0.13440420200432007\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.1803873021170412\n",
      "val_loss: 0.13445297170991757\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 25\n",
      "Train_loss: 2.175016371073798\n",
      "val_loss: 0.13441766014408918\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.1641561812530195\n",
      "val_loss: 0.13440925165966838\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.163470586567167\n",
      "val_loss: 0.13434870948684274\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.161892509373149\n",
      "val_loss: 0.13428817891782882\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.161867265288508\n",
      "val_loss: 0.13428817469161833\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.1607964395603387\n",
      "val_loss: 0.13420997614611774\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.1606276186533484\n",
      "val_loss: 0.13422174536010478\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.159923483278505\n",
      "val_loss: 0.13410572106851798\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.159766638087402\n",
      "val_loss: 0.13426379323784124\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.1589693734743274\n",
      "val_loss: 0.13422847819618017\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.1582433756379213\n",
      "val_loss: 0.13420408679243437\n",
      "best loss: 0.1339089718539915\n",
      "*********************************\n",
      "RC 7\n",
      "initial loss: 0.1288608586847583\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626291835bf745509c43bc9e2fe39d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.30962078846785\n",
      "val_loss: 0.12813536771524187\n",
      "best loss: 0.12813536771524187\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.2968799428376414\n",
      "val_loss: 0.1278413581373224\n",
      "best loss: 0.1278413581373224\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.290402797376584\n",
      "val_loss: 0.1276027068519626\n",
      "best loss: 0.1276027068519626\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.2806376258529992\n",
      "val_loss: 0.12813727885158532\n",
      "best loss: 0.1276027068519626\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.272537002625354\n",
      "val_loss: 0.12779553052920842\n",
      "best loss: 0.1276027068519626\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.26520524706515\n",
      "val_loss: 0.12762561852826504\n",
      "best loss: 0.1276027068519626\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.2610957950720834\n",
      "val_loss: 0.12717504589706502\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.2538022906740505\n",
      "val_loss: 0.12758361118284237\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.2472790864055674\n",
      "val_loss: 0.12826710509243203\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.2415739875716705\n",
      "val_loss: 0.1275129743185255\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.237273742773858\n",
      "val_loss: 0.12734687095977143\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.2334637227456975\n",
      "val_loss: 0.1276943482899884\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.2276816923153855\n",
      "val_loss: 0.12744424147483588\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.218654950453159\n",
      "val_loss: 0.1278222652017476\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.2168804797098094\n",
      "val_loss: 0.12771534550517916\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.2133800824505365\n",
      "val_loss: 0.12744424280417663\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.2115456702383938\n",
      "val_loss: 0.12792727173012486\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 17\n",
      "Train_loss: 2.201913681022705\n",
      "val_loss: 0.127839445321194\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.198579288658233\n",
      "val_loss: 0.1277764429793859\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.1969031067245495\n",
      "val_loss: 0.12769816778218815\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.1965810407615285\n",
      "val_loss: 0.12776307867814085\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.1957856526190946\n",
      "val_loss: 0.12772108029211066\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.1962027578889933\n",
      "val_loss: 0.12775734561429394\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.196881776116769\n",
      "val_loss: 0.12772489462193598\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.195025399190669\n",
      "val_loss: 0.12777834819419412\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.197425703330897\n",
      "val_loss: 0.12768671277806168\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.1926374763666754\n",
      "val_loss: 0.1275377932014216\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.194123060770064\n",
      "val_loss: 0.12771534994481307\n",
      "best loss: 0.12717504589706502\n",
      "*********************************\n",
      "RC 8\n",
      "initial loss: 0.13037414345591694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4cb9388bbd41b8bd65399fffbd5406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.2815968085924614\n",
      "val_loss: 0.1294799003888879\n",
      "best loss: 0.1294799003888879\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.266427677510385\n",
      "val_loss: 0.12947708376193987\n",
      "best loss: 0.12947708376193987\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.251670820174495\n",
      "val_loss: 0.12936001645459305\n",
      "best loss: 0.12936001645459305\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.2444795534901227\n",
      "val_loss: 0.12935436929986255\n",
      "best loss: 0.12935436929986255\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.2351179192765107\n",
      "val_loss: 0.12937552882767822\n",
      "best loss: 0.12935436929986255\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.227281435468532\n",
      "val_loss: 0.12933744643992465\n",
      "best loss: 0.12933744643992465\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.221981066405862\n",
      "val_loss: 0.12961248360798316\n",
      "best loss: 0.12933744643992465\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.2126051102320994\n",
      "val_loss: 0.1296054332655563\n",
      "best loss: 0.12933744643992465\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.204830636457189\n",
      "val_loss: 0.1297746922503832\n",
      "best loss: 0.12933744643992465\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.2023037381228217\n",
      "val_loss: 0.1289580243055009\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.1953109884669133\n",
      "val_loss: 0.12976341017668802\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.1901215523483804\n",
      "val_loss: 0.1296590290926429\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.185374101874547\n",
      "val_loss: 0.12947143828617977\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.1807796110826665\n",
      "val_loss: 0.12984521155655795\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.1778328182011015\n",
      "val_loss: 0.1297845622838193\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.1694716656235484\n",
      "val_loss: 0.129674548166811\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.1653626129074923\n",
      "val_loss: 0.12949400807722464\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.1592372423812876\n",
      "val_loss: 0.13003421977472981\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.1559205900394875\n",
      "val_loss: 0.12961953773736126\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.1513129776475015\n",
      "val_loss: 0.1297182717656323\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 20\n",
      "Train_loss: 2.145603627828283\n",
      "val_loss: 0.12956876108198692\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.137867304253315\n",
      "val_loss: 0.12948695347757938\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.1363614821119152\n",
      "val_loss: 0.12941078573756537\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.132543287382587\n",
      "val_loss: 0.1294248958146082\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.135163832681754\n",
      "val_loss: 0.12938963100210998\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.135650680431939\n",
      "val_loss: 0.12941360903031882\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.1373754580629827\n",
      "val_loss: 0.12949964943269096\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.1335816516137105\n",
      "val_loss: 0.12958850831527632\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.1355205691358043\n",
      "val_loss: 0.1295349107479321\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.1320405292554314\n",
      "val_loss: 0.12955888338182073\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.1324946378535485\n",
      "val_loss: 0.12956735310716208\n",
      "best loss: 0.1289580243055009\n",
      "*********************************\n",
      "fold 1, score: 0.13633837173130992\n",
      "fold: 2\n",
      "RC 0\n",
      "initial loss: 0.1252216288728437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e89acf46c12411f9f17a5d4283ca60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.5082280605190825\n",
      "val_loss: 0.12448077820536187\n",
      "best loss: 0.12448077820536187\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.485050114705277\n",
      "val_loss: 0.12407129053810814\n",
      "best loss: 0.12407129053810814\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.468172437585161\n",
      "val_loss: 0.12418415649418224\n",
      "best loss: 0.12407129053810814\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.454662268444039\n",
      "val_loss: 0.1240553716201827\n",
      "best loss: 0.1240553716201827\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.444348415819392\n",
      "val_loss: 0.12410890400956845\n",
      "best loss: 0.1240553716201827\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.4345232406984865\n",
      "val_loss: 0.12414363219868488\n",
      "best loss: 0.1240553716201827\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.4245177365389723\n",
      "val_loss: 0.12414219386828705\n",
      "best loss: 0.1240553716201827\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.4174015599929795\n",
      "val_loss: 0.12387160762413942\n",
      "best loss: 0.12387160762413942\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.4108835095265397\n",
      "val_loss: 0.12407418250337103\n",
      "best loss: 0.12387160762413942\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.403976994703841\n",
      "val_loss: 0.12390199022079532\n",
      "best loss: 0.12387160762413942\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.3968044731456675\n",
      "val_loss: 0.12390923080469411\n",
      "best loss: 0.12387160762413942\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.3891180128029204\n",
      "val_loss: 0.12388462951078748\n",
      "best loss: 0.12387160762413942\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.383500444953966\n",
      "val_loss: 0.12382964315162398\n",
      "best loss: 0.12382964315162398\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.377798003249481\n",
      "val_loss: 0.12375440574390854\n",
      "best loss: 0.12375440574390854\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.371120670965999\n",
      "val_loss: 0.12415087288041989\n",
      "best loss: 0.12375440574390854\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.3671911062326467\n",
      "val_loss: 0.12383687698911758\n",
      "best loss: 0.12375440574390854\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.361385517896694\n",
      "val_loss: 0.12375584759641016\n",
      "best loss: 0.12375440574390854\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.355286485226072\n",
      "val_loss: 0.12372112444447876\n",
      "best loss: 0.12372112444447876\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.3497462905876945\n",
      "val_loss: 0.12377610759252883\n",
      "best loss: 0.12372112444447876\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.3432504208804805\n",
      "val_loss: 0.12378479590922323\n",
      "best loss: 0.12372112444447876\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.338303911415167\n",
      "val_loss: 0.12389620515825239\n",
      "best loss: 0.12372112444447876\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.3346608600772303\n",
      "val_loss: 0.12398591789855583\n",
      "best loss: 0.12372112444447876\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.3282648379565916\n",
      "val_loss: 0.1239063302534598\n",
      "best loss: 0.12372112444447876\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.3219989366460916\n",
      "val_loss: 0.12396710553616978\n",
      "best loss: 0.12372112444447876\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.3177333711767223\n",
      "val_loss: 0.12399170639487395\n",
      "best loss: 0.12372112444447876\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.3138683664213047\n",
      "val_loss: 0.12431727634771302\n",
      "best loss: 0.12372112444447876\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.310302978429124\n",
      "val_loss: 0.12410891128931904\n",
      "best loss: 0.12372112444447876\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.305408805896971\n",
      "val_loss: 0.12399604451037796\n",
      "best loss: 0.12372112444447876\n",
      "*********************************\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 28\n",
      "Train_loss: 2.2997212335623285\n",
      "val_loss: 0.12401919998128874\n",
      "best loss: 0.12372112444447876\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.287866602552489\n",
      "val_loss: 0.123667584822267\n",
      "best loss: 0.123667584822267\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.2863645650236575\n",
      "val_loss: 0.12369363237651886\n",
      "best loss: 0.123667584822267\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.2866791551766044\n",
      "val_loss: 0.12377900377793698\n",
      "best loss: 0.123667584822267\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.2849540238000134\n",
      "val_loss: 0.12375295206487917\n",
      "best loss: 0.123667584822267\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.2851710611244433\n",
      "val_loss: 0.12371678471360373\n",
      "best loss: 0.123667584822267\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.2844737932920034\n",
      "val_loss: 0.12360536727853552\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.2834744694680777\n",
      "val_loss: 0.12377321749658174\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.284217310571728\n",
      "val_loss: 0.12377610853715436\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.282715561199739\n",
      "val_loss: 0.12375729377057364\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.281933750415057\n",
      "val_loss: 0.12370086836027529\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.2816797331795513\n",
      "val_loss: 0.12361404590576412\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.28188219371775\n",
      "val_loss: 0.12372691297023974\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.2805081226455606\n",
      "val_loss: 0.12371967520089568\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.280988896845793\n",
      "val_loss: 0.12370375822435974\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.279585669741437\n",
      "val_loss: 0.12376453342058127\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 2.278989222752879\n",
      "val_loss: 0.1237240187176336\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 45\n",
      "Train_loss: 2.2786178343281387\n",
      "val_loss: 0.12371678424834498\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 2.278307660366327\n",
      "val_loss: 0.1237153346443934\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 2.2774132144271193\n",
      "val_loss: 0.1236936278748261\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 2.277138658903832\n",
      "val_loss: 0.12368060830741776\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 2.277931196808796\n",
      "val_loss: 0.12367481940656683\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 2.276893162908041\n",
      "val_loss: 0.12366613685730206\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 51\n",
      "Train_loss: 2.2768314291522613\n",
      "val_loss: 0.12371822943678557\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 52\n",
      "Train_loss: 2.2771626235925275\n",
      "val_loss: 0.12367481824510679\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 53\n",
      "Train_loss: 2.277203450205351\n",
      "val_loss: 0.1236748201947771\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 54\n",
      "Train_loss: 2.2772930088519527\n",
      "val_loss: 0.12366469237365027\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "epoch 55\n",
      "Train_loss: 2.2758505266008666\n",
      "val_loss: 0.12370520024370432\n",
      "best loss: 0.12360536727853552\n",
      "*********************************\n",
      "RC 1\n",
      "initial loss: 0.14034328753641426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35f3d7895b54a7396ca537d696ab825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.3734731678713406\n",
      "val_loss: 0.1382061008601785\n",
      "best loss: 0.1382061008601785\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.3521061377260044\n",
      "val_loss: 0.13742687588384772\n",
      "best loss: 0.13742687588384772\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.3323281307113968\n",
      "val_loss: 0.13717343814773064\n",
      "best loss: 0.13717343814773064\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.3236716481399604\n",
      "val_loss: 0.13703916036669925\n",
      "best loss: 0.13703916036669925\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.309003938675123\n",
      "val_loss: 0.13699565549153803\n",
      "best loss: 0.13699565549153803\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.301147620714393\n",
      "val_loss: 0.13708076130472807\n",
      "best loss: 0.13699565549153803\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.2894567709977265\n",
      "val_loss: 0.13701835150302863\n",
      "best loss: 0.13699565549153803\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.281075415979924\n",
      "val_loss: 0.13650769720278982\n",
      "best loss: 0.13650769720278982\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.2717331921985116\n",
      "val_loss: 0.1368462373405965\n",
      "best loss: 0.13650769720278982\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.266019247282946\n",
      "val_loss: 0.13665710978027773\n",
      "best loss: 0.13650769720278982\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.261693011797064\n",
      "val_loss: 0.13688973721556447\n",
      "best loss: 0.13650769720278982\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.253436780959955\n",
      "val_loss: 0.13666278407519244\n",
      "best loss: 0.13650769720278982\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.247928873297851\n",
      "val_loss: 0.13676680837272845\n",
      "best loss: 0.13650769720278982\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.240977351618062\n",
      "val_loss: 0.1364717643363934\n",
      "best loss: 0.1364717643363934\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.236587261328387\n",
      "val_loss: 0.13626561366563425\n",
      "best loss: 0.13626561366563425\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.229509672233636\n",
      "val_loss: 0.1366041545659173\n",
      "best loss: 0.13626561366563425\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.2228159846371836\n",
      "val_loss: 0.13652282466993235\n",
      "best loss: 0.13626561366563425\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.218997279586305\n",
      "val_loss: 0.13653984342559847\n",
      "best loss: 0.13626561366563425\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.2140088243514624\n",
      "val_loss: 0.13621832509496684\n",
      "best loss: 0.13621832509496684\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.209215367237607\n",
      "val_loss: 0.13630154336947756\n",
      "best loss: 0.13621832509496684\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.205772396237993\n",
      "val_loss: 0.13616537572024523\n",
      "best loss: 0.13616537572024523\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.1976535280984106\n",
      "val_loss: 0.13611808893710783\n",
      "best loss: 0.13611808893710783\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.193616409358727\n",
      "val_loss: 0.1359932580048016\n",
      "best loss: 0.1359932580048016\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.189085732929233\n",
      "val_loss: 0.13596110389505298\n",
      "best loss: 0.13596110389505298\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.1835449670167675\n",
      "val_loss: 0.13611240704268507\n",
      "best loss: 0.13596110389505298\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.1792676390558334\n",
      "val_loss: 0.1358098002419095\n",
      "best loss: 0.1358098002419095\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.1718986812224284\n",
      "val_loss: 0.13595543676829794\n",
      "best loss: 0.1358098002419095\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.171202811160095\n",
      "val_loss: 0.13637530560826489\n",
      "best loss: 0.1358098002419095\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.1635646976971805\n",
      "val_loss: 0.13628263316373265\n",
      "best loss: 0.1358098002419095\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.158334805638148\n",
      "val_loss: 0.13593841115635785\n",
      "best loss: 0.1358098002419095\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.1582610433292833\n",
      "val_loss: 0.13591382520811562\n",
      "best loss: 0.1358098002419095\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.148734575574945\n",
      "val_loss: 0.1359157072787731\n",
      "best loss: 0.1358098002419095\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.149577637990102\n",
      "val_loss: 0.13596678710316396\n",
      "best loss: 0.1358098002419095\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.1476387839538043\n",
      "val_loss: 0.1362599388395517\n",
      "best loss: 0.1358098002419095\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.137740618431517\n",
      "val_loss: 0.1355639229062356\n",
      "best loss: 0.1355639229062356\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.1338887727707068\n",
      "val_loss: 0.13586843102077592\n",
      "best loss: 0.1355639229062356\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.127886154986477\n",
      "val_loss: 0.13592327684536867\n",
      "best loss: 0.1355639229062356\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.120263780276644\n",
      "val_loss: 0.13610295392537802\n",
      "best loss: 0.1355639229062356\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.1211757963270883\n",
      "val_loss: 0.13590247498108668\n",
      "best loss: 0.1355639229062356\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.116518820098994\n",
      "val_loss: 0.13561499461758939\n",
      "best loss: 0.1355639229062356\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.111189032933905\n",
      "val_loss: 0.13619563011534486\n",
      "best loss: 0.1355639229062356\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.107335814774473\n",
      "val_loss: 0.13566228122594254\n",
      "best loss: 0.1355639229062356\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.1027152144976773\n",
      "val_loss: 0.1357738697419158\n",
      "best loss: 0.1355639229062356\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.109648429673504\n",
      "val_loss: 0.13641501798215988\n",
      "best loss: 0.1355639229062356\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 2.1068754273781023\n",
      "val_loss: 0.1353766911792324\n",
      "best loss: 0.1353766911792324\n",
      "*********************************\n",
      "epoch 45\n",
      "Train_loss: 2.090031435570411\n",
      "val_loss: 0.135478821727635\n",
      "best loss: 0.1353766911792324\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 2.086130782853683\n",
      "val_loss: 0.13550908542157875\n",
      "best loss: 0.1353766911792324\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 2.079022995065342\n",
      "val_loss: 0.13556204090533144\n",
      "best loss: 0.1353766911792324\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 2.08024527806019\n",
      "val_loss: 0.13558473628623566\n",
      "best loss: 0.1353766911792324\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 2.0759329945089484\n",
      "val_loss: 0.1356357964193339\n",
      "best loss: 0.1353766911792324\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 2.0682671545916014\n",
      "val_loss: 0.13570199978744135\n",
      "best loss: 0.1353766911792324\n",
      "*********************************\n",
      "epoch 51\n",
      "Train_loss: 2.065850150465249\n",
      "val_loss: 0.13575305905383409\n",
      "best loss: 0.1353766911792324\n",
      "*********************************\n",
      "epoch 52\n",
      "Train_loss: 2.06053857051791\n",
      "val_loss: 0.1358135901971782\n",
      "best loss: 0.1353766911792324\n",
      "*********************************\n",
      "epoch 53\n",
      "Train_loss: 2.0599301782900175\n",
      "val_loss: 0.13542397349655141\n",
      "best loss: 0.1353766911792324\n",
      "*********************************\n",
      "epoch 54\n",
      "Train_loss: 2.0553698463670025\n",
      "val_loss: 0.13565281900061088\n",
      "best loss: 0.1353766911792324\n",
      "*********************************\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 55\n",
      "Train_loss: 2.0509552479972504\n",
      "val_loss: 0.13550908154144803\n",
      "best loss: 0.1353766911792324\n",
      "*********************************\n",
      "epoch 56\n",
      "Train_loss: 2.0409745675042577\n",
      "val_loss: 0.13542587189149896\n",
      "best loss: 0.1353766911792324\n",
      "*********************************\n",
      "epoch 57\n",
      "Train_loss: 2.039219434849317\n",
      "val_loss: 0.13530860196737204\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 58\n",
      "Train_loss: 2.0367733718485868\n",
      "val_loss: 0.1353558817948169\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 59\n",
      "Train_loss: 2.03583430546215\n",
      "val_loss: 0.13544856139387884\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 60\n",
      "Train_loss: 2.038354872764917\n",
      "val_loss: 0.13540505746519854\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61\n",
      "Train_loss: 2.035018128025377\n",
      "val_loss: 0.1353937113359789\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 62\n",
      "Train_loss: 2.0361328695191543\n",
      "val_loss: 0.13541640909130342\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 63\n",
      "Train_loss: 2.03793386542631\n",
      "val_loss: 0.1354655839414818\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 64\n",
      "Train_loss: 2.0352987756326986\n",
      "val_loss: 0.13542018705741318\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 65\n",
      "Train_loss: 2.033357880177234\n",
      "val_loss: 0.1353539946858824\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 66\n",
      "Train_loss: 2.035856978742087\n",
      "val_loss: 0.13541451949369743\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 67\n",
      "Train_loss: 2.036449203796205\n",
      "val_loss: 0.13544099569859464\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 68\n",
      "Train_loss: 2.032437590816874\n",
      "val_loss: 0.13540127723851877\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 69\n",
      "Train_loss: 2.0329265282046576\n",
      "val_loss: 0.13542019020914245\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 70\n",
      "Train_loss: 2.033383086139531\n",
      "val_loss: 0.13545990552991635\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 71\n",
      "Train_loss: 2.030771228180372\n",
      "val_loss: 0.13545612110280167\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 72\n",
      "Train_loss: 2.0301126621261245\n",
      "val_loss: 0.13543342946933642\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 73\n",
      "Train_loss: 2.031223767435218\n",
      "val_loss: 0.1354428831025778\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 74\n",
      "Train_loss: 2.0344160335195087\n",
      "val_loss: 0.13544288003383095\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 75\n",
      "Train_loss: 2.0362138301902553\n",
      "val_loss: 0.13544288426072407\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 76\n",
      "Train_loss: 2.033865412264627\n",
      "val_loss: 0.13543721020914434\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 77\n",
      "Train_loss: 2.0337991092090317\n",
      "val_loss: 0.13543531507376316\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "epoch 78\n",
      "Train_loss: 2.032034936809233\n",
      "val_loss: 0.13545045182371457\n",
      "best loss: 0.13530860196737204\n",
      "*********************************\n",
      "RC 2\n",
      "initial loss: 0.21764228823830836\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd085fa69e4349acbaf8ac6e1dd92534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.7811933145295353\n",
      "val_loss: 0.21585192406676204\n",
      "best loss: 0.21585192406676204\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.7545981898402077\n",
      "val_loss: 0.21530272912109805\n",
      "best loss: 0.21530272912109805\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.737073413677963\n",
      "val_loss: 0.21474254590947128\n",
      "best loss: 0.21474254590947128\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.7204485027057546\n",
      "val_loss: 0.21474804135638795\n",
      "best loss: 0.21474254590947128\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.7074020395936165\n",
      "val_loss: 0.21383226230599695\n",
      "best loss: 0.21383226230599695\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.6947038993317123\n",
      "val_loss: 0.2134862638833597\n",
      "best loss: 0.2134862638833597\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.6851680416784696\n",
      "val_loss: 0.2134670493062814\n",
      "best loss: 0.2134670493062814\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.6752126183693368\n",
      "val_loss: 0.21374576409648482\n",
      "best loss: 0.2134670493062814\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.6687703033882553\n",
      "val_loss: 0.21307024882221517\n",
      "best loss: 0.21307024882221517\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.6594243296235884\n",
      "val_loss: 0.21321168265792692\n",
      "best loss: 0.21307024882221517\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.6518127963176226\n",
      "val_loss: 0.21296727963175477\n",
      "best loss: 0.21296727963175477\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.644632302159213\n",
      "val_loss: 0.2130716303345254\n",
      "best loss: 0.21296727963175477\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.6392159551227357\n",
      "val_loss: 0.21249223087655503\n",
      "best loss: 0.21249223087655503\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.6333121239471238\n",
      "val_loss: 0.21272977197067122\n",
      "best loss: 0.21249223087655503\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.6259212312728066\n",
      "val_loss: 0.21272427055036897\n",
      "best loss: 0.21249223087655503\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.618168856745955\n",
      "val_loss: 0.21263640236702294\n",
      "best loss: 0.21249223087655503\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.6145423671399466\n",
      "val_loss: 0.2130482959865234\n",
      "best loss: 0.21249223087655503\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.6076752997762314\n",
      "val_loss: 0.2130139726610256\n",
      "best loss: 0.21249223087655503\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.599548405694869\n",
      "val_loss: 0.21276408547002834\n",
      "best loss: 0.21249223087655503\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.5943295793272885\n",
      "val_loss: 0.21224921767642588\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.590097467043305\n",
      "val_loss: 0.21319246303987693\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.585388237249807\n",
      "val_loss: 0.21242770459772126\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.579632922718299\n",
      "val_loss: 0.21244281161867234\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.576047716598001\n",
      "val_loss: 0.21229726664414073\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.570844716386444\n",
      "val_loss: 0.2128794115726724\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.561860871626569\n",
      "val_loss: 0.2130881053384729\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.5587932545051046\n",
      "val_loss: 0.2130290601661816\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.5539983237921002\n",
      "val_loss: 0.2123110031229045\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.5501697491532775\n",
      "val_loss: 0.21252655228746142\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.542656859089395\n",
      "val_loss: 0.21314439621981202\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 30\n",
      "Train_loss: 2.5385071361605966\n",
      "val_loss: 0.21291511585755085\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.5289163079695234\n",
      "val_loss: 0.2124249536965184\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.5267511305075474\n",
      "val_loss: 0.2123412062665646\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.5269453715471357\n",
      "val_loss: 0.2125952043155517\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.5271507254503796\n",
      "val_loss: 0.21251145636264296\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.524767026357653\n",
      "val_loss: 0.21246339430592087\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.5247351298577874\n",
      "val_loss: 0.21238651884223986\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.5228788532947375\n",
      "val_loss: 0.21240710497045645\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.52338563653646\n",
      "val_loss: 0.2124427997691004\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.5222399965683633\n",
      "val_loss: 0.21258971141676736\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.5213602913339344\n",
      "val_loss: 0.2123123759190074\n",
      "best loss: 0.21224921767642588\n",
      "*********************************\n",
      "RC 3\n",
      "initial loss: 0.21288618697908102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155df0688a5c40a9880eb24b17111921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.7573633753183504\n",
      "val_loss: 0.21160754505454413\n",
      "best loss: 0.21160754505454413\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.7260616954004226\n",
      "val_loss: 0.21001096351986703\n",
      "best loss: 0.21001096351986703\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.704867466724693\n",
      "val_loss: 0.20895306163165583\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.688124850785187\n",
      "val_loss: 0.20951117447985826\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.6738944591122444\n",
      "val_loss: 0.21019144517686386\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.6606468913398813\n",
      "val_loss: 0.21165057680751997\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.6500714536857473\n",
      "val_loss: 0.2122100794145604\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.6408343862259103\n",
      "val_loss: 0.21255715991685947\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.630432172921024\n",
      "val_loss: 0.2127737389873981\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.622246751108394\n",
      "val_loss: 0.21205041609488795\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.615367225980535\n",
      "val_loss: 0.21246691792379402\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.6068445946570176\n",
      "val_loss: 0.21277234790729513\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.599652131869621\n",
      "val_loss: 0.21181717817764475\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 13\n",
      "Train_loss: 2.592396458195023\n",
      "val_loss: 0.21225033921726535\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.58387490882758\n",
      "val_loss: 0.2119574026047249\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.582303547836622\n",
      "val_loss: 0.21215454025402317\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.5818211443078223\n",
      "val_loss: 0.2121600993143881\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.5807019032249685\n",
      "val_loss: 0.21212815743944197\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.5788656180198672\n",
      "val_loss: 0.21221284743517166\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.579358345315121\n",
      "val_loss: 0.2121226150096534\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.577748003592117\n",
      "val_loss: 0.21211844698937096\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.5772724620356406\n",
      "val_loss: 0.21214342914511983\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.5759639923564577\n",
      "val_loss: 0.2121712032640365\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.5748545305438513\n",
      "val_loss: 0.2121559370335157\n",
      "best loss: 0.20895306163165583\n",
      "*********************************\n",
      "RC 4\n",
      "initial loss: 0.08752396232179493\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4211b0f2065c439589cc75e88c52d76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.1812981190582037\n",
      "val_loss: 0.08674427036775395\n",
      "best loss: 0.08674427036775395\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.1629575166025288\n",
      "val_loss: 0.0869502824125293\n",
      "best loss: 0.08674427036775395\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.1488796524088767\n",
      "val_loss: 0.08654398418127095\n",
      "best loss: 0.08654398418127095\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.1399397807570772\n",
      "val_loss: 0.086227818720713\n",
      "best loss: 0.086227818720713\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.1295558121618114\n",
      "val_loss: 0.08636801988699093\n",
      "best loss: 0.086227818720713\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.122622822207881\n",
      "val_loss: 0.08614341220356883\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.1175221218590785\n",
      "val_loss: 0.08640521684807931\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.1085750854188774\n",
      "val_loss: 0.08634512950617258\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.1019760941548045\n",
      "val_loss: 0.08632080813249761\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.0981427959961163\n",
      "val_loss: 0.08632223822156898\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.0885826445857782\n",
      "val_loss: 0.08633511788549204\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.086160342938989\n",
      "val_loss: 0.08631365446347325\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.0807396842139196\n",
      "val_loss: 0.08624642002480906\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.07281853680067\n",
      "val_loss: 0.08639233995130682\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.0700458025374635\n",
      "val_loss: 0.08629648667573686\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.064606302113275\n",
      "val_loss: 0.0863308212835939\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 16\n",
      "Train_loss: 2.060431469618231\n",
      "val_loss: 0.08640664754604208\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.050322062062448\n",
      "val_loss: 0.08626358459342645\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.0489028107431393\n",
      "val_loss: 0.0863193821090195\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.0473427005838425\n",
      "val_loss: 0.08627073925478002\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.045925473552404\n",
      "val_loss: 0.08622638552456713\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.0459081374566623\n",
      "val_loss: 0.08622924981757846\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.045844502034031\n",
      "val_loss: 0.08621351295780688\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.043774339950672\n",
      "val_loss: 0.08621494574655954\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.0436454266977546\n",
      "val_loss: 0.0862049299405088\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.0442479590602463\n",
      "val_loss: 0.08618490153251629\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.044180877977168\n",
      "val_loss: 0.08620206605291966\n",
      "best loss: 0.08614341220356883\n",
      "*********************************\n",
      "RC 5\n",
      "initial loss: 0.08163885148905783\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4d12870cf54d93a73457de1929dd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.147595991270811\n",
      "val_loss: 0.08085985949909141\n",
      "best loss: 0.08085985949909141\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.1252462050312433\n",
      "val_loss: 0.08043045244159974\n",
      "best loss: 0.08043045244159974\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.1097998432656513\n",
      "val_loss: 0.08026804308273545\n",
      "best loss: 0.08026804308273545\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.097374092343036\n",
      "val_loss: 0.08020610955931078\n",
      "best loss: 0.08020610955931078\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.086787109620371\n",
      "val_loss: 0.07991570683681905\n",
      "best loss: 0.07991570683681905\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.078637403936497\n",
      "val_loss: 0.07984964716333542\n",
      "best loss: 0.07984964716333542\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.0714633227805686\n",
      "val_loss: 0.07973540539684805\n",
      "best loss: 0.07973540539684805\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.063874063048926\n",
      "val_loss: 0.07971751577058223\n",
      "best loss: 0.07971751577058223\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.055803338430962\n",
      "val_loss: 0.07982486749466103\n",
      "best loss: 0.07971751577058223\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.0508707745573895\n",
      "val_loss: 0.07982349200429469\n",
      "best loss: 0.07971751577058223\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.0427358473212314\n",
      "val_loss: 0.07977807703985888\n",
      "best loss: 0.07971751577058223\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.0373681169178997\n",
      "val_loss: 0.07965695788119698\n",
      "best loss: 0.07965695788119698\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.0306379127328116\n",
      "val_loss: 0.07991708425648901\n",
      "best loss: 0.07965695788119698\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.0239711226023096\n",
      "val_loss: 0.08004920888916767\n",
      "best loss: 0.07965695788119698\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.0192314326949425\n",
      "val_loss: 0.07988267340241532\n",
      "best loss: 0.07965695788119698\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.014259013888548\n",
      "val_loss: 0.07963493742448399\n",
      "best loss: 0.07963493742448399\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.009694983733466\n",
      "val_loss: 0.07963356105865985\n",
      "best loss: 0.07963356105865985\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.0036188826525354\n",
      "val_loss: 0.07972990383168707\n",
      "best loss: 0.07963356105865985\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.0001303832085124\n",
      "val_loss: 0.07984689079230897\n",
      "best loss: 0.07963356105865985\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 1.9968891337014814\n",
      "val_loss: 0.07975054635821653\n",
      "best loss: 0.07963356105865985\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 1.9906883247149516\n",
      "val_loss: 0.07968861171020342\n",
      "best loss: 0.07963356105865985\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 1.9829663007018152\n",
      "val_loss: 0.0795702490952674\n",
      "best loss: 0.0795702490952674\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 1.9817205935745754\n",
      "val_loss: 0.08008499264063644\n",
      "best loss: 0.0795702490952674\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 1.9761801240970345\n",
      "val_loss: 0.07964044320911239\n",
      "best loss: 0.0795702490952674\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 1.9698337873273717\n",
      "val_loss: 0.07943262047613493\n",
      "best loss: 0.07943262047613493\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 1.968457291114187\n",
      "val_loss: 0.07978908411703403\n",
      "best loss: 0.07943262047613493\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 1.964218367512702\n",
      "val_loss: 0.0797863308201743\n",
      "best loss: 0.07943262047613493\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 1.9576728588370105\n",
      "val_loss: 0.0796831073275911\n",
      "best loss: 0.07943262047613493\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 1.9554532834024856\n",
      "val_loss: 0.07961154064351726\n",
      "best loss: 0.07943262047613493\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 1.9493283431714878\n",
      "val_loss: 0.07965145315260232\n",
      "best loss: 0.07943262047613493\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 1.945201377783598\n",
      "val_loss: 0.07938444797728522\n",
      "best loss: 0.07938444797728522\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 1.9407156233458942\n",
      "val_loss: 0.07956336827740108\n",
      "best loss: 0.07938444797728522\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 1.935889484277103\n",
      "val_loss: 0.07972714949440074\n",
      "best loss: 0.07938444797728522\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 1.9325005520655787\n",
      "val_loss: 0.07938169716122964\n",
      "best loss: 0.07938169716122964\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 1.9274823913609889\n",
      "val_loss: 0.07949592870154717\n",
      "best loss: 0.07938169716122964\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 1.925133597018034\n",
      "val_loss: 0.07936655670089375\n",
      "best loss: 0.07936655670089375\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 1.920315397664876\n",
      "val_loss: 0.07952896204741326\n",
      "best loss: 0.07936655670089375\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 1.9164751175460057\n",
      "val_loss: 0.07992258655678951\n",
      "best loss: 0.07936655670089375\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 1.9130334633554849\n",
      "val_loss: 0.07947528681009658\n",
      "best loss: 0.07936655670089375\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 1.9119096934178557\n",
      "val_loss: 0.07942436334378755\n",
      "best loss: 0.07936655670089375\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 1.9049425523416808\n",
      "val_loss: 0.08013591585679383\n",
      "best loss: 0.07936655670089375\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 1.9035953373887708\n",
      "val_loss: 0.07950418464731521\n",
      "best loss: 0.07936655670089375\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 1.8990275944528623\n",
      "val_loss: 0.07967622625986485\n",
      "best loss: 0.07936655670089375\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 1.894467082199787\n",
      "val_loss: 0.07919176180796667\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 1.8902695714231013\n",
      "val_loss: 0.07933489873862373\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 45\n",
      "Train_loss: 1.886462425453206\n",
      "val_loss: 0.07994873807251383\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 1.8820610743038735\n",
      "val_loss: 0.07949730548117902\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 1.8794678739025976\n",
      "val_loss: 0.07986891415078097\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 1.8763978954357194\n",
      "val_loss: 0.07990744813938298\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 1.8720233492948894\n",
      "val_loss: 0.07984275855240686\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 1.8705142154285102\n",
      "val_loss: 0.07969962508128133\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 51\n",
      "Train_loss: 1.8653654550052623\n",
      "val_loss: 0.07982349181773846\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 52\n",
      "Train_loss: 1.8617677654171365\n",
      "val_loss: 0.0800629696927632\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 53\n",
      "Train_loss: 1.8601530806940032\n",
      "val_loss: 0.07961704278672545\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 54\n",
      "Train_loss: 1.8545043522757885\n",
      "val_loss: 0.0801028822129337\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 55\n",
      "Train_loss: 1.8417323915331152\n",
      "val_loss: 0.0798771686475657\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 56\n",
      "Train_loss: 1.8413164394751824\n",
      "val_loss: 0.07980147034714558\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 57\n",
      "Train_loss: 1.8402658424448637\n",
      "val_loss: 0.07978358001855895\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 58\n",
      "Train_loss: 1.839410104592549\n",
      "val_loss: 0.07970925562182907\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 59\n",
      "Train_loss: 1.840849377902556\n",
      "val_loss: 0.07979183753700045\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n",
      "epoch 60\n",
      "Train_loss: 1.8399254495924802\n",
      "val_loss: 0.07933077000697072\n",
      "best loss: 0.07919176180796667\n",
      "*********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61\n",
      "Train_loss: 1.8392538444165987\n",
      "val_loss: 0.07915322739126258\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 62\n",
      "Train_loss: 1.8379989195788244\n",
      "val_loss: 0.07920277132116661\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 63\n",
      "Train_loss: 1.838104404366549\n",
      "val_loss: 0.07927572056724046\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 64\n",
      "Train_loss: 1.8368728865435804\n",
      "val_loss: 0.07974091341067033\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 65\n",
      "Train_loss: 1.8371920847764096\n",
      "val_loss: 0.07922479499323978\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 66\n",
      "Train_loss: 1.836147548013685\n",
      "val_loss: 0.0792619560672351\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 67\n",
      "Train_loss: 1.836193676674927\n",
      "val_loss: 0.07926195238701585\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 68\n",
      "Train_loss: 1.8358255197708282\n",
      "val_loss: 0.0791945165504549\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 69\n",
      "Train_loss: 1.8358659735824199\n",
      "val_loss: 0.07922754793551137\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 70\n",
      "Train_loss: 1.8367734618951443\n",
      "val_loss: 0.07920139658986099\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 71\n",
      "Train_loss: 1.8349675913907133\n",
      "val_loss: 0.07930737109555802\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 72\n",
      "Train_loss: 1.835275768859369\n",
      "val_loss: 0.07976430766940841\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 73\n",
      "Train_loss: 1.8326888675272177\n",
      "val_loss: 0.07922617000576543\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 74\n",
      "Train_loss: 1.831318910340251\n",
      "val_loss: 0.07920965408934054\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 75\n",
      "Train_loss: 1.8320464604879516\n",
      "val_loss: 0.07922204047975334\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 76\n",
      "Train_loss: 1.83264907558381\n",
      "val_loss: 0.0792234185040172\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 77\n",
      "Train_loss: 1.8338081947122886\n",
      "val_loss: 0.0792302983440313\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 78\n",
      "Train_loss: 1.8333834101623268\n",
      "val_loss: 0.07923029840150053\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 79\n",
      "Train_loss: 1.8331330758773694\n",
      "val_loss: 0.07923029586045581\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 80\n",
      "Train_loss: 1.8333205267438104\n",
      "val_loss: 0.07922479477459411\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 81\n",
      "Train_loss: 1.8321889691919593\n",
      "val_loss: 0.07924956561328031\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "epoch 82\n",
      "Train_loss: 1.8323518857226457\n",
      "val_loss: 0.07924405977074508\n",
      "best loss: 0.07915322739126258\n",
      "*********************************\n",
      "RC 6\n",
      "initial loss: 0.12774070722301875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2617fb0cd7744f1db95a1fce2e035cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.358088693200608\n",
      "val_loss: 0.12623035398839844\n",
      "best loss: 0.12623035398839844\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.3209175500680206\n",
      "val_loss: 0.12598157187837944\n",
      "best loss: 0.12598157187837944\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.3005691665224086\n",
      "val_loss: 0.12576220808874164\n",
      "best loss: 0.12576220808874164\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.2845006476715515\n",
      "val_loss: 0.12600174875814935\n",
      "best loss: 0.12576220808874164\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.271457568366418\n",
      "val_loss: 0.12586138638693872\n",
      "best loss: 0.12576220808874164\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.2615163244929626\n",
      "val_loss: 0.1258479402326121\n",
      "best loss: 0.12576220808874164\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.2514487405945376\n",
      "val_loss: 0.1257193457932251\n",
      "best loss: 0.1257193457932251\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.2424534346072784\n",
      "val_loss: 0.12568572648909523\n",
      "best loss: 0.12568572648909523\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.2350267157121393\n",
      "val_loss: 0.12562100822016373\n",
      "best loss: 0.12562100822016373\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.2269248203112575\n",
      "val_loss: 0.12560587905383422\n",
      "best loss: 0.12560587905383422\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.2193936428132\n",
      "val_loss: 0.12546131769501948\n",
      "best loss: 0.12546131769501948\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.21203872027237\n",
      "val_loss: 0.12539323533667673\n",
      "best loss: 0.12539323533667673\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.204505750819598\n",
      "val_loss: 0.12541257249650914\n",
      "best loss: 0.12539323533667673\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.198358419395637\n",
      "val_loss: 0.12538819414067948\n",
      "best loss: 0.12538819414067948\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.1924465238187647\n",
      "val_loss: 0.1254075282148162\n",
      "best loss: 0.12538819414067948\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.1860430023258104\n",
      "val_loss: 0.12500409387460462\n",
      "best loss: 0.12500409387460462\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.179207704355983\n",
      "val_loss: 0.12498476280537357\n",
      "best loss: 0.12498476280537357\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.1739816462602417\n",
      "val_loss: 0.12518059453410407\n",
      "best loss: 0.12498476280537357\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.168937611762834\n",
      "val_loss: 0.12480322201252768\n",
      "best loss: 0.12480322201252768\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.1620543631120586\n",
      "val_loss: 0.12463260065948795\n",
      "best loss: 0.12463260065948795\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.157656675671658\n",
      "val_loss: 0.12448299764505497\n",
      "best loss: 0.12448299764505497\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.151447522477907\n",
      "val_loss: 0.12466285689891193\n",
      "best loss: 0.12448299764505497\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.1466824061477445\n",
      "val_loss: 0.12480574348247003\n",
      "best loss: 0.12448299764505497\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.1412423994472003\n",
      "val_loss: 0.12431574004454923\n",
      "best loss: 0.12431574004454923\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.1372132130933275\n",
      "val_loss: 0.12415772983968575\n",
      "best loss: 0.12415772983968575\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.1312058572588466\n",
      "val_loss: 0.12469479781628667\n",
      "best loss: 0.12415772983968575\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.1283585717825453\n",
      "val_loss: 0.1242518656136166\n",
      "best loss: 0.12415772983968575\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.1218261545293937\n",
      "val_loss: 0.1247553131793453\n",
      "best loss: 0.12415772983968575\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.1163967007399607\n",
      "val_loss: 0.12447375017735199\n",
      "best loss: 0.12415772983968575\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.1122238311503385\n",
      "val_loss: 0.12430313219317361\n",
      "best loss: 0.12415772983968575\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.1067398211492274\n",
      "val_loss: 0.12419806767496236\n",
      "best loss: 0.12415772983968575\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.1022986405931054\n",
      "val_loss: 0.1242787600348339\n",
      "best loss: 0.12415772983968575\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.0974026756384223\n",
      "val_loss: 0.12436196454494196\n",
      "best loss: 0.12415772983968575\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.0934314984808724\n",
      "val_loss: 0.12441575807844989\n",
      "best loss: 0.12415772983968575\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.0889802021827215\n",
      "val_loss: 0.12477632674047713\n",
      "best loss: 0.12415772983968575\n",
      "*********************************\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 35\n",
      "Train_loss: 2.085754031429745\n",
      "val_loss: 0.12453678650940175\n",
      "best loss: 0.12415772983968575\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.0725681293562843\n",
      "val_loss: 0.12420815627290882\n",
      "best loss: 0.12415772983968575\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.072140027445739\n",
      "val_loss: 0.1244418134815424\n",
      "best loss: 0.12415772983968575\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.0701935590632417\n",
      "val_loss: 0.1240930115116983\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.0703697521695155\n",
      "val_loss: 0.12420226911948995\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.069769988386666\n",
      "val_loss: 0.12421992433825414\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.0693517257360954\n",
      "val_loss: 0.12421739921726452\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.0685310127798227\n",
      "val_loss: 0.12420983734969365\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.0684580685893827\n",
      "val_loss: 0.1241594068607609\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 2.0673296526347684\n",
      "val_loss: 0.12442332316024995\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 45\n",
      "Train_loss: 2.067560431588476\n",
      "val_loss: 0.12417453853416247\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 2.0671119134287514\n",
      "val_loss: 0.12419723174645245\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 2.066131931414774\n",
      "val_loss: 0.12423169058248498\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 2.066595779538847\n",
      "val_loss: 0.12418882959546301\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 49\n",
      "Train_loss: 2.0656075351659546\n",
      "val_loss: 0.1242174028229732\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 2.0640833268413648\n",
      "val_loss: 0.12417201716843648\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 51\n",
      "Train_loss: 2.0643712233942106\n",
      "val_loss: 0.12415352569666643\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 52\n",
      "Train_loss: 2.06379448083105\n",
      "val_loss: 0.12413587537669574\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 53\n",
      "Train_loss: 2.064525270750203\n",
      "val_loss: 0.12412326694331172\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 54\n",
      "Train_loss: 2.063458691005162\n",
      "val_loss: 0.1241358761096843\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 55\n",
      "Train_loss: 2.0636723470144522\n",
      "val_loss: 0.12412662968138384\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 56\n",
      "Train_loss: 2.0637565429763876\n",
      "val_loss: 0.12411822459968722\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 57\n",
      "Train_loss: 2.0634959699554156\n",
      "val_loss: 0.12412242821734908\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 58\n",
      "Train_loss: 2.063527416466863\n",
      "val_loss: 0.12414596087478381\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "epoch 59\n",
      "Train_loss: 2.0639060206404727\n",
      "val_loss: 0.12412831230119464\n",
      "best loss: 0.1240930115116983\n",
      "*********************************\n",
      "RC 7\n",
      "initial loss: 0.1335152780637044\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b11c1984824e20a5e9ee7f2b8f0585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.250109491549032\n",
      "val_loss: 0.1334579991530112\n",
      "best loss: 0.1334579991530112\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.234819996668264\n",
      "val_loss: 0.13331861844984702\n",
      "best loss: 0.13331861844984702\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.22040857518802\n",
      "val_loss: 0.13343126771260458\n",
      "best loss: 0.13331861844984702\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.21673153737909\n",
      "val_loss: 0.13337017677675395\n",
      "best loss: 0.13331861844984702\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.204148754701693\n",
      "val_loss: 0.13307041960638044\n",
      "best loss: 0.13307041960638044\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.199157607700951\n",
      "val_loss: 0.13337017181091426\n",
      "best loss: 0.13307041960638044\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.189171820502426\n",
      "val_loss: 0.13312578530663755\n",
      "best loss: 0.13307041960638044\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.1840952683350885\n",
      "val_loss: 0.13348854797088525\n",
      "best loss: 0.13307041960638044\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.178906572121205\n",
      "val_loss: 0.13330334178764658\n",
      "best loss: 0.13307041960638044\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.1737507903841347\n",
      "val_loss: 0.13344845547685347\n",
      "best loss: 0.13307041960638044\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.1643601447900926\n",
      "val_loss: 0.1333396234179552\n",
      "best loss: 0.13307041960638044\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.1612755752649813\n",
      "val_loss: 0.13363364924205315\n",
      "best loss: 0.13307041960638044\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.1571953307233858\n",
      "val_loss: 0.13323653150876144\n",
      "best loss: 0.13307041960638044\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.151216874350681\n",
      "val_loss: 0.13383984278330466\n",
      "best loss: 0.13307041960638044\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.149274541491369\n",
      "val_loss: 0.13325943329894208\n",
      "best loss: 0.13307041960638044\n",
      "*********************************\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 15\n",
      "Train_loss: 2.141953034165506\n",
      "val_loss: 0.13359163639658558\n",
      "best loss: 0.13307041960638044\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.136679474181041\n",
      "val_loss: 0.13300169299696926\n",
      "best loss: 0.13300169299696926\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.135379045693614\n",
      "val_loss: 0.13303224142594494\n",
      "best loss: 0.13300169299696926\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.134351649431454\n",
      "val_loss: 0.13302841849908792\n",
      "best loss: 0.13300169299696926\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.1300343092267564\n",
      "val_loss: 0.13303032657452768\n",
      "best loss: 0.13300169299696926\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.1290359168463793\n",
      "val_loss: 0.13298260222874203\n",
      "best loss: 0.13298260222874203\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.1295717328241217\n",
      "val_loss: 0.13298641653387183\n",
      "best loss: 0.13298260222874203\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.1315223375353116\n",
      "val_loss: 0.13295968845353096\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.130456113621964\n",
      "val_loss: 0.13299978256669115\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.1317834054772393\n",
      "val_loss: 0.13298068932424473\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.131905629249236\n",
      "val_loss: 0.13303415164295618\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.130007108292123\n",
      "val_loss: 0.13310096792609227\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.127851088411318\n",
      "val_loss: 0.1330627819296493\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.1277369004729527\n",
      "val_loss: 0.13311051411369987\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.127143386715883\n",
      "val_loss: 0.13305133356077967\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.1257316608688006\n",
      "val_loss: 0.1331296110249836\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.1270977274781746\n",
      "val_loss: 0.1331162464109756\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.1249576809412054\n",
      "val_loss: 0.13309905849011522\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 33\n",
      "Train_loss: 2.126143529790119\n",
      "val_loss: 0.133181157968216\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.1212483629513352\n",
      "val_loss: 0.13319070235216068\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.1235456552840897\n",
      "val_loss: 0.13318115960231758\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.120071749845646\n",
      "val_loss: 0.13316587820939707\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.1203385012452944\n",
      "val_loss: 0.13316015308023463\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.12307399952114\n",
      "val_loss: 0.13316015422669572\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.1226593203958037\n",
      "val_loss: 0.13316015582923219\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.122377408168795\n",
      "val_loss: 0.13316779046357213\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.1249536502680795\n",
      "val_loss: 0.13316397431431132\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.1225270787431954\n",
      "val_loss: 0.13317733143888935\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.1231442214373004\n",
      "val_loss: 0.13315824836931212\n",
      "best loss: 0.13295968845353096\n",
      "*********************************\n",
      "RC 8\n",
      "initial loss: 0.13475517663733277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62ad5b5a18549daab60b207c570fdf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.2359419846410686\n",
      "val_loss: 0.1343689009758195\n",
      "best loss: 0.1343689009758195\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.21508984500339\n",
      "val_loss: 0.1343026424719216\n",
      "best loss: 0.1343026424719216\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.2027489140112873\n",
      "val_loss: 0.13447745439533798\n",
      "best loss: 0.1343026424719216\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.192578002300423\n",
      "val_loss: 0.13442106829440573\n",
      "best loss: 0.1343026424719216\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.1823349305525093\n",
      "val_loss: 0.1346113829597624\n",
      "best loss: 0.1343026424719216\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.1725057073381038\n",
      "val_loss: 0.1341630818022443\n",
      "best loss: 0.1341630818022443\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.1677463059660074\n",
      "val_loss: 0.1350385446812301\n",
      "best loss: 0.1341630818022443\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.1589262280056736\n",
      "val_loss: 0.13442247354101952\n",
      "best loss: 0.1341630818022443\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.150356487462473\n",
      "val_loss: 0.1349567761419865\n",
      "best loss: 0.1341630818022443\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.143154791253517\n",
      "val_loss: 0.13499342930191902\n",
      "best loss: 0.1341630818022443\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.140823393904924\n",
      "val_loss: 0.13453384358658485\n",
      "best loss: 0.1341630818022443\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.137818138327507\n",
      "val_loss: 0.13477492340645947\n",
      "best loss: 0.1341630818022443\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.1297349538058694\n",
      "val_loss: 0.13506250794200936\n",
      "best loss: 0.1341630818022443\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.125572731512371\n",
      "val_loss: 0.1345282085526747\n",
      "best loss: 0.1341630818022443\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.115520129185173\n",
      "val_loss: 0.13416307398263078\n",
      "best loss: 0.13416307398263078\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.1131750021947577\n",
      "val_loss: 0.1343519840229028\n",
      "best loss: 0.13416307398263078\n",
      "*********************************\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 16\n",
      "Train_loss: 2.1081578553266445\n",
      "val_loss: 0.13522604175418163\n",
      "best loss: 0.13416307398263078\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.0989002641261423\n",
      "val_loss: 0.13399672840787719\n",
      "best loss: 0.13399672840787719\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.0985210524471847\n",
      "val_loss: 0.134487322076475\n",
      "best loss: 0.13399672840787719\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.0956122135591277\n",
      "val_loss: 0.13448309740215228\n",
      "best loss: 0.13399672840787719\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.096474940104793\n",
      "val_loss: 0.134449258871903\n",
      "best loss: 0.13399672840787719\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.0969793840234408\n",
      "val_loss: 0.13395584380343645\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.09265311560563\n",
      "val_loss: 0.13448027857475678\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.0956147868529187\n",
      "val_loss: 0.13446758916386245\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.094762063337326\n",
      "val_loss: 0.13463112151753293\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.0935731723416255\n",
      "val_loss: 0.13453244126115804\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.094180132530299\n",
      "val_loss: 0.13448590939511768\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.0936037826706073\n",
      "val_loss: 0.13448168279554865\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.092984991944622\n",
      "val_loss: 0.13408272063386958\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.092196068649602\n",
      "val_loss: 0.13412501136641977\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.091852432990886\n",
      "val_loss: 0.1346085610372713\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.089159715019939\n",
      "val_loss: 0.13448591335706717\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 32\n",
      "Train_loss: 2.089726733421154\n",
      "val_loss: 0.13397276107279513\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.088236985301581\n",
      "val_loss: 0.13402350869182453\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.090338306403509\n",
      "val_loss: 0.13454089642618083\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.092352544103916\n",
      "val_loss: 0.13460715407726903\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.086748520000273\n",
      "val_loss: 0.13460433327771376\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.0896227509035166\n",
      "val_loss: 0.13457896456294513\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.089133154103789\n",
      "val_loss: 0.13455218007471173\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.0899046610315652\n",
      "val_loss: 0.1345733204400677\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.087612950456765\n",
      "val_loss: 0.13461138675766404\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.0893504698782346\n",
      "val_loss: 0.13457755304247276\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.0862563806952252\n",
      "val_loss: 0.1345620459253259\n",
      "best loss: 0.13395584380343645\n",
      "*********************************\n",
      "fold 2, score: 0.13688828418769142\n",
      "fold: 3\n",
      "RC 0\n",
      "initial loss: 0.13235893818378888\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abff4771566d459aa8df1a690fb735a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.5319979988063674\n",
      "val_loss: 0.13140300134466795\n",
      "best loss: 0.13140300134466795\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.49161121744298\n",
      "val_loss: 0.13080661106451807\n",
      "best loss: 0.13080661106451807\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.4740242169697884\n",
      "val_loss: 0.1305654692006476\n",
      "best loss: 0.1305654692006476\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.4605974228389\n",
      "val_loss: 0.13041672652459702\n",
      "best loss: 0.13041672652459702\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.448742604601125\n",
      "val_loss: 0.13052069735031813\n",
      "best loss: 0.13041672652459702\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.439064066170397\n",
      "val_loss: 0.13059434313814877\n",
      "best loss: 0.13041672652459702\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.4300581351768713\n",
      "val_loss: 0.13077628855142331\n",
      "best loss: 0.13041672652459702\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.4212781912114405\n",
      "val_loss: 0.13046293587603583\n",
      "best loss: 0.13041672652459702\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.414559479897772\n",
      "val_loss: 0.13055102300219093\n",
      "best loss: 0.13041672652459702\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.407268981659259\n",
      "val_loss: 0.1304557174050895\n",
      "best loss: 0.13041672652459702\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.4000016847114902\n",
      "val_loss: 0.1304282774566637\n",
      "best loss: 0.13041672652459702\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.3940724270528912\n",
      "val_loss: 0.1305553507193337\n",
      "best loss: 0.13041672652459702\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.386632148897625\n",
      "val_loss: 0.13040661724674343\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.381081981836072\n",
      "val_loss: 0.13043261380475735\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 14\n",
      "Train_loss: 2.373855314798312\n",
      "val_loss: 0.1305582402052301\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.3633744946354796\n",
      "val_loss: 0.13052358938702643\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.362432861463398\n",
      "val_loss: 0.13047448723675767\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.361676850932771\n",
      "val_loss: 0.13049470770220695\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.3607163401886635\n",
      "val_loss: 0.1305770089077952\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.3597842050757736\n",
      "val_loss: 0.1305019176807004\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.3596611310222744\n",
      "val_loss: 0.13051924974528184\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.358113877050456\n",
      "val_loss: 0.13055246687589198\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.3580406316751534\n",
      "val_loss: 0.13053513934210828\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.356382601840457\n",
      "val_loss: 0.1304297230774291\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.355697316253977\n",
      "val_loss: 0.13053513541932443\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 25\n",
      "Train_loss: 2.35555772879903\n",
      "val_loss: 0.13053513518931062\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.3534361348811643\n",
      "val_loss: 0.1305250297747097\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.354139892010997\n",
      "val_loss: 0.13051492691183894\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.3541651506198322\n",
      "val_loss: 0.13052214287757824\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.3544007210760234\n",
      "val_loss: 0.13049325633186132\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.354098244045304\n",
      "val_loss: 0.13054236277572132\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.3537937160821447\n",
      "val_loss: 0.13052213935207707\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.3539490948579083\n",
      "val_loss: 0.13051636477487955\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.3536215920415517\n",
      "val_loss: 0.13052936700261006\n",
      "best loss: 0.13040661724674343\n",
      "*********************************\n",
      "RC 1\n",
      "initial loss: 0.1382038815217941\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.4076128638083825\n",
      "val_loss: 0.13765155064623766\n",
      "best loss: 0.13765155064623766\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.3757203912609577\n",
      "val_loss: 0.13726566760596653\n",
      "best loss: 0.13726566760596653\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.358008182236368\n",
      "val_loss: 0.13730349605357256\n",
      "best loss: 0.13726566760596653\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.34817840446869\n",
      "val_loss: 0.1372845828443363\n",
      "best loss: 0.13726566760596653\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.335458022975501\n",
      "val_loss: 0.13720702838210982\n",
      "best loss: 0.13720702838210982\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.327963282384586\n",
      "val_loss: 0.1371332561634415\n",
      "best loss: 0.1371332561634415\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.3163436072533736\n",
      "val_loss: 0.13714082690755397\n",
      "best loss: 0.1371332561634415\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.30847474889305\n",
      "val_loss: 0.1374207746484292\n",
      "best loss: 0.1371332561634415\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.3027212316678725\n",
      "val_loss: 0.13738294781859708\n",
      "best loss: 0.1371332561634415\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.2940008065057595\n",
      "val_loss: 0.13732430694569353\n",
      "best loss: 0.1371332561634415\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.2860666634075972\n",
      "val_loss: 0.13726944826943865\n",
      "best loss: 0.1371332561634415\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.2823775354531954\n",
      "val_loss: 0.13709731570370376\n",
      "best loss: 0.13709731570370376\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.2743366029129035\n",
      "val_loss: 0.13757021059625174\n",
      "best loss: 0.13709731570370376\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.2711997659766388\n",
      "val_loss: 0.13713515041953223\n",
      "best loss: 0.13709731570370376\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.2634525932798613\n",
      "val_loss: 0.1373753751908906\n",
      "best loss: 0.13709731570370376\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.255654313489261\n",
      "val_loss: 0.13724675359205313\n",
      "best loss: 0.13709731570370376\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.2531519868675236\n",
      "val_loss: 0.13718621324448502\n",
      "best loss: 0.13709731570370376\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.2451863332872715\n",
      "val_loss: 0.13695545630273023\n",
      "best loss: 0.13695545630273023\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.2400690961935332\n",
      "val_loss: 0.13711623317849064\n",
      "best loss: 0.13695545630273023\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.2346702365603077\n",
      "val_loss: 0.13715217974206728\n",
      "best loss: 0.13695545630273023\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.2279953393593703\n",
      "val_loss: 0.13762128768527956\n",
      "best loss: 0.13695545630273023\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.2266226303063315\n",
      "val_loss: 0.13708408022739335\n",
      "best loss: 0.13695545630273023\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.215480999556417\n",
      "val_loss: 0.13725620468862218\n",
      "best loss: 0.13695545630273023\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.209510683670357\n",
      "val_loss: 0.13715216641938835\n",
      "best loss: 0.13695545630273023\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.2079731909521105\n",
      "val_loss: 0.13719946461026214\n",
      "best loss: 0.13695545630273023\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.201076056767352\n",
      "val_loss: 0.13689492506240739\n",
      "best loss: 0.13689492506240739\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.196403295134068\n",
      "val_loss: 0.1373053934686325\n",
      "best loss: 0.13689492506240739\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.18874726135744\n",
      "val_loss: 0.13763074085909435\n",
      "best loss: 0.13689492506240739\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.185015196191381\n",
      "val_loss: 0.13694977493532595\n",
      "best loss: 0.13689492506240739\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.1779199309254973\n",
      "val_loss: 0.13685708817391057\n",
      "best loss: 0.13685708817391057\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.175017148444366\n",
      "val_loss: 0.13703111294695683\n",
      "best loss: 0.13685708817391057\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.172119386269873\n",
      "val_loss: 0.1370670530358294\n",
      "best loss: 0.13685708817391057\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.167752744871162\n",
      "val_loss: 0.13742834476788449\n",
      "best loss: 0.13685708817391057\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.161420464503407\n",
      "val_loss: 0.13706326697576818\n",
      "best loss: 0.13685708817391057\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.155457224944177\n",
      "val_loss: 0.13701787775210297\n",
      "best loss: 0.13685708817391057\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.151213564000877\n",
      "val_loss: 0.13732431151595495\n",
      "best loss: 0.13685708817391057\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.1470855232366675\n",
      "val_loss: 0.13713137039635376\n",
      "best loss: 0.13685708817391057\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.1396210865411147\n",
      "val_loss: 0.1367908935080379\n",
      "best loss: 0.1367908935080379\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.134429093088984\n",
      "val_loss: 0.13666036593537473\n",
      "best loss: 0.13666036593537473\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.1320777595344\n",
      "val_loss: 0.13663010552677074\n",
      "best loss: 0.13663010552677074\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.12593637820916\n",
      "val_loss: 0.1371332575598991\n",
      "best loss: 0.13663010552677074\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.122214664564081\n",
      "val_loss: 0.13697626296819132\n",
      "best loss: 0.13663010552677074\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.1176524951452067\n",
      "val_loss: 0.1373678215570928\n",
      "best loss: 0.13663010552677074\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.1155086188891574\n",
      "val_loss: 0.137294045982596\n",
      "best loss: 0.13663010552677074\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 2.1096395415880576\n",
      "val_loss: 0.1370557145315454\n",
      "best loss: 0.13663010552677074\n",
      "*********************************\n",
      "epoch 45\n",
      "Train_loss: 2.1053408409453933\n",
      "val_loss: 0.1370632730098444\n",
      "best loss: 0.13663010552677074\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 2.0992412408621384\n",
      "val_loss: 0.13667360885103957\n",
      "best loss: 0.13663010552677074\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 2.0965966197400308\n",
      "val_loss: 0.13707839810342415\n",
      "best loss: 0.13663010552677074\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 2.0926451631145975\n",
      "val_loss: 0.13653741693187824\n",
      "best loss: 0.13653741693187824\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 2.086069880052582\n",
      "val_loss: 0.13687978973936446\n",
      "best loss: 0.13653741693187824\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 2.084157471551231\n",
      "val_loss: 0.13652417211257262\n",
      "best loss: 0.13652417211257262\n",
      "*********************************\n",
      "epoch 51\n",
      "Train_loss: 2.078758329417052\n",
      "val_loss: 0.13665091505290514\n",
      "best loss: 0.13652417211257262\n",
      "*********************************\n",
      "epoch 52\n",
      "Train_loss: 2.0732414747999286\n",
      "val_loss: 0.13689870964181453\n",
      "best loss: 0.13652417211257262\n",
      "*********************************\n",
      "epoch 53\n",
      "Train_loss: 2.0709178265714163\n",
      "val_loss: 0.13659416757889264\n",
      "best loss: 0.13652417211257262\n",
      "*********************************\n",
      "epoch 54\n",
      "Train_loss: 2.066420362319162\n",
      "val_loss: 0.1362877293863094\n",
      "best loss: 0.1362877293863094\n",
      "*********************************\n",
      "epoch 55\n",
      "Train_loss: 2.0609882587829467\n",
      "val_loss: 0.13619126201995843\n",
      "best loss: 0.13619126201995843\n",
      "*********************************\n",
      "epoch 56\n",
      "Train_loss: 2.0594146170361083\n",
      "val_loss: 0.13642959416983927\n",
      "best loss: 0.13619126201995843\n",
      "*********************************\n",
      "epoch 57\n",
      "Train_loss: 2.052634936437484\n",
      "val_loss: 0.13685710020597877\n",
      "best loss: 0.13619126201995843\n",
      "*********************************\n",
      "epoch 58\n",
      "Train_loss: 2.0518989846730262\n",
      "val_loss: 0.1365582238483248\n",
      "best loss: 0.13619126201995843\n",
      "*********************************\n",
      "epoch 59\n",
      "Train_loss: 2.0458741733963386\n",
      "val_loss: 0.13632178214885687\n",
      "best loss: 0.13619126201995843\n",
      "*********************************\n",
      "epoch 60\n",
      "Train_loss: 2.0414371619964498\n",
      "val_loss: 0.1364636425970734\n",
      "best loss: 0.13619126201995843\n",
      "*********************************\n",
      "epoch 61\n",
      "Train_loss: 2.035546588925703\n",
      "val_loss: 0.13642203514145707\n",
      "best loss: 0.13619126201995843\n",
      "*********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62\n",
      "Train_loss: 2.0273366318142103\n",
      "val_loss: 0.13654688172880725\n",
      "best loss: 0.13619126201995843\n",
      "*********************************\n",
      "epoch 63\n",
      "Train_loss: 2.027167390173227\n",
      "val_loss: 0.13652606757146926\n",
      "best loss: 0.13619126201995843\n",
      "*********************************\n",
      "epoch 64\n",
      "Train_loss: 2.0204872309670012\n",
      "val_loss: 0.136041824708154\n",
      "best loss: 0.136041824708154\n",
      "*********************************\n",
      "epoch 65\n",
      "Train_loss: 2.017887701017333\n",
      "val_loss: 0.1369913939013937\n",
      "best loss: 0.136041824708154\n",
      "*********************************\n",
      "epoch 66\n",
      "Train_loss: 2.021271436548239\n",
      "val_loss: 0.13647689278129418\n",
      "best loss: 0.136041824708154\n",
      "*********************************\n",
      "epoch 67\n",
      "Train_loss: 2.013286276417766\n",
      "val_loss: 0.136446616641192\n",
      "best loss: 0.136041824708154\n",
      "*********************************\n",
      "epoch 68\n",
      "Train_loss: 2.00883226898676\n",
      "val_loss: 0.13645797941769786\n",
      "best loss: 0.136041824708154\n",
      "*********************************\n",
      "epoch 69\n",
      "Train_loss: 2.005314535052886\n",
      "val_loss: 0.13645040419834562\n",
      "best loss: 0.136041824708154\n",
      "*********************************\n",
      "epoch 70\n",
      "Train_loss: 2.0006092753304334\n",
      "val_loss: 0.13637095551049946\n",
      "best loss: 0.136041824708154\n",
      "*********************************\n",
      "epoch 71\n",
      "Train_loss: 1.9975118980296833\n",
      "val_loss: 0.13665279827605842\n",
      "best loss: 0.136041824708154\n",
      "*********************************\n",
      "epoch 72\n",
      "Train_loss: 1.994217087930536\n",
      "val_loss: 0.13647689485012032\n",
      "best loss: 0.136041824708154\n",
      "*********************************\n",
      "epoch 73\n",
      "Train_loss: 1.9906454656861154\n",
      "val_loss: 0.1362177380083266\n",
      "best loss: 0.136041824708154\n",
      "*********************************\n",
      "epoch 74\n",
      "Train_loss: 1.9845198355899099\n",
      "val_loss: 0.13626692346859265\n",
      "best loss: 0.136041824708154\n",
      "*********************************\n",
      "epoch 75\n",
      "Train_loss: 1.9795124399151534\n",
      "val_loss: 0.13587536326873317\n",
      "best loss: 0.13587536326873317\n",
      "*********************************\n",
      "epoch 76\n",
      "Train_loss: 1.976527725832184\n",
      "val_loss: 0.13612505644543824\n",
      "best loss: 0.13587536326873317\n",
      "*********************************\n",
      "epoch 77\n",
      "Train_loss: 1.9715735735521998\n",
      "val_loss: 0.1365128240864763\n",
      "best loss: 0.13587536326873317\n",
      "*********************************\n",
      "epoch 78\n",
      "Train_loss: 1.9679552643988374\n",
      "val_loss: 0.1362253077917981\n",
      "best loss: 0.13587536326873317\n",
      "*********************************\n",
      "epoch 79\n",
      "Train_loss: 1.9676399255321881\n",
      "val_loss: 0.13615909635881135\n",
      "best loss: 0.13587536326873317\n",
      "*********************************\n",
      "epoch 80\n",
      "Train_loss: 1.962590797491442\n",
      "val_loss: 0.1364125693830852\n",
      "best loss: 0.13587536326873317\n",
      "*********************************\n",
      "epoch 81\n",
      "Train_loss: 1.9561286594182241\n",
      "val_loss: 0.13630853986105673\n",
      "best loss: 0.13587536326873317\n",
      "*********************************\n",
      "epoch 82\n",
      "Train_loss: 1.9540660574449416\n",
      "val_loss: 0.13612883782658453\n",
      "best loss: 0.13587536326873317\n",
      "*********************************\n",
      "epoch 83\n",
      "Train_loss: 1.9518921387610266\n",
      "val_loss: 0.1364504042789336\n",
      "best loss: 0.13587536326873317\n",
      "*********************************\n",
      "epoch 84\n",
      "Train_loss: 1.9474665631152486\n",
      "val_loss: 0.1364579778107492\n",
      "best loss: 0.13587536326873317\n",
      "*********************************\n",
      "epoch 85\n",
      "Train_loss: 1.940836222252094\n",
      "val_loss: 0.1358545637315007\n",
      "best loss: 0.1358545637315007\n",
      "*********************************\n",
      "epoch 86\n",
      "Train_loss: 1.9368657064803927\n",
      "val_loss: 0.1362896214701327\n",
      "best loss: 0.1358545637315007\n",
      "*********************************\n",
      "epoch 87\n",
      "Train_loss: 1.9351666538990375\n",
      "val_loss: 0.135735389463648\n",
      "best loss: 0.135735389463648\n",
      "*********************************\n",
      "epoch 88\n",
      "Train_loss: 1.9327104662382184\n",
      "val_loss: 0.13606641306668907\n",
      "best loss: 0.135735389463648\n",
      "*********************************\n",
      "epoch 89\n",
      "Train_loss: 1.927834411696839\n",
      "val_loss: 0.1360210170491753\n",
      "best loss: 0.135735389463648\n",
      "*********************************\n",
      "epoch 90\n",
      "Train_loss: 1.9216574230782075\n",
      "val_loss: 0.13609856810385268\n",
      "best loss: 0.135735389463648\n",
      "*********************************\n",
      "epoch 91\n",
      "Train_loss: 1.9203858094851716\n",
      "val_loss: 0.13591319909034116\n",
      "best loss: 0.135735389463648\n",
      "*********************************\n",
      "epoch 92\n",
      "Train_loss: 1.916957115971474\n",
      "val_loss: 0.13622909001891786\n",
      "best loss: 0.135735389463648\n",
      "*********************************\n",
      "epoch 93\n",
      "Train_loss: 1.913358449716512\n",
      "val_loss: 0.13595859693451615\n",
      "best loss: 0.135735389463648\n",
      "*********************************\n",
      "epoch 94\n",
      "Train_loss: 1.9110078346350277\n",
      "val_loss: 0.13592265548126078\n",
      "best loss: 0.135735389463648\n",
      "*********************************\n",
      "epoch 95\n",
      "Train_loss: 1.9046423281363696\n",
      "val_loss: 0.13613450891761628\n",
      "best loss: 0.135735389463648\n",
      "*********************************\n",
      "epoch 96\n",
      "Train_loss: 1.9041356678306944\n",
      "val_loss: 0.13586022990746666\n",
      "best loss: 0.135735389463648\n",
      "*********************************\n",
      "epoch 97\n",
      "Train_loss: 1.9029543514368674\n",
      "val_loss: 0.1362820571991206\n",
      "best loss: 0.135735389463648\n",
      "*********************************\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 98\n",
      "Train_loss: 1.8963518651842985\n",
      "val_loss: 0.13614775096405338\n",
      "best loss: 0.135735389463648\n",
      "*********************************\n",
      "epoch 99\n",
      "Train_loss: 1.8829492056929484\n",
      "val_loss: 0.135969943662384\n",
      "best loss: 0.135735389463648\n",
      "*********************************\n",
      "RC 2\n",
      "initial loss: 0.20633630975251596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9dacd98edfe4b4bb69b6cb7ea3b4144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.793462978482492\n",
      "val_loss: 0.20495663584209797\n",
      "best loss: 0.20495663584209797\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.7645801954284073\n",
      "val_loss: 0.20561557851704135\n",
      "best loss: 0.20495663584209797\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.7464707306205622\n",
      "val_loss: 0.20473149288063797\n",
      "best loss: 0.20473149288063797\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.7283612451927852\n",
      "val_loss: 0.20411235785238727\n",
      "best loss: 0.20411235785238727\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.7184046854254533\n",
      "val_loss: 0.20417276282162433\n",
      "best loss: 0.20411235785238727\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.7064901556417156\n",
      "val_loss: 0.20386661959885155\n",
      "best loss: 0.20386661959885155\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.69599008126178\n",
      "val_loss: 0.20420571085421327\n",
      "best loss: 0.20386661959885155\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.6840239603328744\n",
      "val_loss: 0.20402173954448624\n",
      "best loss: 0.20386661959885155\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.677405184404459\n",
      "val_loss: 0.20363048733188593\n",
      "best loss: 0.20363048733188593\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.6699171957778334\n",
      "val_loss: 0.20392840000957374\n",
      "best loss: 0.20363048733188593\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.6627535425419078\n",
      "val_loss: 0.2038666257592203\n",
      "best loss: 0.20363048733188593\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.6540975114974175\n",
      "val_loss: 0.20372521741167685\n",
      "best loss: 0.20363048733188593\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.6459272201049884\n",
      "val_loss: 0.2040190048101148\n",
      "best loss: 0.20363048733188593\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.6378453499996257\n",
      "val_loss: 0.20377051637516522\n",
      "best loss: 0.20363048733188593\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.6318634196724773\n",
      "val_loss: 0.20343143018491797\n",
      "best loss: 0.20343143018491797\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.626904427514542\n",
      "val_loss: 0.2035851920801572\n",
      "best loss: 0.20343143018491797\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.6184982073415664\n",
      "val_loss: 0.2039489911924091\n",
      "best loss: 0.20343143018491797\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.611619034262297\n",
      "val_loss: 0.20368129210013752\n",
      "best loss: 0.20343143018491797\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.607195965026301\n",
      "val_loss: 0.20348223277517324\n",
      "best loss: 0.20343143018491797\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.600786394451572\n",
      "val_loss: 0.20354539171673083\n",
      "best loss: 0.20343143018491797\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.5939242514335326\n",
      "val_loss: 0.20320903801855178\n",
      "best loss: 0.20320903801855178\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.5884299248378717\n",
      "val_loss: 0.20399566433597788\n",
      "best loss: 0.20320903801855178\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.5824862020493384\n",
      "val_loss: 0.20339300643301317\n",
      "best loss: 0.20320903801855178\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.5769158737447913\n",
      "val_loss: 0.20396271155515328\n",
      "best loss: 0.20320903801855178\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.5687728487122583\n",
      "val_loss: 0.20326120157832864\n",
      "best loss: 0.20320903801855178\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.565395917766375\n",
      "val_loss: 0.20357420860708422\n",
      "best loss: 0.20320903801855178\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.55908086522198\n",
      "val_loss: 0.20334357218051233\n",
      "best loss: 0.20320903801855178\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.5519864838769535\n",
      "val_loss: 0.203235111674092\n",
      "best loss: 0.20320903801855178\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.546819204764594\n",
      "val_loss: 0.20369090691741334\n",
      "best loss: 0.20320903801855178\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.543178088288104\n",
      "val_loss: 0.20297840205725923\n",
      "best loss: 0.20297840205725923\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.536660971294234\n",
      "val_loss: 0.20353028267022572\n",
      "best loss: 0.20297840205725923\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.532102939228772\n",
      "val_loss: 0.20367716188322307\n",
      "best loss: 0.20297840205725923\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.528658782389758\n",
      "val_loss: 0.2031184404410438\n",
      "best loss: 0.20297840205725923\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.5213540786371134\n",
      "val_loss: 0.20335867720303463\n",
      "best loss: 0.20297840205725923\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.5172952046008574\n",
      "val_loss: 0.2029756543928351\n",
      "best loss: 0.2029756543928351\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.5106228489894016\n",
      "val_loss: 0.20304566882645286\n",
      "best loss: 0.2029756543928351\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.5047041128053067\n",
      "val_loss: 0.20318158461529165\n",
      "best loss: 0.2029756543928351\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.4982417178985132\n",
      "val_loss: 0.20314588531621894\n",
      "best loss: 0.2029756543928351\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.4938864236576253\n",
      "val_loss: 0.20374855445747006\n",
      "best loss: 0.2029756543928351\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.490117273150854\n",
      "val_loss: 0.20304429928228926\n",
      "best loss: 0.2029756543928351\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.4844595527804056\n",
      "val_loss: 0.20284524119894293\n",
      "best loss: 0.20284524119894293\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.479337246857762\n",
      "val_loss: 0.20345889829001698\n",
      "best loss: 0.20284524119894293\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.4768063690982953\n",
      "val_loss: 0.20333945926826602\n",
      "best loss: 0.20284524119894293\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.4711687556763633\n",
      "val_loss: 0.2036922648359942\n",
      "best loss: 0.20284524119894293\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 2.462094610551904\n",
      "val_loss: 0.20300586454670683\n",
      "best loss: 0.20284524119894293\n",
      "*********************************\n",
      "epoch 45\n",
      "Train_loss: 2.4606668917203347\n",
      "val_loss: 0.2028397475673896\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 2.458340464750909\n",
      "val_loss: 0.20298390293774302\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 2.4503206799099\n",
      "val_loss: 0.20305527787560296\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 2.4449336669359907\n",
      "val_loss: 0.20349458773500215\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 2.4420323161036275\n",
      "val_loss: 0.2030031194734727\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 2.439166235726347\n",
      "val_loss: 0.2032598260489671\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 51\n",
      "Train_loss: 2.4303566507514\n",
      "val_loss: 0.2032543436853803\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 52\n",
      "Train_loss: 2.4199752247125255\n",
      "val_loss: 0.20316785506189766\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 53\n",
      "Train_loss: 2.4186052597570473\n",
      "val_loss: 0.2031349077253364\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 54\n",
      "Train_loss: 2.417196096017006\n",
      "val_loss: 0.2031321630772262\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 55\n",
      "Train_loss: 2.4177750544665315\n",
      "val_loss: 0.20304430427844114\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 56\n",
      "Train_loss: 2.415255975604689\n",
      "val_loss: 0.20320355043359345\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 57\n",
      "Train_loss: 2.4172876817988525\n",
      "val_loss: 0.20294272206888095\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 58\n",
      "Train_loss: 2.41648601066006\n",
      "val_loss: 0.20299350418684375\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 59\n",
      "Train_loss: 2.4159750744378976\n",
      "val_loss: 0.203140393421534\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 60\n",
      "Train_loss: 2.4140954395285044\n",
      "val_loss: 0.2029619363076029\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61\n",
      "Train_loss: 2.4133230509327226\n",
      "val_loss: 0.20304980325794295\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 62\n",
      "Train_loss: 2.4113355851162437\n",
      "val_loss: 0.20298251677562754\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 63\n",
      "Train_loss: 2.411233169866518\n",
      "val_loss: 0.20296056999100578\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 64\n",
      "Train_loss: 2.4114771486934727\n",
      "val_loss: 0.20299762371426283\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 65\n",
      "Train_loss: 2.4124605220576534\n",
      "val_loss: 0.20301135565952452\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "epoch 66\n",
      "Train_loss: 2.41187621606489\n",
      "val_loss: 0.20296879624004036\n",
      "best loss: 0.2028397475673896\n",
      "*********************************\n",
      "RC 3\n",
      "initial loss: 0.22119709825112285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09fc989680a4b4da1f0dd51f970463d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.7721487663456728\n",
      "val_loss: 0.2200435173315424\n",
      "best loss: 0.2200435173315424\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.733301702567087\n",
      "val_loss: 0.22028227393599578\n",
      "best loss: 0.2200435173315424\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.711408803617722\n",
      "val_loss: 0.21982000809054503\n",
      "best loss: 0.21982000809054503\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.6945425209787346\n",
      "val_loss: 0.21983666438802457\n",
      "best loss: 0.21982000809054503\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.6802998885258096\n",
      "val_loss: 0.2192189256455537\n",
      "best loss: 0.2192189256455537\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.668544168494793\n",
      "val_loss: 0.21899958942792047\n",
      "best loss: 0.21899958942792047\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.6565611266671483\n",
      "val_loss: 0.21894822540510686\n",
      "best loss: 0.21894822540510686\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.647377064794143\n",
      "val_loss: 0.21875666589056234\n",
      "best loss: 0.21875666589056234\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.638076279307774\n",
      "val_loss: 0.21915784124364796\n",
      "best loss: 0.21875666589056234\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.6283618506974458\n",
      "val_loss: 0.21870529280635503\n",
      "best loss: 0.21870529280635503\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.620034492792737\n",
      "val_loss: 0.21810420672221198\n",
      "best loss: 0.21810420672221198\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.612776593763258\n",
      "val_loss: 0.2180223033446223\n",
      "best loss: 0.2180223033446223\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.6042796719819843\n",
      "val_loss: 0.21815140675127728\n",
      "best loss: 0.2180223033446223\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.597157995330407\n",
      "val_loss: 0.21788348459742907\n",
      "best loss: 0.21788348459742907\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.590924540971122\n",
      "val_loss: 0.21788348667917218\n",
      "best loss: 0.21788348459742907\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.5826330118042367\n",
      "val_loss: 0.21798898567521213\n",
      "best loss: 0.21788348459742907\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.576339905995657\n",
      "val_loss: 0.21793207683948662\n",
      "best loss: 0.21788348459742907\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.5692634126900398\n",
      "val_loss: 0.21812919336110262\n",
      "best loss: 0.21788348459742907\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.563678715620588\n",
      "val_loss: 0.21780436595477518\n",
      "best loss: 0.21780436595477518\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.5564708179870155\n",
      "val_loss: 0.21807228297267628\n",
      "best loss: 0.21780436595477518\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.5499187583481873\n",
      "val_loss: 0.21791957386752087\n",
      "best loss: 0.21780436595477518\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.542734167932366\n",
      "val_loss: 0.2176724811360289\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.5360419275702455\n",
      "val_loss: 0.217782154147608\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.530888699668329\n",
      "val_loss: 0.2184734612369656\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.5247282297581917\n",
      "val_loss: 0.21853593455903153\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.5207339687958172\n",
      "val_loss: 0.2187469416166245\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.512594031829746\n",
      "val_loss: 0.21842488350443673\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.5065183723723186\n",
      "val_loss: 0.21868586580474106\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.5008088309191407\n",
      "val_loss: 0.21899403921924815\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.494552405917618\n",
      "val_loss: 0.21904262889759862\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.488934977134311\n",
      "val_loss: 0.21868030084320417\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.483612547370882\n",
      "val_loss: 0.21899682138841717\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 32\n",
      "Train_loss: 2.478688276507946\n",
      "val_loss: 0.21900237398719538\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.46424595545307\n",
      "val_loss: 0.21880107609288066\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.4627389852076575\n",
      "val_loss: 0.21889825933707133\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.4631322118380163\n",
      "val_loss: 0.21880108952402227\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.4609532292914302\n",
      "val_loss: 0.2190231909064408\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.461658048858574\n",
      "val_loss: 0.21896906072460728\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.4602067479083805\n",
      "val_loss: 0.21905928627876153\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.460572071842847\n",
      "val_loss: 0.21896072037611738\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.4592391503594104\n",
      "val_loss: 0.21883994851284108\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.458295218261233\n",
      "val_loss: 0.218966278280913\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.4577261770682424\n",
      "val_loss: 0.21902458082524917\n",
      "best loss: 0.2176724811360289\n",
      "*********************************\n",
      "RC 4\n",
      "initial loss: 0.0892661557805949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f980a7c92344440ae392dffaae13204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.185035124644126\n",
      "val_loss: 0.08908345465147902\n",
      "best loss: 0.08908345465147902\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.167429111379961\n",
      "val_loss: 0.08928613652657139\n",
      "best loss: 0.08908345465147902\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.1573285795242807\n",
      "val_loss: 0.08912341809165908\n",
      "best loss: 0.08908345465147902\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.145569190067835\n",
      "val_loss: 0.08896212847942513\n",
      "best loss: 0.08896212847942513\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.1376062957652553\n",
      "val_loss: 0.08878941230293318\n",
      "best loss: 0.08878941230293318\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.131308058658219\n",
      "val_loss: 0.08862383553392451\n",
      "best loss: 0.08862383553392451\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.1239096071122874\n",
      "val_loss: 0.08874373448375368\n",
      "best loss: 0.08862383553392451\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.116888895580329\n",
      "val_loss: 0.08868378614730923\n",
      "best loss: 0.08862383553392451\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.111172965083973\n",
      "val_loss: 0.08894499555068885\n",
      "best loss: 0.08862383553392451\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.1045269699179534\n",
      "val_loss: 0.08859814398758105\n",
      "best loss: 0.08859814398758105\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.098771901657549\n",
      "val_loss: 0.0886252682215925\n",
      "best loss: 0.08859814398758105\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.0902055656032084\n",
      "val_loss: 0.08857244855764154\n",
      "best loss: 0.08857244855764154\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.08555990775325\n",
      "val_loss: 0.08875515246697833\n",
      "best loss: 0.08857244855764154\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.081335770172836\n",
      "val_loss: 0.088753728378345\n",
      "best loss: 0.08857244855764154\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.0764935598056056\n",
      "val_loss: 0.08889503670062975\n",
      "best loss: 0.08857244855764154\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.0703956007508495\n",
      "val_loss: 0.08848110217029784\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.065223197463717\n",
      "val_loss: 0.08881510055004284\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.0583607041337\n",
      "val_loss: 0.08873517389522868\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.056176979584396\n",
      "val_loss: 0.08861241633250957\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.052193931804645\n",
      "val_loss: 0.08888219165764608\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.0463602515472905\n",
      "val_loss: 0.08900351644329567\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.0409795339517136\n",
      "val_loss: 0.08893643142830777\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.0343771407470252\n",
      "val_loss: 0.08886934099401447\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.0311375351430434\n",
      "val_loss: 0.08896497807168642\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.027703217196011\n",
      "val_loss: 0.08894214131817092\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.0219068056468203\n",
      "val_loss: 0.0890177921801875\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 26\n",
      "Train_loss: 2.018191582293964\n",
      "val_loss: 0.08905204621366594\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.0033793388682515\n",
      "val_loss: 0.08908916138294222\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.001169715071688\n",
      "val_loss: 0.08895356002023827\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.0022255433648763\n",
      "val_loss: 0.08884079473471444\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 1.9987371107945515\n",
      "val_loss: 0.08886934580551056\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 1.9989947561403714\n",
      "val_loss: 0.08886649262629685\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 1.9992861752286368\n",
      "val_loss: 0.08885935072782397\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 1.9997492119127769\n",
      "val_loss: 0.08891359344843335\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 1.9977631254966008\n",
      "val_loss: 0.08886506196324809\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 1.998389804396951\n",
      "val_loss: 0.0888365133646839\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 1.9965685750763007\n",
      "val_loss: 0.08891073496957005\n",
      "best loss: 0.08848110217029784\n",
      "*********************************\n",
      "RC 5\n",
      "initial loss: 0.08452420536539972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab21c5287d741b5a2dc44509ba79011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.1470270089717354\n",
      "val_loss: 0.08312921316418558\n",
      "best loss: 0.08312921316418558\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.125877301904744\n",
      "val_loss: 0.08309485448928114\n",
      "best loss: 0.08309485448928114\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.111738151774986\n",
      "val_loss: 0.0830769847564616\n",
      "best loss: 0.0830769847564616\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.1021928376546803\n",
      "val_loss: 0.08312783973561853\n",
      "best loss: 0.0830769847564616\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.0929337679196913\n",
      "val_loss: 0.08302613583323189\n",
      "best loss: 0.08302613583323189\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.0818933560407795\n",
      "val_loss: 0.08289419880607607\n",
      "best loss: 0.08289419880607607\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.0757276995880374\n",
      "val_loss: 0.08282960146871822\n",
      "best loss: 0.08282960146871822\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.0677949164582627\n",
      "val_loss: 0.08296291631100829\n",
      "best loss: 0.08282960146871822\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.062007317889569\n",
      "val_loss: 0.0828364721351106\n",
      "best loss: 0.08282960146871822\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.0548299235767065\n",
      "val_loss: 0.08287632908680251\n",
      "best loss: 0.08282960146871822\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.049057868346099\n",
      "val_loss: 0.08281860575965505\n",
      "best loss: 0.08281860575965505\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.0422788398438434\n",
      "val_loss: 0.08274713882545466\n",
      "best loss: 0.08274713882545466\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.035586332177983\n",
      "val_loss: 0.08272789660951925\n",
      "best loss: 0.08272789660951925\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.0298183318053202\n",
      "val_loss: 0.08284334520336555\n",
      "best loss: 0.08272789660951925\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.0255895967057254\n",
      "val_loss: 0.08280074021210652\n",
      "best loss: 0.08272789660951925\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.0172318566237095\n",
      "val_loss: 0.08271965135543173\n",
      "best loss: 0.08271965135543173\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.012139050292891\n",
      "val_loss: 0.08276775253535804\n",
      "best loss: 0.08271965135543173\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.008397285499897\n",
      "val_loss: 0.08271827372863032\n",
      "best loss: 0.08271827372863032\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.0023360943444857\n",
      "val_loss: 0.08277600107806006\n",
      "best loss: 0.08271827372863032\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 1.997306839231356\n",
      "val_loss: 0.08269629001408853\n",
      "best loss: 0.08269629001408853\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 1.9925821239634058\n",
      "val_loss: 0.0828117346870289\n",
      "best loss: 0.08269629001408853\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 1.9893204446873303\n",
      "val_loss: 0.08283097324467564\n",
      "best loss: 0.08269629001408853\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 1.9817118259644086\n",
      "val_loss: 0.08295054730738131\n",
      "best loss: 0.08269629001408853\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 1.9769940617213337\n",
      "val_loss: 0.08298078098899225\n",
      "best loss: 0.08269629001408853\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 1.9712090274387424\n",
      "val_loss: 0.0825602215019101\n",
      "best loss: 0.0825602215019101\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 1.9664727586165012\n",
      "val_loss: 0.08288319980228086\n",
      "best loss: 0.0825602215019101\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 1.960148059252866\n",
      "val_loss: 0.08281585904366133\n",
      "best loss: 0.0825602215019101\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 1.9577223067538023\n",
      "val_loss: 0.08296016452852654\n",
      "best loss: 0.0825602215019101\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 1.9530842172143028\n",
      "val_loss: 0.08268666762595284\n",
      "best loss: 0.0825602215019101\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 1.9479924711066463\n",
      "val_loss: 0.08280486054354355\n",
      "best loss: 0.0825602215019101\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 1.9417168262172038\n",
      "val_loss: 0.082870834309539\n",
      "best loss: 0.0825602215019101\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 1.939315233480159\n",
      "val_loss: 0.08272789574388739\n",
      "best loss: 0.0825602215019101\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 1.9330935998814194\n",
      "val_loss: 0.08268941261534384\n",
      "best loss: 0.0825602215019101\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 1.9292190989838227\n",
      "val_loss: 0.08289419396535438\n",
      "best loss: 0.0825602215019101\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 1.924361476986075\n",
      "val_loss: 0.08252448636486726\n",
      "best loss: 0.08252448636486726\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 1.924895220889834\n",
      "val_loss: 0.08275263392170416\n",
      "best loss: 0.08252448636486726\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 1.9206361770665377\n",
      "val_loss: 0.0826852862657044\n",
      "best loss: 0.08252448636486726\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 1.9110360587329245\n",
      "val_loss: 0.08301651790842396\n",
      "best loss: 0.08252448636486726\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 1.9083606577240892\n",
      "val_loss: 0.08288182421305709\n",
      "best loss: 0.08252448636486726\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 1.9032714646190094\n",
      "val_loss: 0.08272927075238187\n",
      "best loss: 0.08252448636486726\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 1.8996548482759776\n",
      "val_loss: 0.0826729235809132\n",
      "best loss: 0.08252448636486726\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 1.894667591237475\n",
      "val_loss: 0.0826550572664874\n",
      "best loss: 0.08252448636486726\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 1.8901393844652858\n",
      "val_loss: 0.08281173231502575\n",
      "best loss: 0.08252448636486726\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 1.888333026410583\n",
      "val_loss: 0.08258221251074391\n",
      "best loss: 0.08252448636486726\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 1.881911408525885\n",
      "val_loss: 0.08269491449885785\n",
      "best loss: 0.08252448636486726\n",
      "*********************************\n",
      "epoch 45\n",
      "Train_loss: 1.8797725795321212\n",
      "val_loss: 0.08248051121442913\n",
      "best loss: 0.08248051121442913\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 1.8732348441858775\n",
      "val_loss: 0.08243240484566401\n",
      "best loss: 0.08243240484566401\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 1.8710384481178288\n",
      "val_loss: 0.08263855985699942\n",
      "best loss: 0.08243240484566401\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 1.866062569081194\n",
      "val_loss: 0.0825877123862484\n",
      "best loss: 0.08243240484566401\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 1.8618870652171375\n",
      "val_loss: 0.08264543433505593\n",
      "best loss: 0.08243240484566401\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 1.8609594153674993\n",
      "val_loss: 0.08238842612360235\n",
      "best loss: 0.08238842612360235\n",
      "*********************************\n",
      "epoch 51\n",
      "Train_loss: 1.852160512336383\n",
      "val_loss: 0.08236231373402782\n",
      "best loss: 0.08236231373402782\n",
      "*********************************\n",
      "epoch 52\n",
      "Train_loss: 1.8500103420906204\n",
      "val_loss: 0.08235269490484362\n",
      "best loss: 0.08235269490484362\n",
      "*********************************\n",
      "epoch 53\n",
      "Train_loss: 1.845454116761921\n",
      "val_loss: 0.08268391440031438\n",
      "best loss: 0.08235269490484362\n",
      "*********************************\n",
      "epoch 54\n",
      "Train_loss: 1.8436921438681686\n",
      "val_loss: 0.08233207610208852\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 55\n",
      "Train_loss: 1.8390854008371909\n",
      "val_loss: 0.08244065096829649\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 56\n",
      "Train_loss: 1.83643708393556\n",
      "val_loss: 0.08266605319316019\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 57\n",
      "Train_loss: 1.8344690821640721\n",
      "val_loss: 0.08241041739680127\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 58\n",
      "Train_loss: 1.826720344558516\n",
      "val_loss: 0.0827979843945248\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 59\n",
      "Train_loss: 1.8250944576267591\n",
      "val_loss: 0.08259183338012757\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 60\n",
      "Train_loss: 1.818633971091588\n",
      "val_loss: 0.08267567197180187\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 61\n",
      "Train_loss: 1.817171523830042\n",
      "val_loss: 0.08275400872831983\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62\n",
      "Train_loss: 1.8126267981043735\n",
      "val_loss: 0.08257534423543558\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 63\n",
      "Train_loss: 1.8105688272188811\n",
      "val_loss: 0.0827814991652038\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 64\n",
      "Train_loss: 1.807666114535395\n",
      "val_loss: 0.08242003409693605\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 65\n",
      "Train_loss: 1.80208579242905\n",
      "val_loss: 0.08242415916480528\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 66\n",
      "Train_loss: 1.7865756057635127\n",
      "val_loss: 0.08241591269085123\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 67\n",
      "Train_loss: 1.7864258899640175\n",
      "val_loss: 0.08243515509453683\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 68\n",
      "Train_loss: 1.784800476349009\n",
      "val_loss: 0.08245439684160652\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 69\n",
      "Train_loss: 1.7843347809176964\n",
      "val_loss: 0.08240492058603846\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 70\n",
      "Train_loss: 1.7845468027510127\n",
      "val_loss: 0.08240904230746789\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 71\n",
      "Train_loss: 1.7842748250847542\n",
      "val_loss: 0.08245989478018145\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 72\n",
      "Train_loss: 1.7833422911877508\n",
      "val_loss: 0.08242416307362176\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 73\n",
      "Train_loss: 1.7837161285100316\n",
      "val_loss: 0.08246264340892588\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 74\n",
      "Train_loss: 1.782762430196274\n",
      "val_loss: 0.0824406546886345\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "epoch 75\n",
      "Train_loss: 1.7826924550569436\n",
      "val_loss: 0.08242278502820585\n",
      "best loss: 0.08233207610208852\n",
      "*********************************\n",
      "RC 6\n",
      "initial loss: 0.12296068397345399\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c25194ae654aa983863c8859ea43c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.4318164737893664\n",
      "val_loss: 0.12251694002903722\n",
      "best loss: 0.12251694002903722\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.331686995682461\n",
      "val_loss: 0.12112858479973738\n",
      "best loss: 0.12112858479973738\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.3086435905318887\n",
      "val_loss: 0.12105631159535397\n",
      "best loss: 0.12105631159535397\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.2917549330087854\n",
      "val_loss: 0.12088822337718125\n",
      "best loss: 0.12088822337718125\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.2784845695466296\n",
      "val_loss: 0.12085040591672125\n",
      "best loss: 0.12085040591672125\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.26645043917614\n",
      "val_loss: 0.12073022656597662\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.2563465878161257\n",
      "val_loss: 0.12090251182787534\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.2462978626492163\n",
      "val_loss: 0.12081006582800903\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.237686718847946\n",
      "val_loss: 0.12108488208797098\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.22891749811517\n",
      "val_loss: 0.1211504325387686\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.221189059356989\n",
      "val_loss: 0.12106303180146324\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.214364446423272\n",
      "val_loss: 0.12112018047775708\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.206296892088854\n",
      "val_loss: 0.12087982124471969\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.1983623372925085\n",
      "val_loss: 0.1211958156952681\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.1921679847167224\n",
      "val_loss: 0.1209411683279004\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.185899782025355\n",
      "val_loss: 0.12095713534785689\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 16\n",
      "Train_loss: 2.1786783893922212\n",
      "val_loss: 0.12110252824694749\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.1669177924697136\n",
      "val_loss: 0.12089998366334617\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.165140382808179\n",
      "val_loss: 0.12088906329556426\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.1641807796120145\n",
      "val_loss: 0.12091764015571471\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.162920702421487\n",
      "val_loss: 0.12092352214736983\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.162254059621415\n",
      "val_loss: 0.1208512488550779\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.1621310745919518\n",
      "val_loss: 0.120936971352043\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.1610164288970197\n",
      "val_loss: 0.1209512565584943\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.1602764723690275\n",
      "val_loss: 0.12085880924944131\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.159160487535466\n",
      "val_loss: 0.12083191757502723\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.1582551467622872\n",
      "val_loss: 0.12097310845229388\n",
      "best loss: 0.12073022656597662\n",
      "*********************************\n",
      "RC 7\n",
      "initial loss: 0.1246880560066647\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c28c77aa8794d91b154ebfe7e268df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.269825620407983\n",
      "val_loss: 0.12462696991967075\n",
      "best loss: 0.12462696991967075\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.2561330905220434\n",
      "val_loss: 0.12490757388477267\n",
      "best loss: 0.12462696991967075\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.24236353426147\n",
      "val_loss: 0.12493621366512585\n",
      "best loss: 0.12462696991967075\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.2360933684641475\n",
      "val_loss: 0.12496102476954936\n",
      "best loss: 0.12462696991967075\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.227587678778853\n",
      "val_loss: 0.12487130969562119\n",
      "best loss: 0.12462696991967075\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.217251336289735\n",
      "val_loss: 0.12461742444049914\n",
      "best loss: 0.12461742444049914\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.214320889581212\n",
      "val_loss: 0.12512900181204292\n",
      "best loss: 0.12461742444049914\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.2035326292472375\n",
      "val_loss: 0.12497820378963415\n",
      "best loss: 0.12461742444049914\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.1993161913542276\n",
      "val_loss: 0.12477204513512095\n",
      "best loss: 0.12461742444049914\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.1892259758442547\n",
      "val_loss: 0.12474149997190356\n",
      "best loss: 0.12461742444049914\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.1861392635515675\n",
      "val_loss: 0.12480830914118912\n",
      "best loss: 0.12461742444049914\n",
      "*********************************\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 11\n",
      "Train_loss: 2.181428724975737\n",
      "val_loss: 0.12477968011379449\n",
      "best loss: 0.12461742444049914\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.1772420413976525\n",
      "val_loss: 0.12482931148125795\n",
      "best loss: 0.12461742444049914\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.1726697699657795\n",
      "val_loss: 0.12472623190891248\n",
      "best loss: 0.12461742444049914\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.1765115340748813\n",
      "val_loss: 0.12478540946461608\n",
      "best loss: 0.12461742444049914\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.1700545001745226\n",
      "val_loss: 0.12482930969574044\n",
      "best loss: 0.12461742444049914\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.1728905552548685\n",
      "val_loss: 0.1246307901954142\n",
      "best loss: 0.12461742444049914\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.17522943892211\n",
      "val_loss: 0.12472623283019582\n",
      "best loss: 0.12461742444049914\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.1702254612017833\n",
      "val_loss: 0.12462696891847812\n",
      "best loss: 0.12461742444049914\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.1688331301763815\n",
      "val_loss: 0.12458306668152937\n",
      "best loss: 0.12458306668152937\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.168456771943486\n",
      "val_loss: 0.1246708773685261\n",
      "best loss: 0.12458306668152937\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.1648242997547555\n",
      "val_loss: 0.12465751657607926\n",
      "best loss: 0.12458306668152937\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.165437373276081\n",
      "val_loss: 0.12462315358557959\n",
      "best loss: 0.12458306668152937\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.1683643446583023\n",
      "val_loss: 0.12463269785316448\n",
      "best loss: 0.12458306668152937\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.1653202216457914\n",
      "val_loss: 0.12464797340537584\n",
      "best loss: 0.12458306668152937\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.1660312686732097\n",
      "val_loss: 0.12462697203008528\n",
      "best loss: 0.12458306668152937\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.1632986441086555\n",
      "val_loss: 0.12465178667863765\n",
      "best loss: 0.12458306668152937\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.1657838350967387\n",
      "val_loss: 0.12462696820657736\n",
      "best loss: 0.12458306668152937\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.162883970773361\n",
      "val_loss: 0.12458306392455762\n",
      "best loss: 0.12458306392455762\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.1616126196361294\n",
      "val_loss: 0.12450861974079107\n",
      "best loss: 0.12450861974079107\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.162827381499649\n",
      "val_loss: 0.12455252498576835\n",
      "best loss: 0.12450861974079107\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.158304225761956\n",
      "val_loss: 0.12465178525463383\n",
      "best loss: 0.12450861974079107\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.1583056806847414\n",
      "val_loss: 0.12474150496754931\n",
      "best loss: 0.12450861974079107\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.1591907086324804\n",
      "val_loss: 0.12453152674494508\n",
      "best loss: 0.12450861974079107\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.159003122343362\n",
      "val_loss: 0.12453534490804868\n",
      "best loss: 0.12450861974079107\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.1581102737764404\n",
      "val_loss: 0.1245162620682873\n",
      "best loss: 0.12450861974079107\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.157988612062916\n",
      "val_loss: 0.12440744795384844\n",
      "best loss: 0.12440744795384844\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.155481645130445\n",
      "val_loss: 0.12449907233125371\n",
      "best loss: 0.12440744795384844\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.1549291790708938\n",
      "val_loss: 0.12457352648547465\n",
      "best loss: 0.12440744795384844\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.1561239117600843\n",
      "val_loss: 0.12447044023473534\n",
      "best loss: 0.12440744795384844\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.153304970528271\n",
      "val_loss: 0.12439981127017359\n",
      "best loss: 0.12439981127017359\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.1539025552618076\n",
      "val_loss: 0.12446471796023564\n",
      "best loss: 0.12439981127017359\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.1477454264511056\n",
      "val_loss: 0.12443990180331951\n",
      "best loss: 0.12439981127017359\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.150520103916382\n",
      "val_loss: 0.12441699498305803\n",
      "best loss: 0.12439981127017359\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 2.1527453398605108\n",
      "val_loss: 0.12440553652741408\n",
      "best loss: 0.12439981127017359\n",
      "*********************************\n",
      "epoch 45\n",
      "Train_loss: 2.150711843111869\n",
      "val_loss: 0.12454488542980963\n",
      "best loss: 0.12439981127017359\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 2.1478580880537397\n",
      "val_loss: 0.12437690700276112\n",
      "best loss: 0.12437690700276112\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 2.1470104793499902\n",
      "val_loss: 0.12441318259709282\n",
      "best loss: 0.12437690700276112\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 2.1477407624061624\n",
      "val_loss: 0.12437309194458872\n",
      "best loss: 0.12437309194458872\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 2.1460428217748335\n",
      "val_loss: 0.1243730914598731\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 2.145797023556354\n",
      "val_loss: 0.12447998584054801\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 51\n",
      "Train_loss: 2.1460210534049686\n",
      "val_loss: 0.12437881789127445\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 52\n",
      "Train_loss: 2.143503996647796\n",
      "val_loss: 0.12447044126809399\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 53\n",
      "Train_loss: 2.143170470090903\n",
      "val_loss: 0.12444180496167087\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 54\n",
      "Train_loss: 2.1430249734428672\n",
      "val_loss: 0.12447808609179467\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 55\n",
      "Train_loss: 2.143323088283502\n",
      "val_loss: 0.12442653667392226\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 56\n",
      "Train_loss: 2.140582760892359\n",
      "val_loss: 0.12438645012329363\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch 57\n",
      "Train_loss: 2.1396008647457534\n",
      "val_loss: 0.12449716713875568\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 58\n",
      "Train_loss: 2.1386927223295196\n",
      "val_loss: 0.12448571752512555\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 59\n",
      "Train_loss: 2.1385019832314853\n",
      "val_loss: 0.1244379955740237\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 60\n",
      "Train_loss: 2.1380455959042086\n",
      "val_loss: 0.12446853062517531\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61\n",
      "Train_loss: 2.137833622458648\n",
      "val_loss: 0.12446089736708034\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 62\n",
      "Train_loss: 2.1352061545803367\n",
      "val_loss: 0.12442463025466487\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 63\n",
      "Train_loss: 2.139108243850689\n",
      "val_loss: 0.12446280460161481\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 64\n",
      "Train_loss: 2.136852962948374\n",
      "val_loss: 0.12446090496432989\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 65\n",
      "Train_loss: 2.1363663434074325\n",
      "val_loss: 0.12447235351809982\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 66\n",
      "Train_loss: 2.1378215043948443\n",
      "val_loss: 0.124416997663155\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 67\n",
      "Train_loss: 2.139220036145196\n",
      "val_loss: 0.12444372145981653\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 68\n",
      "Train_loss: 2.134768168395981\n",
      "val_loss: 0.12445135271916767\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 69\n",
      "Train_loss: 2.135537127304377\n",
      "val_loss: 0.12446471522147107\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "epoch 70\n",
      "Train_loss: 2.1366378329589484\n",
      "val_loss: 0.12442462989982714\n",
      "best loss: 0.1243730914598731\n",
      "*********************************\n",
      "RC 8\n",
      "initial loss: 0.13578471610528128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad13dc2a973d42478df03aba400297bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.236037725001917\n",
      "val_loss: 0.13479460957817962\n",
      "best loss: 0.13479460957817962\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.21579903479023\n",
      "val_loss: 0.1340819631219364\n",
      "best loss: 0.1340819631219364\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.2037986380281307\n",
      "val_loss: 0.13408899362507906\n",
      "best loss: 0.1340819631219364\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.1932824489633242\n",
      "val_loss: 0.1340143486286635\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.1809204175573824\n",
      "val_loss: 0.13423546771011022\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.1716083070595253\n",
      "val_loss: 0.1340594183597172\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.1676516214583668\n",
      "val_loss: 0.1344270166424614\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.1593049128844215\n",
      "val_loss: 0.1342312416891807\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.151195128426798\n",
      "val_loss: 0.13505234727469553\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.1459538236986893\n",
      "val_loss: 0.13476080596712678\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.1387316269994177\n",
      "val_loss: 0.13453546044218878\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.133959571656834\n",
      "val_loss: 0.13484671787075297\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.125876788975148\n",
      "val_loss: 0.13437208322513652\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.1207657249096297\n",
      "val_loss: 0.13462137791942122\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 14\n",
      "Train_loss: 2.116749859113564\n",
      "val_loss: 0.13435236801777606\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.1067040084594053\n",
      "val_loss: 0.1344354612091115\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.1047038629714296\n",
      "val_loss: 0.13442138130755316\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.1035979810295764\n",
      "val_loss: 0.1344805355544622\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.1045466261960546\n",
      "val_loss: 0.1344340567151133\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.102194357658523\n",
      "val_loss: 0.13453263998681206\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.1002768286619418\n",
      "val_loss: 0.134350959942675\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.101589559590877\n",
      "val_loss: 0.13441574537141607\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.1003590632174993\n",
      "val_loss: 0.13445940637703255\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.099463707052018\n",
      "val_loss: 0.13451996626084178\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.099120071398901\n",
      "val_loss: 0.13445658838179825\n",
      "best loss: 0.1340143486286635\n",
      "*********************************\n",
      "fold 3, score: 0.13684298367839648\n",
      "fold: 4\n",
      "RC 0\n",
      "initial loss: 0.1315476182561725\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb3a4b5a863460980d63a7447b929bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.4978064472892005\n",
      "val_loss: 0.13064049165187247\n",
      "best loss: 0.13064049165187247\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.4781394663299596\n",
      "val_loss: 0.13038008273006027\n",
      "best loss: 0.13038008273006027\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.4609909898145164\n",
      "val_loss: 0.13039309708496047\n",
      "best loss: 0.13038008273006027\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.447859313563218\n",
      "val_loss: 0.1303337907602485\n",
      "best loss: 0.1303337907602485\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.4348583446401872\n",
      "val_loss: 0.13042348294391032\n",
      "best loss: 0.1303337907602485\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.426320654390379\n",
      "val_loss: 0.1302874913142507\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.4174471152398604\n",
      "val_loss: 0.1303106392818178\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.4093992521971135\n",
      "val_loss: 0.13045387795827493\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.4016624417409598\n",
      "val_loss: 0.1304307239171499\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.3949071187945536\n",
      "val_loss: 0.1305175246956604\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.3879723613420296\n",
      "val_loss: 0.13032655104520383\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.382889691985841\n",
      "val_loss: 0.13088644702199326\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.375911656324938\n",
      "val_loss: 0.13054067291713572\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.3727519190232087\n",
      "val_loss: 0.13049871264401564\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.3636767242887324\n",
      "val_loss: 0.13077215624411737\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.3558147650082195\n",
      "val_loss: 0.13066364868592512\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 16\n",
      "Train_loss: 2.352659622468432\n",
      "val_loss: 0.1306245875787159\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.342205093852278\n",
      "val_loss: 0.13057105373103992\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.341166476371663\n",
      "val_loss: 0.13053922311262392\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.3401801079758084\n",
      "val_loss: 0.1304582093544472\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.3396307150497466\n",
      "val_loss: 0.13048569335906443\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.3392244973924\n",
      "val_loss: 0.13041770532952632\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.338179719397202\n",
      "val_loss: 0.1305001617603994\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.3358668837890644\n",
      "val_loss: 0.13048135634747296\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.3365518260831357\n",
      "val_loss: 0.13046254977724026\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.3366264160106947\n",
      "val_loss: 0.13052620881752094\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.335372123283388\n",
      "val_loss: 0.13043216748680464\n",
      "best loss: 0.1302874913142507\n",
      "*********************************\n",
      "RC 1\n",
      "initial loss: 0.13379799314787036\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936302fdd1d142128ad5bd3ca973b956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.3963221268042214\n",
      "val_loss: 0.13347055134772806\n",
      "best loss: 0.13347055134772806\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.3775544412101057\n",
      "val_loss: 0.1331203862323844\n",
      "best loss: 0.1331203862323844\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.3632744315488954\n",
      "val_loss: 0.1327588738340478\n",
      "best loss: 0.1327588738340478\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.351234905430586\n",
      "val_loss: 0.13269641403603996\n",
      "best loss: 0.13269641403603996\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.3373736125215396\n",
      "val_loss: 0.13257907132845273\n",
      "best loss: 0.13257907132845273\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.3306701668342575\n",
      "val_loss: 0.13289705062525226\n",
      "best loss: 0.13257907132845273\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.3210298509613887\n",
      "val_loss: 0.13274184211972642\n",
      "best loss: 0.13257907132845273\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.313692154320792\n",
      "val_loss: 0.1327645590288286\n",
      "best loss: 0.13257907132845273\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.304280746409266\n",
      "val_loss: 0.1324636073863728\n",
      "best loss: 0.1324636073863728\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.30202417356893\n",
      "val_loss: 0.13270020451305134\n",
      "best loss: 0.1324636073863728\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.2918880725469934\n",
      "val_loss: 0.13284215920576709\n",
      "best loss: 0.1324636073863728\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.28679330886319\n",
      "val_loss: 0.1326945301975665\n",
      "best loss: 0.1324636073863728\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.278800267099703\n",
      "val_loss: 0.13238032430661525\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.273952286122403\n",
      "val_loss: 0.13267180935004524\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.2662502282222867\n",
      "val_loss: 0.13282890122907276\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.263400374660574\n",
      "val_loss: 0.13262827640296382\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.2559405380789794\n",
      "val_loss: 0.13281376755632665\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.250253287710315\n",
      "val_loss: 0.13240115179036163\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.247149971719283\n",
      "val_loss: 0.1327607626500058\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.2426081101148774\n",
      "val_loss: 0.13278537496169773\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.2346423680389513\n",
      "val_loss: 0.13250902984947752\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.229215630595828\n",
      "val_loss: 0.13250903146424137\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.22848902578409\n",
      "val_loss: 0.13287243434986667\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 23\n",
      "Train_loss: 2.2211746169650484\n",
      "val_loss: 0.13259420944992342\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.210809548483573\n",
      "val_loss: 0.13254121704006946\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.2076484083629935\n",
      "val_loss: 0.13272669920170502\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.2087136609666986\n",
      "val_loss: 0.13268127029639462\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.2081091755614914\n",
      "val_loss: 0.13244089510933607\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.205685551717401\n",
      "val_loss: 0.13260746441653745\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.2055321844189795\n",
      "val_loss: 0.13248821907903852\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.2049996670527507\n",
      "val_loss: 0.1325336362212456\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.2075572158152648\n",
      "val_loss: 0.13254688555163166\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.2053610553746563\n",
      "val_loss: 0.13255445825651793\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.2045635917922324\n",
      "val_loss: 0.13249200155805432\n",
      "best loss: 0.13238032430661525\n",
      "*********************************\n",
      "RC 2\n",
      "initial loss: 0.22407726551166926\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adbc66103f943edb418ec417cfb338e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.7721939184820052\n",
      "val_loss: 0.22265050474726047\n",
      "best loss: 0.22265050474726047\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.747597185467589\n",
      "val_loss: 0.22036051353516095\n",
      "best loss: 0.22036051353516095\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.730431325635751\n",
      "val_loss: 0.21926363613661157\n",
      "best loss: 0.21926363613661157\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.713031035710421\n",
      "val_loss: 0.21876879587040562\n",
      "best loss: 0.21876879587040562\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.7024341242140175\n",
      "val_loss: 0.21925538088602656\n",
      "best loss: 0.21876879587040562\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.690410907067338\n",
      "val_loss: 0.2188622694969042\n",
      "best loss: 0.21876879587040562\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.678760326693035\n",
      "val_loss: 0.21899010368058322\n",
      "best loss: 0.21876879587040562\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.672421631490196\n",
      "val_loss: 0.21863684135541644\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.6633201348419115\n",
      "val_loss: 0.2193832164116433\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.656791804198195\n",
      "val_loss: 0.21865607890485203\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.6481472839222504\n",
      "val_loss: 0.21904782851762375\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.642422842809162\n",
      "val_loss: 0.2189241217155267\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.635434327372991\n",
      "val_loss: 0.21938183765305\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.629386703954791\n",
      "val_loss: 0.2193804687168817\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.6229579734176705\n",
      "val_loss: 0.21960177589920957\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.6163530449639576\n",
      "val_loss: 0.2192732542161788\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.6084215078932553\n",
      "val_loss: 0.21942308787483\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.6029665251769116\n",
      "val_loss: 0.21973785937516507\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 18\n",
      "Train_loss: 2.5972336385683317\n",
      "val_loss: 0.22040587493184213\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.588793645138229\n",
      "val_loss: 0.21957702487526504\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.5869204427758428\n",
      "val_loss: 0.22015983542325523\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.58417155245878\n",
      "val_loss: 0.22001688560607943\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.584516323095689\n",
      "val_loss: 0.22012135183311704\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.5841395464577768\n",
      "val_loss: 0.22006086698409769\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.582414013503428\n",
      "val_loss: 0.22009522566705195\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.5841060610529882\n",
      "val_loss: 0.22006636427843831\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.5826864888856926\n",
      "val_loss: 0.22019419755603256\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.582245438711401\n",
      "val_loss: 0.2200155053132603\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.581623520852738\n",
      "val_loss: 0.21999625519546762\n",
      "best loss: 0.21863684135541644\n",
      "*********************************\n",
      "RC 3\n",
      "initial loss: 0.21425210929454797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545ed6705a9041b1bcc5125e79f9295b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.7628561764026283\n",
      "val_loss: 0.2130864027238\n",
      "best loss: 0.2130864027238\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.735164800115989\n",
      "val_loss: 0.2126570868119649\n",
      "best loss: 0.2126570868119649\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.7140488386071473\n",
      "val_loss: 0.21262652117900127\n",
      "best loss: 0.21262652117900127\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.6974812231294414\n",
      "val_loss: 0.212488959372066\n",
      "best loss: 0.212488959372066\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.6835089627764748\n",
      "val_loss: 0.21252509015626936\n",
      "best loss: 0.212488959372066\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.671735154303827\n",
      "val_loss: 0.21267098793587846\n",
      "best loss: 0.212488959372066\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.659986943344705\n",
      "val_loss: 0.21253204332656989\n",
      "best loss: 0.212488959372066\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.649609797994462\n",
      "val_loss: 0.2122930550542155\n",
      "best loss: 0.2122930550542155\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.639453294769255\n",
      "val_loss: 0.2122041416011777\n",
      "best loss: 0.2122041416011777\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.633455791344335\n",
      "val_loss: 0.21214023006140484\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.6252122730042258\n",
      "val_loss: 0.2126334579105813\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.6176342689026293\n",
      "val_loss: 0.21253898750122088\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.6098070084070466\n",
      "val_loss: 0.21300998164698334\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.6028726599506453\n",
      "val_loss: 0.2136018665513657\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.5974988443539986\n",
      "val_loss: 0.21304611877785215\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.5897862869116097\n",
      "val_loss: 0.21287244950425221\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.58278834212143\n",
      "val_loss: 0.2125292558614467\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.5755763048707667\n",
      "val_loss: 0.2130308238171257\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.570601075796861\n",
      "val_loss: 0.2130224933264795\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.56449112430223\n",
      "val_loss: 0.2130683509440014\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 20\n",
      "Train_loss: 2.5583557206829064\n",
      "val_loss: 0.2124889677828481\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.5477677212535195\n",
      "val_loss: 0.21247646197617465\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.546099770108228\n",
      "val_loss: 0.2125445434082572\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.5456649853171505\n",
      "val_loss: 0.21276267752451572\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.5444188229784155\n",
      "val_loss: 0.2126584743424582\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.5445384788041547\n",
      "val_loss: 0.21276406841902737\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.5428097143767343\n",
      "val_loss: 0.21282659067694418\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.543899214424566\n",
      "val_loss: 0.21276823945044435\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.5420769009658386\n",
      "val_loss: 0.21287105410278648\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.54135148027877\n",
      "val_loss: 0.21286688111651053\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.5397814371985734\n",
      "val_loss: 0.212901616693615\n",
      "best loss: 0.21214023006140484\n",
      "*********************************\n",
      "RC 4\n",
      "initial loss: 0.08584226999513642\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ae6e755dbd40fa816911ac014fc3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.191663262517894\n",
      "val_loss: 0.08532822652853037\n",
      "best loss: 0.08532822652853037\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.175351456765594\n",
      "val_loss: 0.08536116190245886\n",
      "best loss: 0.08532822652853037\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.162767233075256\n",
      "val_loss: 0.08530245704313923\n",
      "best loss: 0.08530245704313923\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.1489383428574316\n",
      "val_loss: 0.08533395054792672\n",
      "best loss: 0.08530245704313923\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.14089159709297\n",
      "val_loss: 0.08521081223692994\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.134786294027696\n",
      "val_loss: 0.08538407031543056\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.1261470880240503\n",
      "val_loss: 0.08538120871720024\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.1188825453475815\n",
      "val_loss: 0.08533681987519735\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.1097500628019663\n",
      "val_loss: 0.08547427595848998\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.106845372931125\n",
      "val_loss: 0.08545709826995158\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.1012398932474547\n",
      "val_loss: 0.08555875651915014\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.096236590020024\n",
      "val_loss: 0.08557594130514883\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.087797899290615\n",
      "val_loss: 0.08549432326899589\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.0844040454449657\n",
      "val_loss: 0.08554587110845473\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.0797570956081715\n",
      "val_loss: 0.08527381622010449\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 15\n",
      "Train_loss: 2.074673104993029\n",
      "val_loss: 0.085618898971471\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.0632271848536163\n",
      "val_loss: 0.08553012322894404\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.062129091860267\n",
      "val_loss: 0.08552296156631749\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.0620754524279565\n",
      "val_loss: 0.08549146032778546\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.0612422218210256\n",
      "val_loss: 0.08551436925640081\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.0615838487746143\n",
      "val_loss: 0.08549432608546043\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.0591207989237272\n",
      "val_loss: 0.08549575521981134\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.060267632887193\n",
      "val_loss: 0.08547570953241453\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.059433406042739\n",
      "val_loss: 0.08551437023973542\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.0578004795018883\n",
      "val_loss: 0.08548286968195014\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.057216539160648\n",
      "val_loss: 0.08546998394802902\n",
      "best loss: 0.08521081223692994\n",
      "*********************************\n",
      "RC 5\n",
      "initial loss: 0.091913775240914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca48d7680cb4c81b02b032cd9a8151a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.1510847184341046\n",
      "val_loss: 0.09130401241826007\n",
      "best loss: 0.09130401241826007\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.1282990297050666\n",
      "val_loss: 0.09127372957215377\n",
      "best loss: 0.09127372957215377\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.11439966821368\n",
      "val_loss: 0.0912957502025573\n",
      "best loss: 0.09127372957215377\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.101455495106125\n",
      "val_loss: 0.09131502097281999\n",
      "best loss: 0.09127372957215377\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.0930662407854204\n",
      "val_loss: 0.09129988018651249\n",
      "best loss: 0.09127372957215377\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.081983921072521\n",
      "val_loss: 0.09122968038565028\n",
      "best loss: 0.09122968038565028\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.0767931262218897\n",
      "val_loss: 0.09158480305591168\n",
      "best loss: 0.09122968038565028\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.0668839503373326\n",
      "val_loss: 0.0915228642896\n",
      "best loss: 0.09122968038565028\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.059895879803101\n",
      "val_loss: 0.0912902435898139\n",
      "best loss: 0.09122968038565028\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.054027869081376\n",
      "val_loss: 0.09121178421898911\n",
      "best loss: 0.09121178421898911\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.045882813015915\n",
      "val_loss: 0.09127097570233875\n",
      "best loss: 0.09121178421898911\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.040613526558001\n",
      "val_loss: 0.09114709029376244\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.03586549266712\n",
      "val_loss: 0.09182155212685575\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.030498901729823\n",
      "val_loss: 0.09140862278432398\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.0267869021493863\n",
      "val_loss: 0.09153938125219056\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.0189752847311464\n",
      "val_loss: 0.09149946201550745\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.0121468819357404\n",
      "val_loss: 0.09134805247486659\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.009571349639562\n",
      "val_loss: 0.0915765456882284\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.004543970466981\n",
      "val_loss: 0.09167152352211701\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 1.9985916433010067\n",
      "val_loss: 0.09166739069111372\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 1.9944001406915546\n",
      "val_loss: 0.09147606244200418\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 1.9873612680523254\n",
      "val_loss: 0.09154901808841638\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 22\n",
      "Train_loss: 1.9846749278863747\n",
      "val_loss: 0.0916233431155111\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 1.9746958560094425\n",
      "val_loss: 0.09167427625570937\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 1.9714998229851426\n",
      "val_loss: 0.09155727060312041\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 1.9729580139978555\n",
      "val_loss: 0.09165224935223061\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 1.9710364664886784\n",
      "val_loss: 0.09163986108551642\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 1.9699370293823184\n",
      "val_loss: 0.09162609980859654\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 1.9695992700463762\n",
      "val_loss: 0.09158618065272835\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 1.968885470900251\n",
      "val_loss: 0.09167564903018058\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 1.9691415143790485\n",
      "val_loss: 0.09169079280080482\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 1.9674066577483476\n",
      "val_loss: 0.09165913749167105\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 1.9662082886728736\n",
      "val_loss: 0.09172933203650058\n",
      "best loss: 0.09114709029376244\n",
      "*********************************\n",
      "RC 6\n",
      "initial loss: 0.13220103249243992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc46df066194cb88d50bad907dc33b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.3483353422756776\n",
      "val_loss: 0.13085893455654227\n",
      "best loss: 0.13085893455654227\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.3166884273043427\n",
      "val_loss: 0.13040904677736467\n",
      "best loss: 0.13040904677736467\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.2957744383353713\n",
      "val_loss: 0.13034513318293908\n",
      "best loss: 0.13034513318293908\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.279309517393562\n",
      "val_loss: 0.13034933725641232\n",
      "best loss: 0.13034513318293908\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.2665682704403247\n",
      "val_loss: 0.13053266057510549\n",
      "best loss: 0.13034513318293908\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.2556201491102277\n",
      "val_loss: 0.13060329469732126\n",
      "best loss: 0.13034513318293908\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.2459974832695813\n",
      "val_loss: 0.13047127432621955\n",
      "best loss: 0.13034513318293908\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.2378153072970663\n",
      "val_loss: 0.13040231797223098\n",
      "best loss: 0.13034513318293908\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.2287141917811453\n",
      "val_loss: 0.13049229454047823\n",
      "best loss: 0.13034513318293908\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.220807527257101\n",
      "val_loss: 0.13016854503011607\n",
      "best loss: 0.13016854503011607\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.2132137270380583\n",
      "val_loss: 0.13071429282196906\n",
      "best loss: 0.13016854503011607\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.206385310251077\n",
      "val_loss: 0.13023076703733316\n",
      "best loss: 0.13016854503011607\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.1994093177155785\n",
      "val_loss: 0.12985992412827468\n",
      "best loss: 0.12985992412827468\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.192610597421377\n",
      "val_loss: 0.13032747546832005\n",
      "best loss: 0.12985992412827468\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.1869291115441913\n",
      "val_loss: 0.1302963610548602\n",
      "best loss: 0.12985992412827468\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.1799464823114643\n",
      "val_loss: 0.12997176704967892\n",
      "best loss: 0.12985992412827468\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.175213340127174\n",
      "val_loss: 0.13053349565256256\n",
      "best loss: 0.12985992412827468\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.169244720545195\n",
      "val_loss: 0.13018619377689256\n",
      "best loss: 0.12985992412827468\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.1622136557153993\n",
      "val_loss: 0.1304872525845962\n",
      "best loss: 0.12985992412827468\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.1558545894362577\n",
      "val_loss: 0.13030981368111147\n",
      "best loss: 0.12985992412827468\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.1507603613638118\n",
      "val_loss: 0.13002054077772282\n",
      "best loss: 0.12985992412827468\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.145937519948294\n",
      "val_loss: 0.13004660957435474\n",
      "best loss: 0.12985992412827468\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.143195996000341\n",
      "val_loss: 0.13029131245626716\n",
      "best loss: 0.12985992412827468\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.1333236521839467\n",
      "val_loss: 0.12976910429693092\n",
      "best loss: 0.12976910429693092\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.1292273954020637\n",
      "val_loss: 0.1300701523102849\n",
      "best loss: 0.12976910429693092\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.1228767333364744\n",
      "val_loss: 0.12999699603259024\n",
      "best loss: 0.12976910429693092\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.1190998837055806\n",
      "val_loss: 0.1303821304230497\n",
      "best loss: 0.12976910429693092\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.1139241899494245\n",
      "val_loss: 0.13022741030266516\n",
      "best loss: 0.12976910429693092\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.109794598665345\n",
      "val_loss: 0.12981451943902442\n",
      "best loss: 0.12976910429693092\n",
      "*********************************\n",
      "epoch 29\n",
      "Train_loss: 2.1037506280385974\n",
      "val_loss: 0.1297337856605442\n",
      "best loss: 0.1297337856605442\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.098949996905985\n",
      "val_loss: 0.12984730929976854\n",
      "best loss: 0.1297337856605442\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.0947496537049486\n",
      "val_loss: 0.1297220171579985\n",
      "best loss: 0.1297220171579985\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.0902416976508444\n",
      "val_loss: 0.1294932907125898\n",
      "best loss: 0.1294932907125898\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.0849090670810173\n",
      "val_loss: 0.12953449282789398\n",
      "best loss: 0.1294932907125898\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.0805924341562023\n",
      "val_loss: 0.12990701457479362\n",
      "best loss: 0.1294932907125898\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.07761248752511\n",
      "val_loss: 0.1298069480866032\n",
      "best loss: 0.1294932907125898\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.071696093133645\n",
      "val_loss: 0.12960596874745545\n",
      "best loss: 0.1294932907125898\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.06734019611476\n",
      "val_loss: 0.12923512948704438\n",
      "best loss: 0.12923512948704438\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.062481976692897\n",
      "val_loss: 0.12961858001973126\n",
      "best loss: 0.12923512948704438\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.058366754425099\n",
      "val_loss: 0.12937640159935768\n",
      "best loss: 0.12923512948704438\n",
      "*********************************\n",
      "epoch 40\n",
      "Train_loss: 2.054146852478506\n",
      "val_loss: 0.12951935456940888\n",
      "best loss: 0.12923512948704438\n",
      "*********************************\n",
      "epoch 41\n",
      "Train_loss: 2.0491577532767247\n",
      "val_loss: 0.1295353345869182\n",
      "best loss: 0.12923512948704438\n",
      "*********************************\n",
      "epoch 42\n",
      "Train_loss: 2.044795432330534\n",
      "val_loss: 0.1296034498492105\n",
      "best loss: 0.12923512948704438\n",
      "*********************************\n",
      "epoch 43\n",
      "Train_loss: 2.0407233459520935\n",
      "val_loss: 0.12948235970888194\n",
      "best loss: 0.12923512948704438\n",
      "*********************************\n",
      "epoch 44\n",
      "Train_loss: 2.0371567089619806\n",
      "val_loss: 0.12922419436591978\n",
      "best loss: 0.12922419436591978\n",
      "*********************************\n",
      "epoch 45\n",
      "Train_loss: 2.033358558966\n",
      "val_loss: 0.12930408031062424\n",
      "best loss: 0.12922419436591978\n",
      "*********************************\n",
      "epoch 46\n",
      "Train_loss: 2.02830842408091\n",
      "val_loss: 0.1291594450416813\n",
      "best loss: 0.1291594450416813\n",
      "*********************************\n",
      "epoch 47\n",
      "Train_loss: 2.026738644619635\n",
      "val_loss: 0.12909048785094834\n",
      "best loss: 0.12909048785094834\n",
      "*********************************\n",
      "epoch 48\n",
      "Train_loss: 2.0224376853744324\n",
      "val_loss: 0.12953785273424104\n",
      "best loss: 0.12909048785094834\n",
      "*********************************\n",
      "epoch 49\n",
      "Train_loss: 2.0171755398911015\n",
      "val_loss: 0.12958495019349578\n",
      "best loss: 0.12909048785094834\n",
      "*********************************\n",
      "epoch 50\n",
      "Train_loss: 2.012669938890025\n",
      "val_loss: 0.12927044592868162\n",
      "best loss: 0.12909048785094834\n",
      "*********************************\n",
      "epoch 51\n",
      "Train_loss: 2.009471427605735\n",
      "val_loss: 0.12916701131758015\n",
      "best loss: 0.12909048785094834\n",
      "*********************************\n",
      "epoch 52\n",
      "Train_loss: 2.0036723750685796\n",
      "val_loss: 0.129279691086625\n",
      "best loss: 0.12909048785094834\n",
      "*********************************\n",
      "epoch 53\n",
      "Train_loss: 2.000461493434784\n",
      "val_loss: 0.12903751259860957\n",
      "best loss: 0.12903751259860957\n",
      "*********************************\n",
      "epoch 54\n",
      "Train_loss: 1.997276969012619\n",
      "val_loss: 0.12925783103770258\n",
      "best loss: 0.12903751259860957\n",
      "*********************************\n",
      "epoch 55\n",
      "Train_loss: 1.9932004438438142\n",
      "val_loss: 0.12887437485108716\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 56\n",
      "Train_loss: 1.9895187093567843\n",
      "val_loss: 0.12918634906976903\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 57\n",
      "Train_loss: 1.9862017143085196\n",
      "val_loss: 0.12965390533117946\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 58\n",
      "Train_loss: 1.9823701430912908\n",
      "val_loss: 0.12920737691855122\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 59\n",
      "Train_loss: 1.9788542541003933\n",
      "val_loss: 0.12930492241026376\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 60\n",
      "Train_loss: 1.9774402114485143\n",
      "val_loss: 0.12913925520230338\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 61\n",
      "Train_loss: 1.9714035630800657\n",
      "val_loss: 0.1297253820490747\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62\n",
      "Train_loss: 1.9666072268917296\n",
      "val_loss: 0.12907703402773113\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 63\n",
      "Train_loss: 1.963075442418857\n",
      "val_loss: 0.12902573711229198\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 64\n",
      "Train_loss: 1.9611523916209235\n",
      "val_loss: 0.12936210335217144\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 65\n",
      "Train_loss: 1.9561748294930705\n",
      "val_loss: 0.12900051260889053\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 66\n",
      "Train_loss: 1.9526620239308725\n",
      "val_loss: 0.12910226410868558\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 67\n",
      "Train_loss: 1.9413193776792477\n",
      "val_loss: 0.12922419629063675\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 68\n",
      "Train_loss: 1.9396076363506458\n",
      "val_loss: 0.1289887346314115\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 69\n",
      "Train_loss: 1.938897158333027\n",
      "val_loss: 0.12909721188292297\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 70\n",
      "Train_loss: 1.938060012180847\n",
      "val_loss: 0.1290433961246713\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 71\n",
      "Train_loss: 1.9371387137359148\n",
      "val_loss: 0.12903919510354592\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 72\n",
      "Train_loss: 1.9366942980564985\n",
      "val_loss: 0.1289273533908714\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 73\n",
      "Train_loss: 1.9367875342294445\n",
      "val_loss: 0.12892483042681\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 74\n",
      "Train_loss: 1.9364309065264618\n",
      "val_loss: 0.1292056953409939\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 75\n",
      "Train_loss: 1.9357405996509283\n",
      "val_loss: 0.12901901027598947\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "epoch 76\n",
      "Train_loss: 1.9361333950506683\n",
      "val_loss: 0.12904423260807987\n",
      "best loss: 0.12887437485108716\n",
      "*********************************\n",
      "RC 7\n",
      "initial loss: 0.1411387940371666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f5328afac0488cac40b6ed816239f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.264809517598096\n",
      "val_loss: 0.13999152456526454\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.2496974734319215\n",
      "val_loss: 0.14097845025924619\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.2405687763538844\n",
      "val_loss: 0.14077227721760557\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.231676367624158\n",
      "val_loss: 0.14014233465769643\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.2220032978421687\n",
      "val_loss: 0.14052603293043972\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.213276079499444\n",
      "val_loss: 0.14045158418004075\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.2063682255714356\n",
      "val_loss: 0.14010797808315203\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.2014271825466913\n",
      "val_loss: 0.14011751991880048\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.1956653972328746\n",
      "val_loss: 0.14035040521744382\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.1834733828528337\n",
      "val_loss: 0.14053176108683388\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.182797981414422\n",
      "val_loss: 0.1401728797953629\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 11\n",
      "Train_loss: 2.1775012614596045\n",
      "val_loss: 0.14040194930670782\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.172645593500658\n",
      "val_loss: 0.1402415999879896\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.1728436527079302\n",
      "val_loss: 0.14014805342783185\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.1709599636340275\n",
      "val_loss: 0.14008888279576312\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.167714203187663\n",
      "val_loss: 0.14004689216754576\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.1665361051141563\n",
      "val_loss: 0.140058342980807\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.167989043589705\n",
      "val_loss: 0.14014615466067856\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.1662743399096973\n",
      "val_loss: 0.14012133692358544\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.164991495406564\n",
      "val_loss: 0.1401308873836026\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.1665255027707127\n",
      "val_loss: 0.1401213388426744\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.166591947859313\n",
      "val_loss: 0.14010606276603144\n",
      "best loss: 0.13999152456526454\n",
      "*********************************\n",
      "RC 8\n",
      "initial loss: 0.13301437860880388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6352d55a1e934ced89c551ee5eeb33d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train_loss: 2.24332124418199\n",
      "val_loss: 0.1320573631272611\n",
      "best loss: 0.1320573631272611\n",
      "*********************************\n",
      "epoch 1\n",
      "Train_loss: 2.2224780234381503\n",
      "val_loss: 0.1325689936971083\n",
      "best loss: 0.1320573631272611\n",
      "*********************************\n",
      "epoch 2\n",
      "Train_loss: 2.211323987185134\n",
      "val_loss: 0.1324069070082678\n",
      "best loss: 0.1320573631272611\n",
      "*********************************\n",
      "epoch 3\n",
      "Train_loss: 2.197756012815362\n",
      "val_loss: 0.13224200278047968\n",
      "best loss: 0.1320573631272611\n",
      "*********************************\n",
      "epoch 4\n",
      "Train_loss: 2.1883291049109226\n",
      "val_loss: 0.13203199229919838\n",
      "best loss: 0.13203199229919838\n",
      "*********************************\n",
      "epoch 5\n",
      "Train_loss: 2.179778395726114\n",
      "val_loss: 0.13207004864630176\n",
      "best loss: 0.13203199229919838\n",
      "*********************************\n",
      "epoch 6\n",
      "Train_loss: 2.1752946905041406\n",
      "val_loss: 0.13203622099385495\n",
      "best loss: 0.13203199229919838\n",
      "*********************************\n",
      "epoch 7\n",
      "Train_loss: 2.1627942228658563\n",
      "val_loss: 0.13236744155933547\n",
      "best loss: 0.13203199229919838\n",
      "*********************************\n",
      "epoch 8\n",
      "Train_loss: 2.1561492454604334\n",
      "val_loss: 0.1320291776733249\n",
      "best loss: 0.1320291776733249\n",
      "*********************************\n",
      "epoch 9\n",
      "Train_loss: 2.150700867201313\n",
      "val_loss: 0.1319361494697587\n",
      "best loss: 0.1319361494697587\n",
      "*********************************\n",
      "epoch 10\n",
      "Train_loss: 2.1461246735378174\n",
      "val_loss: 0.13169512976942427\n",
      "best loss: 0.13169512976942427\n",
      "*********************************\n",
      "epoch 11\n",
      "Train_loss: 2.1409662847765274\n",
      "val_loss: 0.13238012772187543\n",
      "best loss: 0.13169512976942427\n",
      "*********************************\n",
      "epoch 12\n",
      "Train_loss: 2.133623081558012\n",
      "val_loss: 0.1313695427827305\n",
      "best loss: 0.1313695427827305\n",
      "*********************************\n",
      "epoch 13\n",
      "Train_loss: 2.127205933518429\n",
      "val_loss: 0.13143578969023872\n",
      "best loss: 0.1313695427827305\n",
      "*********************************\n",
      "epoch 14\n",
      "Train_loss: 2.125542533210401\n",
      "val_loss: 0.1312765310242458\n",
      "best loss: 0.1312765310242458\n",
      "*********************************\n",
      "epoch 15\n",
      "Train_loss: 2.119018918413311\n",
      "val_loss: 0.13134558877161706\n",
      "best loss: 0.1312765310242458\n",
      "*********************************\n",
      "epoch 16\n",
      "Train_loss: 2.1144795091690085\n",
      "val_loss: 0.13139773596702312\n",
      "best loss: 0.1312765310242458\n",
      "*********************************\n",
      "epoch 17\n",
      "Train_loss: 2.1108866129838577\n",
      "val_loss: 0.1311200752873168\n",
      "best loss: 0.1311200752873168\n",
      "*********************************\n",
      "epoch 18\n",
      "Train_loss: 2.1033288251320292\n",
      "val_loss: 0.1309283966534541\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 19\n",
      "Train_loss: 2.0985928732646384\n",
      "val_loss: 0.13169372639455978\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 20\n",
      "Train_loss: 2.092068866351031\n",
      "val_loss: 0.13097349040441925\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 21\n",
      "Train_loss: 2.0900427723923687\n",
      "val_loss: 0.1314005563129899\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 22\n",
      "Train_loss: 2.0846269832022752\n",
      "val_loss: 0.13144425385212796\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 23\n",
      "Train_loss: 2.0794437661351863\n",
      "val_loss: 0.13171485644487757\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 24\n",
      "Train_loss: 2.074871135379631\n",
      "val_loss: 0.1315175443397767\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 25\n",
      "Train_loss: 2.070189985728066\n",
      "val_loss: 0.13155700592442704\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 26\n",
      "Train_loss: 2.0641901770804916\n",
      "val_loss: 0.1318177539322652\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 27\n",
      "Train_loss: 2.063572389434533\n",
      "val_loss: 0.1315795522757594\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 28\n",
      "Train_loss: 2.0608278912189495\n",
      "val_loss: 0.13184031093150927\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch 29\n",
      "Train_loss: 2.056474943922063\n",
      "val_loss: 0.13141747339584553\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 30\n",
      "Train_loss: 2.0421405502206564\n",
      "val_loss: 0.13135545868459797\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 31\n",
      "Train_loss: 2.0426933772063296\n",
      "val_loss: 0.13133290612591725\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 32\n",
      "Train_loss: 2.0409127073653037\n",
      "val_loss: 0.13139915112533357\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 33\n",
      "Train_loss: 2.0400820598615974\n",
      "val_loss: 0.13132022061344903\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 34\n",
      "Train_loss: 2.040179022553772\n",
      "val_loss: 0.1312074620036871\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 35\n",
      "Train_loss: 2.040920664100075\n",
      "val_loss: 0.13134135952487752\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 36\n",
      "Train_loss: 2.039264699461939\n",
      "val_loss: 0.1313709643897762\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 37\n",
      "Train_loss: 2.038843290986358\n",
      "val_loss: 0.13126384238271\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 38\n",
      "Train_loss: 2.0393327330449162\n",
      "val_loss: 0.13138082878700622\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "epoch 39\n",
      "Train_loss: 2.0380324722434864\n",
      "val_loss: 0.13141324377358204\n",
      "best loss: 0.1309283966534541\n",
      "*********************************\n",
      "fold 4, score: 0.14076225324364613\n",
      "CV score: 0.1380712609359419\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "N_FOLDS = 5\n",
    "BATCH_SIZE = 128\n",
    "oof_path = f\"oofs/oof_finetune_{MODEL_NAME}\"\n",
    "device = torch.device('cuda:0')\n",
    "kf = StratifiedKFold(N_FOLDS,shuffle=True, random_state=42)\n",
    "oof = np.zeros(y_tr[:75450].shape)\n",
    "y_true = le.inverse_transform(y_tr[:75450].reshape(-1)).reshape(y_tr[:75450].shape)\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_tr[:75450,0,0], X_tr[:75450,0,0])):\n",
    "    print(\"fold:\",fold)\n",
    "    for RC in range(9):\n",
    "      print(\"RC\",RC)\n",
    "      model_path = f'models/{MODEL_NAME}/model_{fold}_RC_{RC}.pt'\n",
    "\n",
    "      train_index = np.concatenate([train_index,np.arange(75450,len(X_tr))])\n",
    "      tr_idx = np.intersect1d(train_index,np.where(X_tr[:,0,0]==RC))\n",
    "      val_idx = np.intersect1d(val_index,np.where(X_tr[:,0,0]==RC))\n",
    "      test_idx = np.where(X_test[:,0,0]==RC)\n",
    "\n",
    "      train_dataset = TensorDataset(torch.Tensor(X_tr[tr_idx]),torch.LongTensor(y_tr[tr_idx]))\n",
    "      val_dataset = TensorDataset(torch.Tensor(X_tr[val_idx]),torch.LongTensor(y_tr[val_idx]))\n",
    "      train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=2)\n",
    "      val_dataloader = DataLoader(val_dataset, batch_size=3*BATCH_SIZE, shuffle=False, drop_last=False, num_workers=2)\n",
    "\n",
    "      model = BrainModel().to(device)\n",
    "      if (not os.path.exists(model_path)):\n",
    "          model.load_state_dict(torch.load(f'models/{MODEL_NAME}/model_{fold}.pt'))\n",
    "          optimizer = optim.Ranger(model.parameters(), lr=1e-4, weight_decay=0, alpha=0.5, k=5)\n",
    "          scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10, threshold=0.0001, min_lr=1e-6, verbose=True)\n",
    "          best_score = evaluation(model, val_dataloader, device)\n",
    "          torch.save(model.state_dict(),model_path)\n",
    "          print(f\"initial loss: {best_score}\")\n",
    "          stop_step = 0\n",
    "          for epoch in tqdm(range(N_EPOCHS),leave=False):\n",
    "              Train_loss = train_one_epoch(model, optimizer, train_dataloader, epoch, device)\n",
    "              val_loss = evaluation(model, val_dataloader, device)\n",
    "              scheduler.step(val_loss)\n",
    "              if val_loss < best_score:\n",
    "                best_score = val_loss\n",
    "                torch.save(model.state_dict(),model_path)\n",
    "                stop_step = 0\n",
    "              else:\n",
    "                stop_step += 1\n",
    "              print(f\"epoch {epoch}\")\n",
    "              print(f\"Train_loss: {Train_loss}\")\n",
    "              print(f\"val_loss: {val_loss}\")\n",
    "              print(f\"best loss: {best_score}\")\n",
    "              print(\"*********************************\")\n",
    "              if stop_step > 20:\n",
    "                break\n",
    "      model.load_state_dict(torch.load(model_path))\n",
    "      val_pred = inference(model, val_dataloader, device, False)\n",
    "      oof[val_idx] = val_pred\n",
    "    mask = X_tr[val_index,:,2]==0\n",
    "    print(f\"fold {fold}, score:\",mean_absolute_error(y_true[val_index][mask], oof[val_index][mask]))\n",
    "mask = X_tr[:75450,:,2]==0\n",
    "print(\"CV score:\",mean_absolute_error(y_true[mask], oof[mask]))\n",
    "np.save(oof_path,oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch15]",
   "language": "python",
   "name": "conda-env-.conda-pytorch15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31610.007673,
   "end_time": "2021-10-13T13:02:25.335355",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-13T04:15:35.327682",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "12a4846039954478b23397922ba2e7a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_64b71c2ec725460c9d97dea18c1b8221",
       "max": 300,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7953bfe3acad4a50b5f687991211d2bc",
       "value": 300
      }
     },
     "4927652eb1c346fa84a78d6c5e045622": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "504ef3b85c1c4688bc53a334675aa601": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f594d87f3fb741b8a87da31348a174da",
       "placeholder": "​",
       "style": "IPY_MODEL_ec150678fe7a4cf98a1a68ccd5409338",
       "value": "100%"
      }
     },
     "575472c0debb49129fb32c54a9289a01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_504ef3b85c1c4688bc53a334675aa601",
        "IPY_MODEL_12a4846039954478b23397922ba2e7a2",
        "IPY_MODEL_f6679feabe7341e19bce028fd9597ebd"
       ],
       "layout": "IPY_MODEL_a561495982104452b7b4ba9fdd176a37"
      }
     },
     "5b660f1a714a4a8a8e2f2aefcd060220": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "64b71c2ec725460c9d97dea18c1b8221": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7953bfe3acad4a50b5f687991211d2bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a561495982104452b7b4ba9fdd176a37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec150678fe7a4cf98a1a68ccd5409338": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f594d87f3fb741b8a87da31348a174da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f6679feabe7341e19bce028fd9597ebd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5b660f1a714a4a8a8e2f2aefcd060220",
       "placeholder": "​",
       "style": "IPY_MODEL_4927652eb1c346fa84a78d6c5e045622",
       "value": " 300/300 [8:44:09&lt;00:00, 104.89s/it]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
